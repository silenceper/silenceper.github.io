{"/blog/":{"data":{"":" RSS è®¢é˜… "},"title":"åšå®¢"},"/blog/201601/tcp_time_wait_error/":{"data":{"åæ€#åæ€ï¼š":"é—®é¢˜ç»ˆäºæ‰¾åˆ°è§£å†³ï¼Œä½†æ˜¯å›è¿‡å¤´æ¥æƒ³äº†ä¸€ä¸‹ï¼Œå…¶å®ä¸€å¼€å§‹å°±å¯ä»¥å®šä½åˆ°çš„ï¼Œåªæ˜¯å¾ˆå¤šé—®é¢˜é›†ä¸­åœ¨ä¸€èµ·å‡ºç°åè€Œè®©è‡ªå·±ä¸çŸ¥æ‰€æªï¼Œè¿™ä¸ªæ—¶å€™å¦‚æœæ˜¯æ•æ„Ÿçš„äººçš„è¯åº”è¯¥é©¬ä¸Šèƒ½å¤Ÿä»tcpçŠ¶æ€ä¸Šçœ‹å‡ºé—®é¢˜ï¼Œä¹‹åçº¿ä¸Šé‡åˆ°é—®é¢˜ï¼Œé‡è¦çš„æ˜¯å…ˆè§£å†³ï¼ˆä¸ç®¡é€šè¿‡ä»€ä¹ˆæ–¹å¼ï¼‰ï¼Œä¹‹åå†ä¸€æ­¥æ­¥æ’æŸ¥ã€‚","æ’æŸ¥#æ’æŸ¥ï¼š":"è¿™ä¸ªé—®é¢˜å›´ç»•æˆ‘å¥½å‡ å¤©ï¼Œæˆ‘å±è”½çš„é‚£å‡ ä¸ªæ¥å£ï¼Œåå¤çœ‹äº†å¥½å‡ éï¼Œè€Œä¸”åˆå°†å…¶ä¸­çš„sqlæŸ¥è¯¢åˆ†æï¼Œå¹¶æ²¡æœ‰æ…¢è¯·æ±‚ã€‚ã€‚ã€‚ è¿™ä¸‹åˆå½»åº•æ‡µäº†ï¼Œæ²¡æœ‰å¤´ç»ªã€‚\nè¯´æ¥ä¹Ÿå·§ï¼Œé«˜å³°æ—¶æœŸæˆ‘ç”¨netstat -an å‘½ä»¤æŸ¥çœ‹äº†ä¸€äº›ï¼Œçœ‹åˆ°å¤§é‡tcp time_wait çš„è¿æ¥ï¼Œèµ¶ç´§Googleäº†ä¸‹ï¼Œtcp time_waitçŠ¶æ€æ˜¯åœ¨ä¸»åŠ¨å…³é—­è¿æ¥çš„ä¸€æ–¹ä¿æŒçš„ä¸€ä¸ªçŠ¶æ€ï¼ˆä¸€èˆ¬æŒ‡å®¢æˆ·ç«¯ï¼‰ï¼Œ\næ€»å…±çš„è¿æ¥æ•°åœ¨è¿‘3w(ss -så¯æŸ¥)ï¼Œå…¶ä¸­æœ‰2wå¤šéƒ½æ˜¯è¿™ç§è¿æ¥ï¼Œè€Œä¸”éƒ½æ˜¯mysql è¿æ¥ï¼ˆè¿™é‡Œè¾¹æœåŠ¡å™¨ç¨‹åºå°±ç›¸å½“äºå®¢æˆ·ç«¯å»è¿æ¥mysqlæœåŠ¡å™¨ï¼‰ï¼Œåˆ°è¿™é‡Œå¿ƒé‡Œå¤§è‡´æœ‰åº•äº†ï¼ŒæŠŠæ•°æ®åº“è¿æ¥æ± åŠ ä¸Šå°±å¥½äº†ï¼ŒGolangæä¾›äº†ä¸¤ä¸ªå‡½æ•°å¯è¿›è¡Œé…ç½®ï¼š\nSetMaxOpenConnsç”¨äºè®¾ç½®æœ€å¤§æ‰“å¼€çš„è¿æ¥æ•°ï¼Œé»˜è®¤å€¼ä¸º0è¡¨ç¤ºä¸é™åˆ¶ã€‚ SetMaxIdleConnsç”¨äºè®¾ç½®é—²ç½®çš„è¿æ¥æ•°ã€‚ ä¸ºä»€ä¹ˆä¼šæœ‰TIME_WAITçŠ¶æ€ï¼Ÿ\næºäºtcpé“¾æ¥å…³é—­ä¸­çš„å››æ¬¡æŒ¥æ‰‹ï¼Œæ˜¯ä¸»åŠ¨å…³é—­é“¾æ¥çš„ä¸€æ–¹äº§ç”Ÿçš„çŠ¶æ€ï¼š TCPçŠ¶æ€è½¬åŒ–å›¾ä¸‰æ¬¡æ¡æ‰‹/å››æ¬¡æŒ¥æ‰‹ï¼š\nå››æ¬¡æŒ¥æ‰‹çš„è¿‡ç¨‹å¦‚ä¸‹ï¼š\nä¸»åŠ¨å…³é—­è¿æ¥çš„ä¸€æ–¹ï¼Œè°ƒç”¨close()ï¼›åè®®å±‚å‘é€FINåŒ…\nè¢«åŠ¨å…³é—­çš„ä¸€æ–¹æ”¶åˆ°FINåŒ…åï¼Œåè®®å±‚å›å¤ACKï¼›ç„¶åè¢«åŠ¨å…³é—­çš„ä¸€æ–¹ï¼Œè¿›å…¥CLOSE_WAITçŠ¶æ€ï¼Œä¸»åŠ¨å…³é—­çš„ä¸€æ–¹ç­‰å¾…å¯¹æ–¹å…³é—­ï¼Œåˆ™è¿›å…¥FIN_WAIT_2çŠ¶æ€ï¼›æ­¤æ—¶ï¼Œä¸»åŠ¨å…³é—­çš„ä¸€æ–¹ ç­‰å¾… è¢«åŠ¨å…³é—­ä¸€æ–¹çš„åº”ç”¨ç¨‹åºï¼Œè°ƒç”¨closeæ“ä½œ\nè¢«åŠ¨å…³é—­çš„ä¸€æ–¹åœ¨å®Œæˆæ‰€æœ‰æ•°æ®å‘é€åï¼Œè°ƒç”¨close()æ“ä½œï¼›æ­¤æ—¶ï¼Œåè®®å±‚å‘é€FINåŒ…ç»™ä¸»åŠ¨å…³é—­çš„ä¸€æ–¹ï¼Œç­‰å¾…å¯¹æ–¹çš„ACKï¼Œè¢«åŠ¨å…³é—­çš„ä¸€æ–¹è¿›å…¥LAST_ACKçŠ¶æ€ï¼›\nä¸»åŠ¨å…³é—­çš„ä¸€æ–¹æ”¶åˆ°FINåŒ…ï¼Œåè®®å±‚å›å¤ACKï¼›æ­¤æ—¶ï¼Œä¸»åŠ¨å…³é—­è¿æ¥çš„ä¸€æ–¹ï¼Œè¿›å…¥TIME_WAITçŠ¶æ€ï¼›è€Œè¢«åŠ¨å…³é—­çš„ä¸€æ–¹ï¼Œè¿›å…¥CLOSEDçŠ¶æ€\nç­‰å¾…2MSLæ—¶é—´ï¼Œä¸»åŠ¨å…³é—­çš„ä¸€æ–¹ï¼Œç»“æŸTIME_WAITï¼Œè¿›å…¥CLOSEDçŠ¶æ€\næ‰€ä»¥time_waitå±äºtcpæ­£å¸¸çš„ä¸€ä¸ªçŠ¶æ€ï¼Œæ˜¯ä¸ºäº†è§£å†³ç½‘ç»œçš„ä¸¢åŒ…å’Œç½‘ç»œä¸ç¨³å®šé”å­˜åœ¨çš„ä¸€ä¸ªçŠ¶æ€ã€‚\nå› ä¸ºå½“å‰æœåŠ¡å™¨å¹¶å‘ç›¸å¯¹è¾ƒå¤§ï¼Œæ‰€ä»¥å­˜åœ¨äº†å¤§é‡çš„é“¾æ¥ä¸ºå…³é—­ï¼Œå¦‚æœåªæ˜¯å‡ ç™¾çš„è¯ï¼Œä¹Ÿä¸ä¼šå½±å“æœåŠ¡å™¨æ€§èƒ½ã€‚\nä½¿ç”¨è¿æ¥æ± ä¿å­˜é•¿é“¾æ¥ï¼Œå¯ä½¿å¾—é“¾æ¥å¤ç”¨ï¼Œä¸ä¼šå‡ºç°å¤§é‡çš„è¿™ç§çŠ¶æ€ã€‚","é—®é¢˜å‡ºç°#é—®é¢˜å‡ºç°ï¼š":"é—®é¢˜å‡ºç°ï¼šåœ¨å…ƒæ—¦å‰å¤•ï¼Œè‡ªå·±ç»´æŠ¤çš„ä¸€ä¸ªæœåŠ¡çªç„¶åœ¨é«˜å³°æ—¶æœŸæ”¶åˆ°å¤§é‡æŠ¥è­¦ï¼Œèµ¶ç´§ç™»ä¸ŠæœåŠ¡å™¨çœ‹ä¸€ä¸‹ï¼š\næœ€å¼€å§‹çš„ååº”æ˜¯memcache tcp read time out ,å› ä¸ºä¹‹å‰ä¹Ÿå‡ºç°è¿‡ç±»ä¼¼çš„è­¦å‘Šæ‰€ä»¥å¼€å§‹å°è¯•åˆ‡æ¢memcacheï¼Œä½†æ˜¯è¿ç»´åé¦ˆå·²ç»åˆ‡æ¢äº†å¥½å‡ å°è¿˜æ˜¯ä¸èµ·ä½œç”¨ã€‚\nåˆçœ‹åˆ°æœ‰mysql è¿æ¥ä¸ä¸ŠæŠ¥é”™ï¼Œæ€€ç–‘æœºæˆ¿å†…ç½‘æœ‰é—®é¢˜ï¼Œç„¶åæœ‰å¼€å§‹åˆ‡æ¢æœºæˆ¿åŠ æœºå™¨ï¼Œå½“æ—¶é—®é¢˜è¿˜æ˜¯æ²¡æœ‰å¾—åˆ°è§£å†³ï¼Œè¿™ä¸‹çœŸæ™•äº†ã€‚ã€‚ã€‚ã€‚ å®Œå…¨æ’æŸ¥ä¸å‡ºä»€ä¹ˆé—®é¢˜ï¼ˆå› ä¸ºæ˜¯é«˜å³°æ—¶æœŸï¼Œtcpè¿æ¥æ•°è‡ªç„¶å¾ˆé«˜ï¼Œæ²¡æœ‰åœ¨æ„æ˜¯è¿™ä¸ªé—®é¢˜ï¼Œè‡ªå·±é¢„ä¼°ä¸å¤Ÿï¼‰\nåæ¥ååº”è¿‡æ¥çœ‹åˆ°æœ‰å¥½å‡ ä¸ªæ¥å£è¯·æ±‚æ•°å¢åŠ ï¼Œå› ä¸ºå‘ç‰ˆæœ¬çš„åŸå› ï¼Œæ˜¯æ–°ç‰ˆæœ¬æ‰ä¼šè¯·æ±‚è¿™äº›æ¥å£ï¼Œæ‰€ä»¥ æˆ‘æš‚æ—¶å±è”½äº†è¿™å‡ ä¸ªå£æ¥å£é—®é¢˜å¾—åˆ°éåˆ¶ï¼ˆå¹¸å¥½æ˜¯ç”¨æˆ·æ„ŸçŸ¥ä¸åˆ°çš„æ¥å£ï¼‰ã€‚"},"title":"tcp time_waité—®é¢˜"},"/blog/201605/go-http-process/":{"data":{"21-æ·»åŠ è·¯ç”±è§„åˆ™#2.1 æ·»åŠ è·¯ç”±è§„åˆ™":"å…ˆçœ‹ä¸¤ä¸ªstructï¼Œè¿™æ˜¯å­˜æ”¾é»˜è®¤è·¯ç”±è§„åˆ™çš„ï¼š\ntype ServeMux struct { mu sync.RWMutex //å¤„ç†å¹¶å‘ï¼Œå¢åŠ è¯»å†™é” m map[string]muxEntry //å­˜æ”¾è§„åˆ™mapï¼Œkeyå³ä¸ºè®¾ç½®çš„path hosts bool // whether any patterns contain hostnamesï¼ˆæ˜¯å¦åŒ…å«hostï¼‰ } type muxEntry struct { explicit bool //æ˜¯å¦å®Œå…¨åŒ¹é… h Handler//ç›¸åº”åŒ¹é…è§„åˆ™çš„handler pattern string//åŒ¹é…è·¯å¾„ } é€šè¿‡è·Ÿè¸ªhttp.HandleFuncå®šä½åˆ°å¦‚ä¸‹ä»£ç ï¼Œæ­£æ˜¯å¾€ä¸Šé¢ä¸¤ä¸ªstructä¸­å¢åŠ è§„åˆ™ï¼š\nfunc (mux *ServeMux) Handle(pattern string, handler Handler) { mux.mu.Lock() defer mux.mu.Unlock() if pattern == \"\" { panic(\"http: invalid pattern \" + pattern) } if handler == nil { panic(\"http: nil handler\") } //å¦‚æœå·²ç»åŒ¹é…åˆ°äº†åˆ™panic if mux.m[pattern].explicit { panic(\"http: multiple registrations for \" + pattern) } //å¢åŠ ä¸€ä¸ªæ–°çš„åŒ¹é…è§„åˆ™ mux.m[pattern] = muxEntry{explicit: true, h: handler, pattern: pattern} //æ ¹æ®pathçš„ç¬¬ä¸€ä¸ªå­—æ¯åˆ¤æ–­æ˜¯å¦æœ‰host if pattern[0] != '/' { mux.hosts = true } //ï¼ï¼è¿™é‡Œçœ‹æ¸…æ¥š å°±æ˜¯å®ç°äº†æƒ…æ™¯äºŒçš„æƒ…å†µ ï¼Œçœ‹åˆ¤æ–­æ¡ä»¶ n := len(pattern) if n \u003e 0 \u0026\u0026 pattern[n-1] == '/' \u0026\u0026 !mux.m[pattern[0:n-1]].explicit{ // If pattern contains a host name, strip it and use remaining // path for redirect. path := pattern if pattern[0] != '/' { // In pattern, at least the last character is a '/', so // strings.Index can't be -1. path = pattern[strings.Index(pattern, \"/\"):] } url := \u0026url.URL{Path: path} mux.m[pattern[0:n-1]] = muxEntry{h: RedirectHandler(url.String(), StatusMovedPermanently), pattern: pattern} } } ä¸Šé¢æœ‰ä¸ªHelpful behaviorçš„æ³¨é‡Šè¡Œä¸ºï¼Œå°±æ˜¯å®ç°äº†æƒ…æ™¯äºŒçš„æƒ…å†µï¼Œä»–æ˜¯åˆ¤æ–­å¦‚æœåŒ¹é…çš„è·¯å¾„ä¸­æœ€åå«æœ‰/ï¼Œå¹¶ä¸”ä¹‹å‰ä¹Ÿä¸å­˜åœ¨æ·»åŠ å»é™¤åæ–œæ çš„è§„åˆ™çš„è¯ï¼Œå°±è‡ªåŠ¨ç»™ä»–å¢åŠ ä¸€ä¸ª301çš„è·³è½¬æŒ‡å‘/path/","22-æŸ¥æ‰¾è·¯ç”±è§„åˆ™#2.2 æŸ¥æ‰¾è·¯ç”±è§„åˆ™":"è·¯ç”±è§„åˆ™çš„æŸ¥æ‰¾å°±æ˜¯ä»ServeMux ä¸­çš„mapå»åŒ¹é…æŸ¥æ‰¾çš„,çš„åˆ°è¿™ä¸ªhandlerå¹¶æ‰§è¡Œï¼Œåªæ˜¯ä¼šæœ‰ä¸€äº›å¤„ç†æœºåˆ¶ï¼Œæ¯”å¦‚æ€ä¹ˆæ ·ç¡®ä¿è®¿é—®/path/subpathçš„æ—¶å€™æ˜¯å…ˆåŒ¹é…/path/subpathè€Œä¸æ˜¯åŒ¹é…/path/å‘¢ï¼Ÿ\nå½“ä¸€ä¸ªè¯·æ±‚è¿‡æ¥çš„æ—¶å€™ï¼Œè·Ÿè¸ªåˆ°äº†mux.matchæ–¹æ³•ï¼š\nè¿‡ç¨‹mux.ServerHTTP-\u003emux.Handler-\u003emux.handler-\u003emux.match\nfunc (mux *ServeMux) match(path string) (h Handler, pattern string) { var n = 0 for k, v := range mux.m { if !pathMatch(k, path) { continue } //å¦‚æœåŒ¹é…åˆ°äº†ä¸€ä¸ªè§„åˆ™ï¼Œå¹¶æ²¡æœ‰é©¬ä¸Šè¿”å›handlerï¼Œè€Œä¸”ç»§ç»­åŒ¹é…å¹¶ä¸”åˆ¤æ–­pathçš„é•¿åº¦æ˜¯å¦æ˜¯æœ€é•¿çš„ï¼Œè¿™æ˜¯å…³é”®ï¼ï¼ï¼ if h == nil || len(k) \u003e n { n = len(k) h = v.h pattern = v.pattern } } return } 1.è¿™é‡Œå°±è§£é‡Šäº†ä¸ºä»€ä¹ˆè®¾ç½®çš„ç²¾ç¡®çš„pathæ˜¯æœ€ä¼˜åŒ¹é…åˆ°çš„ï¼Œå› ä¸ºå®ƒæ˜¯æ ¹æ®pathçš„é•¿åº¦åˆ¤æ–­ã€‚ å½“ç„¶ä¹Ÿå°±è§£é‡Šäº†ä¸ºä»€ä¹ˆ/å¯ä»¥åŒ¹é…æ‰€æœ‰ï¼ˆçœ‹pathMatchå‡½æ•°å°±çŸ¥é“äº†ï¼Œ/æ˜¯åŒ¹é…æ‰€æœ‰çš„ï¼Œåªæ˜¯è¿™æ˜¯æœ€åæ‰è¢«åŒ¹é…æˆåŠŸï¼‰\n2.å¾—åˆ°äº†å¤„ç†è¯·æ±‚çš„handlerï¼Œå†è°ƒç”¨h.ServeHTTP(w, r)ï¼Œå»æ‰§è¡Œç›¸åº”çš„handleræ–¹æ³•ã€‚\nç­‰ä¸€ä¸‹ï¼Œhandlerä¸­å“ªé‡Œæœ‰ServeHTTPè¿™ä¸ªæ–¹æ³•ï¼Ÿï¼Ÿ\nå› ä¸ºåœ¨è°ƒç”¨ http.HandleFuncçš„æ—¶å€™å·²ç»å°†è‡ªå®šä¹‰çš„handlerå¤„ç†å‡½æ•°ï¼Œå¼ºåˆ¶è½¬ä¸ºHandlerFuncç±»å‹çš„ï¼Œå°±æ‹¥æœ‰äº†ServeHTTPæ–¹æ³•ï¼š\ntype HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } f(w,r)å°±å®ç°äº†handlerçš„æ‰§è¡Œã€‚\nè„‘å­é‡Œé¢æ¸…æ¥šï¼Œä½†çœŸåˆ°è¡¨è¿°çš„æ—¶å€™ï¼Œå‘µå‘µï¼Œå½“åšç¬”è®°å•¦ã€‚ã€‚ã€‚","ä¸€æ‰§è¡Œæµç¨‹#ä¸€ã€æ‰§è¡Œæµç¨‹":"ä¸€ã€æ‰§è¡Œæµç¨‹æ„å»ºä¸€ä¸ªç®€å•http serverï¼š\npackage main import ( \"log\" \"net/http\" ) func main() { http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) log.Fatal(http.ListenAndServe(\":8080\", nil)) } ä½¿ç”¨http://127.0.0.1:8080/ å°±å¯ä»¥çœ‹åˆ°è¾“å‡ºäº†\né€šè¿‡è·Ÿè¸ªhttp.goåŒ…ä»£ç ï¼Œå¯ä»¥å‘ç°æ‰§è¡Œæµç¨‹åŸºæœ¬å¦‚ä¸‹ï¼š\n1.åˆ›å»ºä¸€ä¸ªListenerç›‘å¬8080ç«¯å£\n2.è¿›å…¥forå¾ªç¯å¹¶Acceptè¯·æ±‚ï¼Œæ²¡æœ‰è¯·æ±‚åˆ™å¤„äºé˜»å¡çŠ¶æ€\n3.æ¥æ”¶åˆ°è¯·æ±‚ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªconnå¯¹è±¡ï¼Œæ”¾å…¥goroutineå¤„ç†ï¼ˆå®ç°é«˜å¹¶å‘å…³é”®ï¼‰\n4.è§£æè¯·æ±‚æ¥æºä¿¡æ¯è·å¾—è¯·æ±‚è·¯å¾„ç­‰é‡è¦ä¿¡æ¯\n5.è¯·æ±‚ServerHTTPæ–¹æ³•ï¼Œå·²ç»é€šè¿‡ä¸Šä¸€æ­¥è·å¾—äº†ResponseWriterå’ŒRequestå¯¹è±¡\nfunc (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { //æ­¤handlerå³ä¸ºhttp.ListenAndServe ä¸­çš„ç¬¬äºŒä¸ªå‚æ•° handler := sh.srv.Handler if handler == nil { //å¦‚æœhandlerä¸ºç©ºåˆ™ä½¿ç”¨å†…éƒ¨çš„DefaultServeMux è¿›è¡Œå¤„ç† handler = DefaultServeMux } if req.RequestURI == \"*\" \u0026\u0026 req.Method == \"OPTIONS\" { handler = globalOptionsHandler{} } //è¿™é‡Œå°±å¼€å§‹å¤„ç†httpè¯·æ±‚ //å¦‚æœéœ€è¦ä½¿ç”¨è‡ªå®šä¹‰çš„muxï¼Œå°±éœ€è¦å®ç°ServeHTTPæ–¹æ³•ï¼Œå³å®ç°Handleræ¥å£ã€‚ handler.ServeHTTP(rw, req) } 6.è¿›å…¥DefaultServeMuxä¸­çš„é€»è¾‘å°±æ˜¯æ ¹æ®è¯·æ±‚pathåœ¨mapä¸­åŒ¹é…æŸ¥æ‰¾handlerï¼Œå¹¶äº¤ç”±handlerå¤„ç† httpè¯·æ±‚å¤„ç†æµç¨‹æ›´å¤šä¿¡æ¯å¯ä»¥å‚è€ƒã€ŠGo Web ç¼–ç¨‹ ã€‹3.3 Goå¦‚ä½•ä½¿å¾—Webå·¥ä½œ","äºŒdefaultservemux-è·¯ç”±åŒ¹é…è§„åˆ™#äºŒã€DefaultServeMux è·¯ç”±åŒ¹é…è§„åˆ™":"å…ˆçœ‹å‡ ä¸ªè·¯ç”±è§„åˆ™ï¼š\npackage main import ( \"log\" \"net/http\" ) func main() { //è§„åˆ™1 http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) //è§„åˆ™2 http.HandleFunc(\"/path/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"pattern path: /path/ \")) }) //è§„åˆ™3 http.HandleFunc(\"/path/subpath\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"pattern path: /path/subpath\")) }) log.Fatal(http.ListenAndServe(\":8080\", nil)) } æƒ…æ™¯ä¸€ï¼š\nè®¿é—®ï¼šhttp://127.0.0.1:8080/\nè¿”å›ï¼šhello world\næƒ…æ™¯äºŒï¼š\nè®¿é—®ï¼šhttp://127.0.0.1:8080/path\nè¿”å›ï¼špattern path: /path/ æƒ…æ™¯ä¸‰ï¼š\nè®¿é—®ï¼šhttp://127.0.0.1:8080/path/subpath/\nè¿”å›ï¼špattern path: /path/ æƒ…æ™¯å››ï¼š\nè®¿é—®ï¼šhttp://127.0.0.1:8080/hahaha/\nè¿”å›ï¼šhello world\nå…ˆè¯´æ˜ä¸€äº›è§„åˆ™å§ï¼Œå†çœ‹ä»£ç æ˜¯æ€ä¹ˆå®ç°çš„ï¼š\n1.å¦‚æœåŒ¹é…è·¯å¾„ä¸­åå¸¦æœ‰/ï¼Œåˆ™ä¼šè‡ªåŠ¨å¢åŠ ä¸€ä¸ªåŒ¹é…è§„åˆ™ä¸å¸¦/åç¼€çš„ï¼Œå¹¶è·³è½¬è½¬åˆ°path/,è§£é‡Šäº†æƒ…æ™¯äºŒçš„åœºæ™¯ï¼Œä¸ºä»€ä¹ˆåŒ¹é…åˆ°çš„/path/\n2.æˆ‘è®¾ç½®äº†è¿™ä¹ˆå¤šè§„åˆ™ä¸ºä»€ä¹ˆè§„åˆ™ä¸€å¯ä»¥é€šç”¨åŒ¹é…æœªè®¾ç½®çš„è·¯ç”±ä¿¡æ¯ï¼Œè€Œä¸”åˆä¸å½±å“å·²ç»å­˜åœ¨è·¯ç”±ï¼Œ å†…éƒ¨æ˜¯æ€ä¹ˆå®ç°çš„ï¼Ÿ"},"title":"Golangä¸­httpåŒ…é»˜è®¤è·¯ç”±åŒ¹é…è§„åˆ™é˜…è¯»ç¬”è®°"},"/blog/201608/dcmp/":{"data":{"":"Distributed Configuration Management Platform\næä¾›äº†ä¸€ä¸ªetcdçš„ç®¡ç†ç•Œé¢ï¼Œå¯é€šè¿‡ç•Œé¢ä¿®æ”¹é…ç½®ä¿¡æ¯ï¼Œå€ŸåŠ©confdå¯å®ç°é…ç½®æ–‡ä»¶çš„åŒæ­¥ã€‚\nGITHUBï¼šhttps://github.com/silenceper/dcmp\nAPIé‡‡ç”¨çš„æ˜¯Gin Frameworkï¼Œå†™èµ·apiåº”ç”¨æ¥éå¸¸æ–¹ä¾¿ï¼Œå‰ç«¯å°è¯•äº†ä¸€ä¸‹reactã€‚\nä¼ åˆ°Githubä¸€çœ‹ï¼Œå‘ç°cssï¼Œjsçš„ä»£ç æ¯”golangè¿˜è¦å¤š ã€‚ ğŸ˜¢"},"title":"dcmp"},"/blog/201609/go-wechat-sdk/":{"data":{"":"ä¸€ç›´å¾ˆæƒ³è‡ªå·±ç”¨golangå†™ä¸ªå¾®ä¿¡çš„sdkï¼Œç›®æ ‡æ˜¯ç®€å•å¥½ç”¨ï¼Œæ‰€ä»¥åˆ©ç”¨é—²æš‡æ—¶é—´ï¼ˆå‘¨æœ«ï¼Œä¸­ç§‹ğŸ˜ï¼‰ï¼Œå°±åšå‡ºæ¥ã€‚\né¡¹ç›®åœ°å€:https://github.com/silenceper/wechat\nç›®å‰å®ç°äº†æ¶ˆæ¯ç®¡ç†ï¼Œå¾®ä¿¡ç½‘é¡µæˆæƒï¼Œèœå•ç®¡ç†ï¼Œç´ æç®¡ç†å‡ ä¸ªæ¥å£ï¼Œçœ‹ä¸‹ä»–çš„åŸºæœ¬ä½¿ç”¨ï¼š\nä»¥ä¸‹æ˜¯ä¸€ä¸ªå¤„ç†æ¶ˆæ¯æ¥æ”¶ä»¥åŠå›å¤çš„ä¾‹å­ï¼š\n//é…ç½®å¾®ä¿¡å‚æ•° config := \u0026wechat.Config{ AppID: \"xxxx\", AppSecret: \"xxxx\", Token: \"xxxx\", EncodingAESKey: \"xxxx\", Cache: memCache } wc := wechat.NewWechat(config) // ä¼ å…¥requestå’ŒresponseWriter server := wc.GetServer(request, responseWriter) server.SetMessageHandler(func(msg message.MixMessage) *message.Reply { //å›å¤æ¶ˆæ¯ï¼šæ¼”ç¤ºå›å¤ç”¨æˆ·å‘é€çš„æ¶ˆæ¯ text := message.NewText(msg.Content) return \u0026message.Reply{message.MsgText, text} }) server.Serve() server.Send() "},"title":"å¼€æºé¡¹ç›®ï¼šwechat sdk"},"/blog/201611/tcp_connection_pool/":{"data":{"1é•¿æ—¶é—´ç©ºé—²è¿æ¥æ–­å¼€#1ã€é•¿æ—¶é—´ç©ºé—²ï¼Œè¿æ¥æ–­å¼€ï¼Ÿ":"å› ä¸ºç½‘ç»œç¯å¢ƒæ˜¯å¤æ‚çš„ï¼Œä¸­é—´å¯èƒ½å› ä¸ºé˜²ç«å¢™ç­‰åŸå› ï¼Œå¯¼è‡´é•¿æ—¶é—´ç©ºé—²çš„è¿æ¥ä¼šæ–­å¼€ï¼Œæ‰€ä»¥å¯ä»¥é€šè¿‡ä¸¤ä¸ªæ–¹æ³•æ¥è§£å†³ï¼š\nå®¢æˆ·ç«¯å¢åŠ å¿ƒè·³ï¼Œå®šæ—¶çš„ç»™æœåŠ¡ç«¯å‘é€è¯·æ±‚ ç»™è¿æ¥æ± ä¸­çš„è¿æ¥å¢åŠ æœ€å¤§ç©ºé—²æ—¶é—´ï¼Œè¶…æ—¶çš„è¿æ¥ä¸å†ä½¿ç”¨ åœ¨https://github.com/silenceper/poolå°±å¢åŠ äº†ä¸€ä¸ªè¿™æ ·æœ€å¤§ç©ºé—²æ—¶é—´çš„å‚æ•°ï¼Œåœ¨è¿æ¥åˆ›å»ºæˆ–è€…è¿æ¥è¢«é‡æ–°è¿”å›è¿æ¥æ± ä¸­æ—¶é‡ç½®ï¼Œç»™æ¯ä¸ªè¿æ¥éƒ½å¢åŠ äº†ä¸€ä¸ªè¿æ¥çš„åˆ›å»ºæ—¶é—´ï¼Œåœ¨å–å‡ºçš„æ—¶å€™å¯¹æ—¶é—´è¿›è¡Œæ¯”è¾ƒï¼šhttps://github.com/silenceper/pool/blob/master/channel.go#L85","2å½“æœåŠ¡ç«¯é‡å¯ä¹‹åè¿æ¥å¤±æ•ˆ#2ã€å½“æœåŠ¡ç«¯é‡å¯ä¹‹åï¼Œè¿æ¥å¤±æ•ˆï¼Ÿ":"è¿œç¨‹æœåŠ¡ç«¯å¾ˆæœ‰å¯èƒ½é‡å¯ï¼Œé‚£ä¹ˆä¹‹å‰åˆ›å»ºçš„é“¾æ¥å°±å¤±æ•ˆäº†ã€‚å®¢æˆ·ç«¯åœ¨ä½¿ç”¨çš„æ—¶å€™å°±éœ€è¦åˆ¤æ–­è¿™äº›å¤±æ•ˆçš„è¿æ¥å¹¶ä¸¢å¼ƒï¼Œåœ¨database/sqlä¸­å°±åˆ¤æ–­äº†è¿™äº›å¤±æ•ˆçš„è¿æ¥ï¼Œä½¿ç”¨è¿™ç§é”™è¯¯è¡¨ç¤ºvar ErrBadConn = errors.New(\"driver: bad connection\")\nå¦å¤–å€¼å¾—ä¸€æçš„å°±æ˜¯åœ¨database/sqlå¯¹è¿™ç§ErrBadConné”™è¯¯è¿›è¡Œäº†é‡è¯•ï¼Œé»˜è®¤é‡è¯•æ¬¡æ•°æ˜¯ä¸¤æ¬¡ï¼Œæ‰€ä»¥èƒ½å¤Ÿä¿è¯å³ä¾¿æ˜¯é“¾æ¥å¤±æ•ˆæˆ–è€…æ–­å¼€äº†ï¼Œæœ¬æ¬¡çš„è¯·æ±‚èƒ½å¤Ÿæ­£å¸¸å“åº”ï¼ˆç»§ç»­å¾€ä¸‹çœ‹å°±æ˜¯åˆ†æäº†ï¼‰ã€‚\nè¿æ¥å¤±æ•ˆçš„ç‰¹å¾\nå¯¹è¿æ¥è¿›è¡Œreadè¯»æ“ä½œæ—¶ï¼Œè¿”å›EOFé”™è¯¯ å¯¹è¿æ¥è¿›è¡Œwriteæ“ä½œæ—¶ï¼Œè¿”å›write tcp 127.0.0.1:52089-\u003e127.0.0.1:8002: write: broken pipeé”™è¯¯ ","databasesql-ä¸­çš„è¿æ¥æ± #database/sql ä¸­çš„è¿æ¥æ± ":"åœ¨database/sqlä¸­ä½¿ç”¨è¿æ¥è¿æ¥æ± å¾ˆç®€å•ï¼Œä¸»è¦æ¶‰åŠä¸‹é¢è¿™äº›é…ç½®ï¼š\ndb.SetMaxIdleConns(10) //è¿æ¥æ± ä¸­æœ€å¤§ç©ºé—²è¿æ¥æ•° db.SetMaxOpenConns(20) //æ‰“å¼€çš„æœ€å¤§è¿æ¥æ•° db.SetConnMaxLifetime(300*time.Second)//è¿æ¥çš„æœ€å¤§ç©ºé—²æ—¶é—´(å¯é€‰) æ³¨ï¼šå¦‚æœMaxIdleConnså¤§äº0å¹¶ä¸”MaxOpenConnså°äºMaxIdleConns ,é‚£ä¹ˆä¼šå°†MaxIdleConnsç½®ä¸ºMaxOpenConns\næ¥çœ‹ä¸‹dbè¿™ä¸ªç»“æ„ï¼Œä»¥åŠå­—æ®µç›¸å…³è¯´æ˜ï¼š\ntype DB struct { //å…·ä½“çš„æ•°æ®åº“å®ç°çš„interface{}, //ä¾‹å¦‚https://github.com/go-sql-driver/mysql å°±æ³¨å†Œå¹¶å¹¶å®ç°äº†driver.Openæ–¹æ³•ï¼Œä¸»è¦æ˜¯åœ¨é‡Œé¢å®ç°äº†ä¸€äº›é‰´æƒçš„æ“ä½œ driver driver.Driver //dsnè¿æ¥ dsn string //åœ¨prepared statementä¸­ç”¨åˆ° numClosed uint64 mu sync.Mutex // protects following fields //å¯ä½¿ç”¨çš„ç©ºé—²çš„é“¾æ¥ freeConn []*driverConn //ç”¨æ¥ä¼ é€’è¿æ¥è¯·æ±‚çš„ç®¡é“ connRequests []chan connRequest //å½“å‰æ‰“å¼€çš„è¿æ¥æ•° numOpen int //å½“éœ€è¦åˆ›å»ºæ–°çš„é“¾æ¥çš„æ—¶å€™ï¼Œå¾€è¿™ä¸ªç®¡é“ä¸­å‘é€ä¸€ä¸ªstructæ•°æ®ï¼Œ //å› ä¸ºåœ¨Openæ•°æ®åº“çš„å°±å¯ç”¨äº†ä¸€ä¸ªgoroutineæ‰§è¡ŒconnectionOpeneræ–¹æ³•è¯»å–ç®¡é“ä¸­çš„æ•°æ® openerCh chan struct{} //æ•°æ®åº“æ˜¯å¦å·²ç»è¢«å…³é—­ closed bool //ç”¨æ¥ä¿è¯é”è¢«æ­£ç¡®çš„å…³é—­ dep map[finalCloser]depSet //stacktrace of last conn's put; debug only lastPut map[*driverConn]string //æœ€å¤§ç©ºé—²è¿æ¥ maxIdle int //æœ€å¤§æ‰“å¼€çš„è¿æ¥ maxOpen int //è¿æ¥çš„æœ€å¤§ç©ºé—²æ—¶é—´ maxLifetime time.Duration //å®šæ—¶æ¸…ç†ç©ºé—²è¿æ¥çš„ç®¡é“ cleanerCh chan struct{} } çœ‹ä¸€ä¸ªæŸ¥è¯¢æ•°æ®åº“çš„ä¾‹å­ï¼š\nrows, err := db.Query(\"select * from table1\") åœ¨è°ƒç”¨db.Queryæ–¹æ³•å¦‚ä¸‹ï¼š\nfunc (db *DB) Query(query string, args ...interface{}) (*Rows, error) { var rows *Rows var err error //è¿™é‡Œå°±åšäº†å¯¹å¤±æ•ˆçš„é“¾æ¥çš„é‡è¯•æ“ä½œ for i := 0; i \u003c maxBadConnRetries; i++ { rows, err = db.query(query, args, cachedOrNewConn) if err != driver.ErrBadConn { break } } if err == driver.ErrBadConn { return db.query(query, args, alwaysNewConn) } return rows, err } åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ä¼šè¿”å›ï¼Œå¯ä»¥ä»è¿™é‡Œçœ‹åˆ°ï¼š readPackï¼ŒwritePack\nç»§ç»­è·Ÿè¿›å»å°±åˆ°äº†\nfunc (db *DB) conn(strategy connReuseStrategy) (*driverConn, error) { æ–¹æ³•ä¸»è¦æ˜¯åˆ›å»ºtcpè¿æ¥ï¼Œå¹¶åˆ¤æ–­äº†è¿æ¥çš„ç”Ÿå­˜æ—¶é—´lifetimeï¼Œä»¥åŠè¿æ¥æ•°çš„ä¸€äº›é™åˆ¶ï¼Œå¦‚æœè¶…è¿‡çš„è®¾å®šçš„æœ€å¤§æ‰“å¼€é“¾æ¥æ•°é™åˆ¶ç­‰å¾…connRequestç®¡é“ä¸­æœ‰è¿æ¥äº§ç”Ÿ(åœ¨putConné‡Šæ”¾é“¾æ¥çš„æ—¶å€™å°±ä¼šå¾€è¿™ä¸ªç®¡é“ä¸­å†™å…¥æ•°æ®)\nä½•æ—¶é‡Šæ”¾é“¾æ¥?\nå½“æˆ‘ä»¬è°ƒç”¨rows.Close()çš„æ—¶å€™ï¼Œå°±ä¼šæŠŠå½“å‰æ­£åœ¨ä½¿ç”¨çš„é“¾æ¥é‡æ–°æ”¾å›freeConnæˆ–è€…å†™å…¥åˆ°db.connRequestsç®¡é“ä¸­\n//putConnDBLocked æ–¹æ³• //å¦‚æœæœ‰db.connRequestsæœ‰åœ¨ç­‰å¾…è¿æ¥çš„è¯ï¼Œå°±æŠŠå½“å‰è¿æ¥ç»™å®ƒç”¨ if c := len(db.connRequests); c \u003e 0 { req := db.connRequests[0] // This copy is O(n) but in practice faster than a linked list. // TODO: consider compacting it down less often and // moving the base instead? copy(db.connRequests, db.connRequests[1:]) db.connRequests = db.connRequests[:c-1] if err == nil { dc.inUse = true } req \u003c- connRequest{ conn: dc, err: err, } return true } else if err == nil \u0026\u0026 !db.closed \u0026\u0026 db.maxIdleConnsLocked() \u003e len(db.freeConn) { //æ²¡äººéœ€è¦æˆ‘è¿™ä¸ªé“¾æ¥ï¼Œæˆ‘å°±æŠŠä»–é‡æ–°è¿”å›`freeConn`è¿æ¥æ± ä¸­ db.freeConn = append(db.freeConn, dc) db.startCleanerLocked() return true } ","ä¸ºä»€ä¹ˆéœ€è¦è¿æ¥æ± #ä¸ºä»€ä¹ˆéœ€è¦è¿æ¥æ± ":"ä»¥ä¸‹ä¸»è¦ä½¿ç”¨Golangä½œä¸ºç¼–ç¨‹è¯­è¨€\nä¸ºä»€ä¹ˆéœ€è¦è¿æ¥æ± æˆ‘è§‰å¾—ä½¿ç”¨è¿æ¥æ± æœ€å¤§çš„ä¸€ä¸ªå¥½å¤„å°±æ˜¯å‡å°‘è¿æ¥çš„åˆ›å»ºå’Œå…³é—­ï¼Œå¢åŠ ç³»ç»Ÿè´Ÿè½½èƒ½åŠ›ï¼Œ ä¹‹å‰å°±æœ‰é‡åˆ°ä¸€ä¸ªé—®é¢˜ï¼šTCP TIME_WAITè¿æ¥æ•°è¿‡å¤šå¯¼è‡´æœåŠ¡ä¸å¯ç”¨ï¼Œå› ä¸ºæœªå¼€å¯æ•°æ®åº“è¿æ¥æ± ï¼Œå†åŠ ä¸Šmysqlå¹¶å‘è¾ƒå¤§ï¼Œå¯¼è‡´éœ€è¦é¢‘ç¹çš„åˆ›å»ºé“¾æ¥ï¼Œæœ€ç»ˆäº§ç”Ÿäº†ä¸Šä¸‡çš„TIME_WAITçš„tcpé“¾æ¥ï¼Œå½±å“äº†ç³»ç»Ÿæ€§èƒ½ã€‚\né“¾æ¥æ± ä¸­çš„çš„åŠŸèƒ½ä¸»è¦æ˜¯ç®¡ç†ä¸€å †çš„é“¾æ¥ï¼ŒåŒ…æ‹¬åˆ›å»ºå’Œå…³é—­ï¼Œæ‰€ä»¥è‡ªå·±åœ¨fatih/poolåŸºç¡€ä¸Šï¼Œæ”¹é€ äº†ä¸€ä¸‹ï¼šhttps://github.com/silenceper/pool ï¼Œä½¿å¾—æ›´åŠ é€šç”¨ä¸€äº›ï¼Œå¢åŠ çš„ä¸€äº›åŠŸèƒ½ç‚¹å¦‚ä¸‹ï¼š\nè¿æ¥å¯¹è±¡ä¸å•å•æ˜¯net.Conn,å˜ä¸ºäº†interface{}ï¼ˆæ± ä¸­å­˜å‚¨è‡ªå·±æƒ³è¦çš„æ ¼å¼ï¼‰ å¢åŠ äº†é“¾æ¥çš„æœ€å¤§ç©ºé—²æ—¶é—´ï¼ˆä¿è¯äº†å½“è¿æ¥ç©ºé—²å¤ªä¹…ï¼Œé“¾æ¥å¤±æ•ˆçš„é—®é¢˜ï¼‰ ä¸»è¦æ˜¯ç”¨åˆ°äº†channelæ¥ç®¡ç†è¿æ¥ï¼Œå¹¶ä¸”èƒ½å¤Ÿå¾ˆå¥½çš„åˆ©ç”¨ç®¡é“çš„é¡ºåºæ€§ï¼Œå½“éœ€è¦ä½¿ç”¨çš„æ—¶å€™Getä¸€ä¸ªè¿æ¥ï¼Œä½¿ç”¨å®Œæ¯•ä¹‹åPutæ”¾å›channelä¸­ã€‚","ä½¿ç”¨è¿æ¥æ± ç®¡ç†thrifté“¾æ¥#ä½¿ç”¨è¿æ¥æ± ç®¡ç†Thrifté“¾æ¥":"è¿™é‡Œæ˜¯ä½¿ç”¨è¿æ¥æ± https://github.com/silenceper/poolï¼Œå¦‚ä½•æ„å»ºä¸€ä¸ªthrifté“¾æ¥\nå®¢æˆ·ç«¯åˆ›å»ºThriftçš„ä»£ç ï¼š\ntype Client struct { *user.UserClient } //åˆ›å»ºThriftå®¢æˆ·ç«¯é“¾æ¥çš„æ–¹æ³• factory := func() (interface{}, error) { protocolFactory := thrift.NewTBinaryProtocolFactoryDefault() transportFactory := thrift.NewTTransportFactory() var transport thrift.TTransport var err error transport, err = thrift.NewTSocket(rpcConfig.Listen) if err != nil { panic(err) } transport = transportFactory.GetTransport(transport) //defer transport.Close() if err := transport.Open(); err != nil { panic(err) } rpcClient := user.NewUserClientFactory(transport, protocolFactory) //åœ¨è¿æ¥æ± ä¸­ç›´æ¥æ”¾ç½®Clientå¯¹è±¡ return \u0026Client{UserClient: rpcClient}, nil } //å…³é—­è¿æ¥çš„æ–¹æ³• close := func(v interface{}) error { v.(*Client).Transport.Close() return nil } //åˆ›å»ºäº†ä¸€ä¸ª åˆå§‹åŒ–è¿æ¥æ˜¯ poolConfig := \u0026pool.PoolConfig{ InitialCap: 10, MaxCap: 20, Factory: factory, Close: close, IdleTimeout: 300 * time.Second, } p, err := pool.NewChannelPool(poolConfig) if err != nil { panic(err) } //å–å¾—é“¾æ¥ conn, err := p.Get() if err != nil { return nil, err } v, ok := conn.(*Client) ...ä½¿ç”¨è¿æ¥è°ƒç”¨è¿œç¨‹æ–¹æ³• //å°†è¿æ¥é‡æ–°æ”¾å›è¿æ¥æ± ä¸­ p.Put(conn) å†™å®Œï¼Œå¬è§å¤–é¢çš„ğŸ“å¼€å§‹æ‰“é¸£äº†ã€‚","è¿æ¥å¤±æ•ˆé—®é¢˜#è¿æ¥å¤±æ•ˆé—®é¢˜":"ä½¿ç”¨è¿æ¥æ± ä¹‹åå°±ä¸å†æ˜¯çŸ­è¿æ¥ï¼Œè€Œæ˜¯é•¿è¿æ¥äº†ï¼Œå°±å¼•å‘äº†ä¸€äº›é—®é¢˜ï¼š"},"title":"èŠèŠè¿æ¥æ± "},"/blog/201809/flannel-in-k8s/":{"data":{"cniæ’ä»¶æ–¹å¼#CNIæ’ä»¶æ–¹å¼":"è¿™ç§æ–¹å¼æ˜¯åˆ©ç”¨cniæ’ä»¶ï¼Œå¹¶ä¸”å°†ç½‘ç»œé…ç½®ä¿¡æ¯å­˜å‚¨åœ¨kubernetes apiä¸­ï¼š\né…ç½®ç½‘æ®µ åœ¨kube-controller-managerå¯åŠ¨è„šæœ¬ä¸­åŠ å…¥--allocate-node-cidrs=trueï¼Œ--cluster-cidr=10.244.0.0/16 å‚æ•°ã€‚\n10.244.0.0/16ä¸ºæˆ‘ä»¬æŒ‡å®šçš„é›†ç¾¤çš„ç½‘æ®µï¼Œè¿™æ ·æ¯ä¸€ä¸ªdockerèŠ‚ç‚¹éƒ½ä¼šåˆ†åˆ«ä½¿ç”¨è‡ªç½‘æ®µ10.244.0.0/24ï¼Œ10.244.1.0/24ä½œä¸ºæ¯ä¸ªpodçš„ç½‘æ®µï¼Œå¯ä»¥é€šè¿‡kubectl get pod 192.168.99.101 -o yamlå‘½ä»¤æŸ¥çœ‹spec.podCIDRå­—æ®µã€‚\nå¦‚æœä¸é…ç½®è¯¥æ­¥éª¤å¯èƒ½ä¼šflannelå‡ºç°error registering network: failed to acquire lease: node \"192.168.99.101\" podçš„é”™è¯¯\næŒ‡å®škubletç½‘ç»œæ’ä»¶ åœ¨kubeletä¸­æŒ‡å®šä¸‰ä¸ªå‚æ•°\n--network-plugin=cni : ç½‘ç»œæ’ä»¶ä½¿ç”¨cni --cni-conf-dir=/etc/cni/net.d cnié…ç½®æ–‡ä»¶ ï¼Œé»˜è®¤ --cni-bin-dir=/opt/cni/bin cniå¯æ‰§è¡Œæ–‡ä»¶ï¼Œé»˜è®¤ è¿™æ ·åœ¨kubletå¯åŠ¨çš„æ—¶å€™ï¼Œå°±ä¼šå»/etc/cni/net.dç›®å½•æŸ¥æ‰¾é…ç½®æ–‡ä»¶ï¼Œå¹¶è§£æï¼Œä½¿ç”¨ç›¸åº”çš„æ’ä»¶é…ç½®ç½‘ç»œ\nä¸‹è½½cniä¾èµ–æ’ä»¶ ä¸‹è½½cniå®˜æ–¹æä¾›çš„ç»„ä»¶ï¼šcni-plugins-amd64-v0.7.1.tgz ï¼Œå¹¶å°†å¯æ‰§è¡Œæ–‡ä»¶æ”¾åœ¨/opt/cni/binç›®å½•ã€‚\nè¿™é‡Œä¸å•å•åªä¼šç”¨åˆ°flannelæ–‡ä»¶ï¼Œä¹Ÿä¼šç”¨åˆ°brageç”¨æ¥åˆ›å»ºç½‘æ¡¥ä»¥åŠhost-localç”¨æ¥åˆ†é…ip\nå®‰è£…flanneldç»„ä»¶ flannelç»„ä»¶ç›´æ¥ä»¥daemonsetçš„æ–¹å¼å®‰è£…åœ¨k8sé›†ç¾¤ä¸­ï¼š\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml å…¶ä¸­kube-flannel-cfgconfigmapä¸­çš„Networkå­—æ®µéœ€è¦ä¸--cluster-cidré…ç½®çš„ç½‘æ®µä¸€è‡´ã€‚\nè¿™ä¸€æ­¥ä¸»è¦æ˜¯å®‰è£…äº†flanneldä»¥åŠå°†flannelé…ç½®æ–‡ä»¶å†™å…¥/etc/cni/net.dç›®å½•\næŸ¥çœ‹kube-flannel.ymlä¸­flanneldçš„å¯åŠ¨å‚æ•°ä¸ºï¼š\n--ip-masq : éœ€è¦ä¸ºå…¶é…ç½®SNAT --kube-subnet-mgr : ä»£è¡¨å…¶ä½¿ç”¨kubeç±»å‹çš„subnet-managerã€‚è¯¥ç±»å‹æœ‰åˆ«äºä½¿ç”¨etcdçš„local-subnet-mgrç±»å‹ï¼Œä½¿ç”¨kubeç±»å‹åï¼Œflannelä¸Šå„Nodeçš„IPå­ç½‘åˆ†é…å‡åŸºäºK8S Nodeçš„spec.podCIDRå±æ€§ æˆ‘çš„æ˜¯å¤šç½‘å¡çš„æœºå™¨ï¼Œå‘ç°ç½‘ç»œä¸é€šï¼Œæ‰€ä»¥æˆ‘ç‰¹åˆ«æŒ‡å®šçš„flanneldç”¨æ¥å¯¹å¤–é€šä¿¡çš„ç½‘å¡ å¢åŠ â€“iface å‚æ•°ï¼ŒæŒ‡å®šå¯ä»¥è¿›è¡Œå¤–éƒ¨é€šä¿¡çš„ç½‘å¡","etcd-æ–¹å¼#ETCD æ–¹å¼":"è¿™ç§æ–¹å¼åœ¨å‰é¢çš„k8sé›†ç¾¤å®‰è£…-å®‰è£…Flannelç½‘ç»œæ’ä»¶å·²ç»ä»‹ç»è¿‡ï¼Œå°±æ˜¯åˆ©ç”¨etcdå­˜å‚¨ç½‘ç»œé…ç½®ä¿¡æ¯ï¼Œå¹¶ä¸”åˆ©ç”¨dockerdå¯åŠ¨å‚æ•°--bipæ¥æŒ‡å®šæ¯ä¸ªèŠ‚ç‚¹çš„ç½‘æ®µä¿¡æ¯ï¼Œæˆ‘ä»¬æŒ‡å®švxlanä½œä¸ºæ•°æ®ä¼ è¾“çš„backendã€‚","flannel-backend#Flannel backend":" Host-gw: åŒä¸€ç½‘æ®µç›´æ¥é€šä¿¡ï¼Œé€Ÿåº¦å¿« udpï¼š ç”¨æˆ·ç©ºé—´çš„udpå°è£… vxlan: åˆ©ç”¨å†…æ ¸vxlanåè®®è¿›è¡Œä¼ è¾“ aws vpc: åˆ©ç”¨awså¹³å°å†…éƒ¨æä¾›çš„åŠŸèƒ½è¿›è¡Œä¼ è¾“ æ›´å¤šæ’ä»¶å‚è€ƒæ–‡æ¡£ï¼šhttps://github.com/coreos/flannel/blob/master/Documentation/backends.md\nå¦‚ä½•é€‰æ‹©ï¼Ÿ\nvxlanåœ¨åŠŸèƒ½ä¸Šï¼Œå’Œæ€§èƒ½ä¸ŠåŸºæœ¬æ»¡è¶³æˆ‘ä»¬çš„è¦æ±‚ï¼Œå¯ä»¥ç›´æ¥è·¨ç½‘æ®µé—´é€šä¿¡ï¼ŒåŒæ—¶æ€§èƒ½ä¸Šåˆæ¯”udpçš„æ–¹å¼é«˜æ•ˆ","åŒºåˆ«#åŒºåˆ«":" flanneld å®¹å™¨åŒ–äº† flanneld ç½‘æ®µä¿¡æ¯æ¥æºäºkubernetes apiï¼Œè€Œä¸ä¾èµ–etcd ","åŸç†#åŸç†":"ä»¥ä¸Šä¸¤ç§æ–¹å¼çš„å¯¹æ¯”å¯ä»¥å‘ç°ï¼Œé€šè¿‡cniæ–¹å¼å®‰è£…çš„flannelä¼šå¤šä¸€ä¸ªcni0çš„ç½‘æ¡¥ï¼Œå…¶å®è¿™ä¸ªä¸docker0ç½‘æ¡¥çš„ä½œç”¨æ˜¯ä¸€æ ·çš„ï¼Œåˆ›å»ºäº†ä¸€å¯¹veth pair åˆ†åˆ«è”é€šå®¹å™¨å†…éƒ¨ä¸ä¸»æœºç½‘ç»œï¼Œå¹¶æŠŠå…¶ä¸­ä¸€ç«¯æ¥å…¥cni0ç½‘æ¡¥ã€‚\næ•´ä¸ªé€šä¿¡è¿‡ç¨‹å¦‚å›¾ï¼š\nå›¾ä¸­çš„ipä¿¡æ¯ä¸æœ¬æœºä¸ä¸€è‡´ï¼Œä¸»è¦è¯´æ˜é€šä¿¡è¿‡ç¨‹\nå®¹å™¨å†…éƒ¨-\u003edocker0-\u003eflanneld-\u003eç½‘ç»œä¼ è¾“-\u003eå¯¹ç«¯flanneld-\u003eå¯¹ç«¯docker0-\u003eå¯¹ç«¯å®¹å™¨å†…\nå½“æ•°æ®åŒ…åˆ°å§flanneldåæ”¯æŒå¤šç§backendè¿›è¡Œè½¬å‘","å®‰è£…#å®‰è£…":"Flannelæ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºk8så®šåˆ¶çš„ç½‘ç»œè§£å†³æ–¹æ¡ˆï¼Œä¸»è¦è§£å†³PODè·¨ä¸»æœºé€šä¿¡é—®é¢˜ï¼Œè¿™é‡Œä¸»è¦è®²è¿°Flannelæ˜¯å¦‚ä½•å®ç°çš„ã€‚\nå®‰è£…é›†æˆåœ¨k8sä¸Šæœ‰ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ˜¯åˆ©ç”¨etcdå­˜å‚¨æ•´ä¸ªé›†ç¾¤çš„ç½‘ç»œé…ç½®ï¼Œå¦å¤–ä¸€ç§æ˜¯åˆ©ç”¨kubernetesçš„api è·å–ç½‘ç»œé…ç½®ä¿¡æ¯ï¼Œåˆ†åˆ«å¦‚ä¸‹ï¼š"},"title":"k8sç½‘ç»œç»„ä»¶ï¼šflannel"},"/blog/201809/how-to-build-a-k8s-cluster/":{"data":{"dockerå®‰è£…#Dockerå®‰è£…":"ä¸‹è½½å¹¶å®‰è£…ï¼š\nwget -c https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-17.12.1.ce-1.el7.centos.x86_64.rpm yum install docker-ce-17.12.1.ce-1.el7.centos.x86_64.rpm åœ¨/usr/lib/systemd/system/docker.serviceæ–‡ä»¶ä¸­å¢åŠ ä¸€ä¸ªç¯å¢ƒå˜é‡ï¼š\nEnvironmentFile=-/run/flannel/docker å¹¶ä¸”å¯åŠ¨å‘½ä»¤ä¸ºï¼Œä¸»è¦æ˜¯å¢åŠ äº†ä¸€ä¸ª$DOCKER_NETWORK_OPTIONSå‚æ•°æ˜¯flannelä¼ å…¥çš„ç”¨æ¥ä¿®æ”¹docker0ç½‘æ¡¥IP\nExecStart=/usr/bin/dockerd $DOCKER_NETWORK_OPTIONS --log-driver=json-file --log-opt max-size=50m --log-opt max-file=5 å¯åŠ¨ï¼š\nsystemctl daemon-reload systemctl enable docker systemctl start docker systemctl status docker ","etcdå®‰è£…#Etcdå®‰è£…":"æˆ‘è¿™é‡Œä¸ºäº†ç®€å•ï¼ŒETCDèŠ‚ç‚¹åªç”¨äº†ä¸€ä¸ªï¼Œå¹¶ä¸”å®‰è£…åœ¨äº†masterèŠ‚ç‚¹ä¸Šï¼Œå¤šä¸ªä¹Ÿæ˜¯ä¸€æ ·çš„ï¼Œåªæ˜¯åœ¨--initial-clusteré€‰æ‹©ä¸­å°†å…¶ä»–èŠ‚ç‚¹ipå¡«å…¥è¿›å»ã€‚\nä¸‹è½½ETCD:\n$ wget -c https://github.com/coreos/etcd/releases/download/v3.1.10/etcd-v3.1.10-linux-amd64.tar.gz $ tar -zxvf etcd-v3.1.10-linux-amd64.tar.gz $ mv etcd-v3.1.10-linux-amd64/etcd* /usr/local/bin åˆ›å»º etcd çš„ systemd unit æ–‡ä»¶\nvim /usr/lib/systemd/system/etcd.service å†…å®¹å¦‚ä¸‹ï¼š\n[Unit] Description=Etcd Server After=network.target After=network-online.target Wants=network-online.target Documentation=https://github.com/coreos [Service] Type=notify WorkingDirectory=/var/lib/etcd/ EnvironmentFile=-/etc/etcd/etcd.conf ExecStart=/usr/local/bin/etcd \\ --name ${ETCD_NAME} \\ --cert-file=/etc/kubernetes/ssl/kubernetes.pem \\ --key-file=/etc/kubernetes/ssl/kubernetes-key.pem \\ --peer-cert-file=/etc/kubernetes/ssl/kubernetes.pem \\ --peer-key-file=/etc/kubernetes/ssl/kubernetes-key.pem \\ --trusted-ca-file=/etc/kubernetes/ssl/ca.pem \\ --peer-trusted-ca-file=/etc/kubernetes/ssl/ca.pem \\ --initial-advertise-peer-urls ${ETCD_INITIAL_ADVERTISE_PEER_URLS} \\ --listen-peer-urls ${ETCD_LISTEN_PEER_URLS} \\ --listen-client-urls ${ETCD_LISTEN_CLIENT_URLS},http://127.0.0.1:2379 \\ --advertise-client-urls ${ETCD_ADVERTISE_CLIENT_URLS} \\ --initial-cluster-token ${ETCD_INITIAL_CLUSTER_TOKEN} \\ --initial-cluster infra1=https://192.168.99.101:2380 \\ --initial-cluster-state new \\ --data-dir=${ETCD_DATA_DIR} Restart=on-failure RestartSec=5 LimitNOFILE=65536 [Install] WantedBy=multi-user.target åˆ›å»º/etc/etcd/etcd.confæ–‡ä»¶:\n# [member] ETCD_NAME=infra1 ETCD_DATA_DIR=\"/var/lib/etcd\" ETCD_LISTEN_PEER_URLS=\"https://192.168.99.101:2380\" ETCD_LISTEN_CLIENT_URLS=\"https://192.168.99.101:2379\" #[cluster] ETCD_INITIAL_ADVERTISE_PEER_URLS=\"https://192.168.99.101:2380\" ETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster\" ETCD_ADVERTISE_CLIENT_URLS=\"https://192.168.99.101:2379\" å¯åŠ¨æœåŠ¡ï¼š\nmv etcd.service /usr/lib/systemd/system/ mkdir /var/lib/etcd systemctl daemon-reload systemctl enable etcd systemctl start etcd systemctl status etcd éªŒè¯æœåŠ¡ï¼š\netcdctl --ca-file=/etc/kubernetes/ssl/ca.pem --cert-file=/etc/kubernetes/ssl/kubernetes.pem --key-file=/etc/kubernetes/ssl/kubernetes-key.pem cluster-health 2018-09-07 15:41:30.782777 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated 2018-09-07 15:41:30.783295 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated member 171ef35542ebf92b is healthy: got healthy result from https://192.168.99.101:2379 cluster is healthy cluster is healthy è¡¨ç¤ºæˆåŠŸã€‚","masterèŠ‚ç‚¹éƒ¨ç½²#MasterèŠ‚ç‚¹éƒ¨ç½²":"masterèŠ‚ç‚¹ä¸Šä¸»è¦æ˜¯ä¸‰ä¸ªç»„ä»¶ï¼š\nkube-apiserver kube-scheduler kube-controller-manager åŒäº‹åªèƒ½åˆä¸€ä¸ªkube-scheduler,kube-controller-managerè¿›ç¨‹å¤„äºå·¥ä½œçŠ¶æ€ï¼Œå¦‚æœè¿è¡Œå¤šä¸ªï¼Œåˆ™éœ€è¦é€šè¿‡é€‰ä¸¾äº§ç”Ÿä¸€ä¸ªleaderã€‚\nä¸‹è½½serveråŒ…ï¼š\nwget -c https://dl.k8s.io/v1.10.7/kubernetes-server-linux-amd64.tar.gz tar -xzvf kubernetes-server-linux-amd64.tar.gz cd kubernetes tar -xzvf kubernetes-src.tar.gz å°†äºŒè¿›åˆ¶æ–‡ä»¶æ‹·è´åˆ°æŒ‡å®šè·¯å¾„\ncp -r server/bin/{kube-apiserver,kube-controller-manager,kube-scheduler} /usr/local/bin/ åŒæ—¶å°† server/bin/ç›®å½•ä¸‹çš„kube-proxy,kubelet ä¸‰ä¸ªæ–‡ä»¶å¤åˆ¶åˆ°nodeèŠ‚ç‚¹çš„ /usr/local/bin/ ç›®å½•","nodeèŠ‚ç‚¹éƒ¨ç½²#NodeèŠ‚ç‚¹éƒ¨ç½²":"kube-proxyï¼Œkubelet æ–‡ä»¶åœ¨kubernetes-server-linux-amd64.tar.gzï¼Œå¤åˆ¶åˆ°/usr/local/binç›®å½•","åˆ†å‘kubeconfigæ–‡ä»¶#åˆ†å‘kubeconfigæ–‡ä»¶":"å°†ä¸¤ä¸ª kubeconfig æ–‡ä»¶åˆ†å‘åˆ°æ‰€æœ‰ Node æœºå™¨çš„ /etc/kubernetes/ ç›®å½•\ncp bootstrap.kubeconfig kube-proxy.kubeconfig /etc/kubernetes/ ","åˆ†å‘è¯ä¹¦#åˆ†å‘è¯ä¹¦":"å°†ç”Ÿæˆçš„è¯ä¹¦å’Œç§˜é’¥æ–‡ä»¶ï¼ˆåç¼€ä¸º.pemï¼‰æ‹·è´åˆ°æ‰€æœ‰æœºå™¨çš„/etc/kubernetes/ssl ç›®å½•ä¸‹\nå‘½ä»¤ç•¥","åˆ›å»º-kube-proxy-kubeconfig-æ–‡ä»¶#åˆ›å»º kube-proxy kubeconfig æ–‡ä»¶":" export KUBE_APISERVER=\"https://192.168.99.101:6443\" # è®¾ç½®é›†ç¾¤å‚æ•° kubectl config set-cluster kubernetes \\ --certificate-authority=/etc/kubernetes/ssl/ca.pem \\ --embed-certs=true \\ --server=${KUBE_APISERVER} \\ --kubeconfig=kube-proxy.kubeconfig # è®¾ç½®å®¢æˆ·ç«¯è®¤è¯å‚æ•° kubectl config set-credentials kube-proxy \\ --client-certificate=/etc/kubernetes/ssl/kube-proxy.pem \\ --client-key=/etc/kubernetes/ssl/kube-proxy-key.pem \\ --embed-certs=true \\ --kubeconfig=kube-proxy.kubeconfig # è®¾ç½®ä¸Šä¸‹æ–‡å‚æ•° kubectl config set-context default \\ --cluster=kubernetes \\ --user=kube-proxy \\ --kubeconfig=kube-proxy.kubeconfig # è®¾ç½®é»˜è®¤ä¸Šä¸‹æ–‡ kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig ","åˆ›å»º-kubeconfig-æ–‡ä»¶#åˆ›å»º kubeconfig æ–‡ä»¶":"","åˆ›å»º-kubectl-kubeconfig-æ–‡ä»¶#åˆ›å»º kubectl kubeconfig æ–‡ä»¶":" export KUBE_APISERVER=\"https://192.168.99.101:6443\" # è®¾ç½®é›†ç¾¤å‚æ•° kubectl config set-cluster kubernetes \\ --certificate-authority=/etc/kubernetes/ssl/ca.pem \\ --embed-certs=true \\ --server=${KUBE_APISERVER} # è®¾ç½®å®¢æˆ·ç«¯è®¤è¯å‚æ•° kubectl config set-credentials admin \\ --client-certificate=/etc/kubernetes/ssl/admin.pem \\ --embed-certs=true \\ --client-key=/etc/kubernetes/ssl/admin-key.pem # è®¾ç½®ä¸Šä¸‹æ–‡å‚æ•° kubectl config set-context kubernetes \\ --cluster=kubernetes \\ --user=admin # è®¾ç½®é»˜è®¤ä¸Šä¸‹æ–‡ kubectl config use-context kubernetes admin è¯ä¹¦ä¸­è®¾å®šäº† group=system:masterså³ï¼ˆO=system:mastersï¼‰ è¿™ä¸ªgroupä¸ckuster-admin ClusterRoleç»‘å®šï¼Œæ‰€ä»¥å…·æœ‰æ•´ä¸ªé›†ç¾¤çš„æƒé™ å¦‚æœéœ€è¦å•ç‹¬æŒ‡å®šæƒé™ï¼Œåˆ™å¯ä»¥è‡ªå·±è®¾å®šuserç»‘å®šClusterRole","åˆ›å»º-kubelet-bootstrapping-kubeconfig-æ–‡ä»¶#åˆ›å»º kubelet bootstrapping kubeconfig æ–‡ä»¶":" cd /etc/kubernetes export KUBE_APISERVER=\"https://192.168.99.101:6443\" # è®¾ç½®é›†ç¾¤å‚æ•° kubectl config set-cluster kubernetes \\ --certificate-authority=/etc/kubernetes/ssl/ca.pem \\ --embed-certs=true \\ --server=${KUBE_APISERVER} \\ --kubeconfig=bootstrap.kubeconfig # è®¾ç½®å®¢æˆ·ç«¯è®¤è¯å‚æ•° kubectl config set-credentials kubelet-bootstrap \\ --token=${BOOTSTRAP_TOKEN} \\ --kubeconfig=bootstrap.kubeconfig # è®¾ç½®ä¸Šä¸‹æ–‡å‚æ•° kubectl config set-context default \\ --cluster=kubernetes \\ --user=kubelet-bootstrap \\ --kubeconfig=bootstrap.kubeconfig # è®¾ç½®é»˜è®¤ä¸Šä¸‹æ–‡ kubectl config use-context default --kubeconfig=bootstrap.kubeconfig ","åˆ›å»º-tls-bootstrapping-token#åˆ›å»º TLS Bootstrapping Token":" $ export BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d ' ') $ cat \u003e token.csv \u003c\u003cEOF ${BOOTSTRAP_TOKEN},kubelet-bootstrap,10001,\"system:kubelet-bootstrap\" EOF $ cp token.csv /etc/kubernetes/ ","åˆ›å»ºadminè¯ä¹¦#åˆ›å»ºadminè¯ä¹¦":"åˆ›å»º admin-csr.jsonæ–‡ä»¶ï¼š\n{ \"CN\": \"admin\", \"hosts\": [], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"BeiJing\", \"L\": \"BeiJing\", \"O\": \"system:masters\", \"OU\": \"System\" } ] } ç”Ÿæˆè¯ä¹¦\n[root@localhost ssl]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare admin ","åˆ›å»ºcaè¯ä¹¦#åˆ›å»ºcaè¯ä¹¦":"åˆ›å»º ca-config.jsonæ–‡ä»¶ï¼š\n{ \"signing\": { \"default\": { \"expiry\": \"87600h\" }, \"profiles\": { \"kubernetes\": { \"usages\": [ \"signing\", \"key encipherment\", \"server auth\", \"client auth\" ], \"expiry\": \"87600h\" } } } } åˆ›å»º ca-csr.jsonæ–‡ä»¶ï¼š\n{ \"CN\": \"kubernetes\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"BeiJing\", \"L\": \"BeiJing\", \"O\": \"k8s\", \"OU\": \"System\" } ], \"ca\": { \"expiry\": \"87600h\" } } ç”Ÿæˆcaè¯ä¹¦å’Œç§é’¥\ncfssl gencert -initca ca-csr.json | cfssljson -bare ca ","åˆ›å»ºkube-proxyè¯ä¹¦#åˆ›å»ºkube-proxyè¯ä¹¦":"åˆ›å»ºkube-proxy-csr.jsonæ–‡ä»¶ï¼š\n{ \"CN\": \"system:kube-proxy\", \"hosts\": [], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"BeiJing\", \"L\": \"BeiJing\", \"O\": \"k8s\", \"OU\": \"System\" } ] } ç”Ÿæˆå‘½ä»¤ï¼š\n[root@localhost ssl]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy ","å®‰è£…flannelç½‘ç»œæ’ä»¶#å®‰è£…Flannelç½‘ç»œæ’ä»¶":"Flannelç½‘ç»œæ’ä»¶åªéœ€è¦å®‰è£…åœ¨nodeèŠ‚ç‚¹ä¸Šå°±å¥½äº†ï¼Œä»–ä¸»è¦ä½œç”¨æ˜¯å°†ä¸åŒnodeä¸Šçš„podç½‘ç»œè”é€šï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨102è¿™å°æœºå™¨ä¸Šæ“ä½œï¼š\nä½¿ç”¨yumç›´æ¥å®‰è£…:\nyum install -y flannel åˆ›å»º /usr/lib/systemd/system/flanneld.serviceæ–‡ä»¶ï¼š\n[Unit] Description=Flanneld overlay address etcd agent After=network.target After=network-online.target Wants=network-online.target After=etcd.service Before=docker.service [Service] Type=notify EnvironmentFile=/etc/sysconfig/flanneld EnvironmentFile=-/etc/sysconfig/docker-network ExecStart=/usr/bin/flanneld-start \\ -etcd-endpoints=${FLANNEL_ETCD_ENDPOINTS} \\ -etcd-prefix=${FLANNEL_ETCD_PREFIX} \\ $FLANNEL_OPTIONS ExecStartPost=/usr/libexec/flannel/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/docker Restart=on-failure [Install] WantedBy=multi-user.target RequiredBy=docker.service /etc/sysconfig/flanneldæ–‡ä»¶ï¼š\n# Flanneld configuration options # etcd url location. Point this to the server where etcd runs FLANNEL_ETCD_ENDPOINTS=\"https://192.168.99.101:2379\" # etcd config key. This is the configuration key that flannel queries # For address range assignment FLANNEL_ETCD_PREFIX=\"/kube-centos/network\" # Any additional options that you want to pass FLANNEL_OPTIONS=\"-etcd-cafile=/etc/kubernetes/ssl/ca.pem -etcd-certfile=/etc/kubernetes/ssl/kubernetes.pem -etcd-keyfile=/etc/kubernetes/ssl/kubernetes-key.pem\" åœ¨etcdä¸­åˆ›å»ºç½‘ç»œé…ç½®ï¼Œåœ¨masterèŠ‚ç‚¹ä¸Šæ“ä½œå°±å¥½äº†ï¼Œçœå¾—æŒ‡å®šendpoints:\n$ etcdctl --ca-file=/etc/kubernetes/ssl/ca.pem --cert-file=/etc/kubernetes/ssl/kubernetes.pem --key-file=/etc/kubernetes/ssl/kubernetes-key.pem mkdir /kube-centos/network $ etcdctl --ca-file=/etc/kubernetes/ssl/ca.pem --cert-file=/etc/kubernetes/ssl/kubernetes.pem --key-file=/etc/kubernetes/ssl/kubernetes-key.pem mk /kube-centos/network/config '{\"Network\":\"172.30.0.0/16\",\"SubnetLen\":24,\"Backend\":{\"Type\":\"vxlan\"}}' å¯åŠ¨flannel\nsystemctl daemon-reload systemctl enable flanneld systemctl start flanneld systemctl status flanneld ","å®‰è£…kubectlæ–‡ä»¶#å®‰è£…kubectlæ–‡ä»¶":" wget -c https://dl.k8s.io/v1.10.7/kubernetes-client-darwin-386.tar.gz tar -xzvf kubernetes-client-linux-amd64.tar.gz cp kubernetes/client/bin/kube* /usr/bin/ chmod a+x /usr/bin/kube* ","å®‰è£…kubednsæ’ä»¶#å®‰è£…kubednsæ’ä»¶":"kubedns ä¸ºæˆ‘ä»¬æä¾›äº†æœåŠ¡å‘ç°çš„åŠŸèƒ½ã€‚\nyamlæ–‡ä»¶é€šè¿‡è¿™é‡Œä¸‹è½½ï¼š\nhttps://github.com/silenceper/k8s-install/tree/master/kube-dns åœ¨masterä¸Šæ‰§è¡Œï¼š\nkubectl create -f .\nè‡³æ­¤ï¼Œk8så°±æ­å»ºå®Œæˆäº†ï¼\nå‚è€ƒèµ„æ–™ï¼š\nhttps://jimmysong.io/kubernetes-handbook/practice/install-kubernetes-on-centos.html","å®‰è£…é…ç½®kubelet#å®‰è£…é…ç½®kubelet":" å‰æï¼šå…³é—­swapï¼Œå¦åˆ™æ— æ³•å¯åŠ¨ ä½¿ç”¨:swapoff -aæˆ–è€…æ³¨é‡Šfstabä¸­swapé…ç½®\nTIPS: ç°åœ¨masterèŠ‚ç‚¹ä¸Šï¼Œèµ‹äºˆkubelet-bootstrapç”¨æˆ·ï¼Œsystem:node-bootstrapper cluster è§’è‰²ï¼Œå¦åˆ™kubeletæ²¡æœ‰æƒé™åˆ›å»ºè®¤è¯è¯·æ±‚ã€‚\ncd /etc/kubernetes kubectl create clusterrolebinding kubelet-bootstrap \\ --clusterrole=system:node-bootstrapper \\ --user=kubelet-bootstrap æ–‡ä»¶/usr/lib/systemd/system/kubelet.serviceï¼š\n[Unit] Description=Kubernetes Kubelet Server Documentation=https://github.com/GoogleCloudPlatform/kubernetes After=docker.service Requires=docker.service [Service] WorkingDirectory=/var/lib/kubelet EnvironmentFile=-/etc/kubernetes/config EnvironmentFile=-/etc/kubernetes/kubelet ExecStart=/usr/local/bin/kubelet \\ $KUBE_LOGTOSTDERR \\ $KUBE_LOG_LEVEL \\ $KUBELET_ADDRESS \\ $KUBELET_HOSTNAME \\ $KUBE_ALLOW_PRIV \\ $KUBELET_ARGS Restart=on-failure [Install] WantedBy=multi-user.target åŒæ—¶é…ç½®/etc/kubernetes/kubeletæ–‡ä»¶ï¼š\n### ## kubernetes kubelet (minion) config # ## The address for the info server to serve on (set to 0.0.0.0 or \"\" for all interfaces) KUBELET_ADDRESS=\"--address=192.168.99.102\" # ## You may leave this blank to use the actual hostname KUBELET_HOSTNAME=\"--hostname-override=192.168.99.102\" KUBELET_ARGS=\"--bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig --kubeconfig=/etc/kubernetes/kubelet.kubeconfig --cert-dir=/etc/kubernetes/ssl --cluster-domain=cluster.local --hairpin-mode promiscuous-bridge --serialize-image-pulls=false\" å¯åŠ¨ï¼š\nmkdir /varlib/kubelet systemctl daemon-reload systemctl enable kubelet systemctl start kubelet systemctl status kubelet é€šè¿‡kubletçš„TLSè¯ä¹¦è¯·æ±‚ [root@localhost kubernetes]# kubectl get csr NAME AGE REQUESTOR CONDITION node-csr-vtB-rALjRudPIp4IvIHwOTOggoJC-213GpvDoYVqQlA 18s kubelet-bootstrap Pending é€šè¿‡ CSR è¯·æ±‚:\n[root@localhost kubernetes]# kubectl certificate approve node-csr-vtB-rALjRudPIp4IvIHwOTOggoJC-213GpvDoYVqQlA certificatesigningrequest.certificates.k8s.io \"node-csr-vtB-rALjRudPIp4IvIHwOTOggoJC-213GpvDoYVqQlA\" approved ","ç¯å¢ƒå‡†å¤‡#ç¯å¢ƒå‡†å¤‡":"ä»¥ä¸‹æ˜¯æˆ‘è‡ªå·±åœ¨éƒ¨ç½²k8sé›†ç¾¤ä¸Šåšçš„ä¸€äº›è®°å½•ï¼Œéƒ¨ç½²äº†ä¸€ä¸ªmasterï¼Œä¸€ä¸ªnodeèŠ‚ç‚¹ã€‚\nç¯å¢ƒå‡†å¤‡æˆ‘åœ¨VirtualBoxä¸­å»ºçš„ä¸¤ä¸ªCentOSå®¹å™¨ï¼Œå¹¶ä¸”äº’é€šï¼š\nIP ç³»ç»Ÿ è§’è‰² é…ç½® 192.168.99.101 CentOS 7.5.1804 master 1æ ¸2G 192.168.99.102 CentOS 7.5.1804 node 1æ ¸2G å®‰è£…ç‰ˆæœ¬ï¼š\nç»„ä»¶ ç‰ˆæœ¬ Kubernetes 1.10.7 Etcd 3.1.10 Docker 17.12.1-ce ","ç”Ÿæˆkubernetesè¯ä¹¦#ç”Ÿæˆkubernetesè¯ä¹¦":"åˆ›å»ºkubernetes-csr.jsonæ–‡ä»¶ï¼š\n{ \"CN\": \"kubernetes\", \"hosts\": [ \"127.0.0.1\", \"192.168.99.101\", \"192.168.99.102\", \"10.254.0.1\", \"kubernetes\", \"kubernetes.default\", \"kubernetes.default.svc\", \"kubernetes.default.svc.cluster\", \"kubernetes.default.svc.cluster.local\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"BeiJing\", \"L\": \"BeiJing\", \"O\": \"k8s\", \"OU\": \"System\" } ] } å…¶ä¸­ipæ®µæ”¹ä¸ºè‡ªå·±çš„ipï¼ŒåŒ…æ‹¬etcdé›†ç¾¤IPï¼Œk8s masteré›†ç¾¤ipï¼Œk8sæœåŠ¡çš„æœåŠ¡ip(ä¸€èˆ¬æ˜¯ kube-apiserver æŒ‡å®šçš„ service-cluster-ip-range ç½‘æ®µçš„ç¬¬ä¸€ä¸ªIPï¼Œå¦‚ 10.254.0.1)\nç”Ÿæˆè¯ä¹¦å’Œç§é’¥ï¼š\n[root@localhost ssl]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kubernetes-csr.json | cfssljson -bare kubernetes ","è¯ä¹¦å‡†å¤‡#è¯ä¹¦å‡†å¤‡":"ä½¿ç”¨CFSSLå·¥å…·è¿›è¡Œè¯ä¹¦ç”Ÿæˆ\nCAè¯ä¹¦å’Œç§˜é’¥æ–‡ä»¶ä¸»è¦ç”¨æ¥åšä¼ è¾“åŠ å¯†ç”¨çš„ï¼Œå°†ä¼šç”Ÿæˆå¦‚ä¸‹æ–‡ä»¶ï¼š\nca-key.pem ca.pem kubernetes-key.pem kubernetes.pem kube-proxy.pem kube-proxy-key.pem admin.pem admin-key.pem ä½¿ç”¨è¯ä¹¦çš„ç»„ä»¶å¦‚ä¸‹ï¼š\netcdï¼šä½¿ç”¨ ca.pemã€kubernetes-key.pemã€kubernetes.pemï¼› kube-apiserverï¼šä½¿ç”¨ ca.pemã€kubernetes-key.pemã€kubernetes.pemï¼› kubeletï¼šä½¿ç”¨ ca.pemï¼› kube-proxyï¼šä½¿ç”¨ ca.pemã€kube-proxy-key.pemã€kube-proxy.pemï¼› kubectlï¼šä½¿ç”¨ ca.pemã€admin-key.pemã€admin.pemï¼› kube-controller-managerï¼šä½¿ç”¨ ca-key.pemã€ca.pem åœ¨masterèŠ‚ç‚¹ä¸Šè¿›è¡Œæ“ä½œï¼š\nwget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 chmod +x cfssl_linux-amd64 mv cfssl_linux-amd64 /usr/local/bin/cfssl wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 chmod +x cfssljson_linux-amd64 mv cfssljson_linux-amd64 /usr/local/bin/cfssljson wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 chmod +x cfssl-certinfo_linux-amd64 mv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo export PATH=/usr/local/bin:$PATH ","é…ç½®-kube-proxy#é…ç½® kube-proxy":"å®‰è£…conntrackï¼š\nyum install -y conntrack-tools æ–‡ä»¶/usr/lib/systemd/system/kube-proxy.serviceï¼š\n[Unit] Description=Kubernetes Kube-Proxy Server Documentation=https://github.com/GoogleCloudPlatform/kubernetes After=network.target [Service] EnvironmentFile=-/etc/kubernetes/config EnvironmentFile=-/etc/kubernetes/proxy ExecStart=/usr/local/bin/kube-proxy \\ $KUBE_LOGTOSTDERR \\ $KUBE_LOG_LEVEL \\ $KUBE_MASTER \\ $KUBE_PROXY_ARGS Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target /etc/kubernetes/proxyæ–‡ä»¶ï¼š\n### # kubernetes proxy config # default config should be adequate # Add your own! KUBE_PROXY_ARGS=\"--bind-address=192.168.99.102 --hostname-override=192.168.99.102 --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig --cluster-cidr=10.254.0.0/16\" å¯åŠ¨kube-proxy:\nsystemctl daemon-reload systemctl enable kube-proxy systemctl start kube-proxy systemctl status kube-proxy æ”¯æŒé›†ç¾¤çš„åŸºæœ¬åŠŸèƒ½å·²ç»æœ‰äº†ï¼Œå¯ä»¥å»ºä¸€ä¸ªéƒ¨ç½²ä¸€ä¸ªnginxåº”ç”¨è¯•ä¸€ä¸‹çœ‹ä¸€ä¸‹ã€‚","é…ç½®å’Œå¯åŠ¨-kube-apiserver#é…ç½®å’Œå¯åŠ¨ kube-apiserver":"åˆ›å»º /etc/kubernetes/configæ–‡ä»¶:\n### # kubernetes system config # # The following values are used to configure various aspects of all # kubernetes services, including # # kube-apiserver.service # kube-controller-manager.service # kube-scheduler.service # kubelet.service # kube-proxy.service # logging to stderr means we get it in the systemd journal KUBE_LOGTOSTDERR=\"--logtostderr=true\" # journal message level, 0 is debug KUBE_LOG_LEVEL=\"--v=0\" # Should this cluster be allowed to run privileged docker containers KUBE_ALLOW_PRIV=\"--allow-privileged=true\" # How the controller-manager, scheduler, and proxy find the apiserver KUBE_MASTER=\"--master=http://192.168.99.101:8080\" åˆ›å»ºserviceæ–‡ä»¶/usr/lib/systemd/system/kube-apiserver.serviceï¼š\n[Unit] Description=Kubernetes API Service Documentation=https://github.com/GoogleCloudPlatform/kubernetes After=network.target After=etcd.service [Service] EnvironmentFile=-/etc/kubernetes/config EnvironmentFile=-/etc/kubernetes/apiserver ExecStart=/usr/local/bin/kube-apiserver \\ $KUBE_LOGTOSTDERR \\ $KUBE_LOG_LEVEL \\ $KUBE_ETCD_SERVERS \\ $KUBE_API_ADDRESS \\ $KUBE_API_PORT \\ $KUBELET_PORT \\ $KUBE_ALLOW_PRIV \\ $KUBE_SERVICE_ADDRESSES \\ $KUBE_ADMISSION_CONTROL \\ $KUBE_API_ARGS Restart=on-failure Type=notify LimitNOFILE=65536 [Install] WantedBy=multi-user.target apiserverçš„é…ç½®æ–‡ä»¶ /etc/kubernetes/apiserver:\n### ## kubernetes system config ## ## The following values are used to configure the kube-apiserver ## # ## The address on the local server to listen to. KUBE_API_ADDRESS=\"--advertise-address=192.168.99.101 --bind-address=192.168.99.101 --insecure-bind-address=192.168.99.101\" # ## The port on the local server to listen on. #KUBE_API_PORT=\"--port=8080\" # ## Port minions listen on #KUBELET_PORT=\"--kubelet-port=10250\" # ## Comma separated list of nodes in the etcd cluster KUBE_ETCD_SERVERS=\"--etcd-servers=https://192.168.99.101:2379\" # ## Address range to use for services KUBE_SERVICE_ADDRESSES=\"--service-cluster-ip-range=10.254.0.0/16\" # ## default admission control policies KUBE_ADMISSION_CONTROL=\"--admission-control=ServiceAccount,NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota\" # ## Add your own! KUBE_API_ARGS=\"--authorization-mode=Node,RBAC --runtime-config=rbac.authorization.k8s.io/v1beta1 --kubelet-https=true --enable-bootstrap-token-auth --token-auth-file=/etc/kubernetes/token.csv --service-node-port-range=30000-32767 --tls-cert-file=/etc/kubernetes/ssl/kubernetes.pem --tls-private-key-file=/etc/kubernetes/ssl/kubernetes-key.pem --client-ca-file=/etc/kubernetes/ssl/ca.pem --service-account-key-file=/etc/kubernetes/ssl/ca-key.pem --etcd-cafile=/etc/kubernetes/ssl/ca.pem --etcd-certfile=/etc/kubernetes/ssl/kubernetes.pem --etcd-keyfile=/etc/kubernetes/ssl/kubernetes-key.pem --enable-swagger-ui=true --apiserver-count=3 --audit-log-maxage=30 --audit-log-maxbackup=3 --audit-log-maxsize=100 --audit-log-path=/var/lib/audit.log --event-ttl=1h\" å¯åŠ¨kube-apiserver:\nsystemctl daemon-reload systemctl enable kube-apiserver systemctl start kube-apiserver systemctl status kube-apiserver ","é…ç½®å’Œå¯åŠ¨-kube-controller-manager#é…ç½®å’Œå¯åŠ¨ kube-controller-manager":"åˆ›å»º /usr/lib/systemd/system/kube-controller-manager.serviceæ–‡ä»¶ï¼š\n[Unit] Description=Kubernetes Controller Manager Documentation=https://github.com/GoogleCloudPlatform/kubernetes [Service] EnvironmentFile=-/etc/kubernetes/config EnvironmentFile=-/etc/kubernetes/controller-manager ExecStart=/usr/local/bin/kube-controller-manager \\ $KUBE_LOGTOSTDERR \\ $KUBE_LOG_LEVEL \\ $KUBE_MASTER \\ $KUBE_CONTROLLER_MANAGER_ARGS Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target é…ç½®æ–‡ä»¶ï¼š/etc/kubernetes/controller-manager\n### # The following values are used to configure the kubernetes controller-manager # defaults from config and apiserver should be adequate # Add your own! KUBE_CONTROLLER_MANAGER_ARGS=\"--address=127.0.0.1 --service-cluster-ip-range=10.254.0.0/16 --cluster-name=kubernetes --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem --service-account-private-key-file=/etc/kubernetes/ssl/ca-key.pem --root-ca-file=/etc/kubernetes/ssl/ca.pem --leader-elect=true\" å¯åŠ¨ kube-controller-manager:\nsystemctl daemon-reload systemctl enable kube-controller-manager systemctl start kube-controller-manager systemctl status kube-controller-manager ","é…ç½®å’Œå¯åŠ¨-kube-scheduler#é…ç½®å’Œå¯åŠ¨ kube-scheduler":"åˆ›å»º/usr/lib/systemd/system/kube-scheduler.serviceæ–‡ä»¶ï¼š\n[Unit] Description=Kubernetes Scheduler Plugin Documentation=https://github.com/GoogleCloudPlatform/kubernetes [Service] EnvironmentFile=-/etc/kubernetes/config EnvironmentFile=-/etc/kubernetes/scheduler ExecStart=/usr/local/bin/kube-scheduler \\ $KUBE_LOGTOSTDERR \\ $KUBE_LOG_LEVEL \\ $KUBE_MASTER \\ $KUBE_SCHEDULER_ARGS Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target /etc/kubernetes/scheduleræ–‡ä»¶ï¼š\n### # kubernetes scheduler config # default config should be adequate # Add your own! KUBE_SCHEDULER_ARGS=\"--leader-elect=true --address=127.0.0.1\" å¯åŠ¨ kube-scheduler:\nsystemctl daemon-reload systemctl enable kube-scheduler systemctl start kube-scheduler systemctl status kube-scheduler éªŒè¯masterèŠ‚ç‚¹ [root@localhost ~]# kubectl get componentstatuses NAME STATUS MESSAGE ERROR scheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy {\"health\": \"true\"} "},"title":"åœ¨CentOSä¸Šæ­å»ºKubernetesé›†ç¾¤"},"/blog/201809/k8s-source-code-structure/":{"data":{"dlvè°ƒè¯•é˜…è¯»#DLVè°ƒè¯•é˜…è¯»":"æœ‰ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ˜¯ç›´æ¥é€šè¿‡dlvå‘½ä»¤è¿›è¡Œè°ƒè¯•ï¼Œæ¯”å¦‚è°ƒè¯•kubeletç»„ä»¶ï¼š\n$ cd cmd/kubelet $ dlv debug . -- --logtostderr=true --v=5 --address=192.168.99.102 --hostname-override=192.168.99.102 --allow-privileged=true --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig --kubeconfig=/etc/kubernetes/kubelet.kubeconfig --cert-dir=/etc/kubernetes/ssl --cluster-domain=cluster.local --hairpin-mode promiscuous-bridge --serialize-image-pulls=false å…¶ä¸­--åä¸ºç¨‹åºè¿è¡Œå‚æ•°\nè¿›å…¥ä¹‹åä¸ºé€šè¿‡breakï¼Œn,s,pç­‰æŒ‡ä»¤æ“ä½œï¼Œè¿™ç§æ–¹å¼ä¸å¤ªæ–¹ä¾¿ï¼Œå°¤å…¶å¯¹äºk8sè¿™ç§å¤§å·¥ç¨‹ï¼Œæ¨èé…åˆå·¥å…·è¿›è¡Œï¼Œæ¯”å¦‚vscodeã€‚\né€šè¿‡æˆ‘é…ç½®launch.jsonæ–‡ä»¶çš„argså‚æ•°ï¼Œè®©kubeletè¿è¡Œèµ·æ¥ï¼š\n\"args\": [ \"--address=192.168.186.219\", \"--hostname-override=192.168.186.219\", \"--cluster-domain=cluster.local\", \"--root-dir=/Users/silenceper/workspace/golang/src/k8s.io/kubelet\", \"--bootstrap-kubeconfig=/Users/silenceper/workspace/golang/src/k8s.io/kubelet/kubernetes/bootstrap.kubeconfig\", \"--kubeconfig=/Users/silenceper/workspace/golang/src/k8s.io/kubelet/kubernetes/kubelet.kubeconfig\", \"--cert-dir=/Users/silenceper/workspace/golang/src/k8s.io/kubelet/kubernetes/ssl\", ], é€šè¿‡è°ƒè¯•ï¼Œå¯ä»¥åšåˆ°è¾¹çœ‹ä»£ç ï¼Œå˜è¿½è¸ªkubeletçš„æ‰§è¡Œè¿‡ç¨‹\nå› ä¸ºosçš„åŸå› ï¼Œæ‰§è¡Œæµç¨‹å¯èƒ½ä¸ç›®æ ‡å¹³å°çš„æ‰§è¡Œç»“æœå¯èƒ½ä¸ä¸€è‡´ï¼Œä¸è¿‡å¯ä»¥æ‰‹åŠ¨æ”¹ä»£ç è¾¾åˆ°é¢„æœŸç»“æœï¼Œæˆ–è€…ç›´æ¥åœ¨Linuxä¸‹è°ƒè¯•","ä»£ç ç»“æ„#ä»£ç ç»“æ„":" â”œâ”€â”€ Godeps godepä¾èµ–æ–‡ä»¶ â”œâ”€â”€ api swagger apiæ–‡æ¡£ â”œâ”€â”€ build æ„å»ºç”¨åˆ°çš„å‘½ä»¤ â”œâ”€â”€ cluster è‡ªåŠ¨æ„å»ºå’Œå¿«é€Ÿæ„å»ºk8sé›†ç¾¤çš„è„šæœ¬(è¿›å…¥ç»´æŠ¤é˜¶æ®µ) â”œâ”€â”€ cmd æ ¸å¿ƒï¼šå‘½ä»¤å…¥å£ â”œâ”€â”€ docs æ–‡æ¡£ â”œâ”€â”€ examples ä¸€äº›éƒ¨ç½²æ ·ä¾‹yamlæ–‡ä»¶ â”œâ”€â”€ hack hackä»£ç  â”œâ”€â”€ logo logoå›¾ç‰‡ â”œâ”€â”€ pkg æ ¸å¿ƒï¼šå…·ä½“å‘½ä»¤çš„é€»è¾‘ä»£ç  â”œâ”€â”€ plugin ä¸»è¦æ˜¯kube-scheduler â”œâ”€â”€ staging æš‚å­˜åŒºï¼Œç”¨äºåˆ†ç¦»ä»“åº“ â”œâ”€â”€ test test â”œâ”€â”€ third_party ä¸€äº›ç¬¬ä¸‰æ–¹å·¥å…· â”œâ”€â”€ translations å¤šè¯­è¨€æ–‡ä»¶ â””â”€â”€ vendor ä¾èµ–ä»£ç  ç»„ä»¶å…¥å£åŸºæœ¬éƒ½åœ¨/cmd/ç›®å½•ä¸‹ï¼Œå¹¶ä¸”å¯ç›´æ¥é€šè¿‡go buildå•ç‹¬ç¼–è¯‘ï¼ˆé€šè¿‡make xxxxä¹Ÿè¡Œï¼Œmake helpæŸ¥çœ‹å…·ä½“æŒ‡ä»¤ï¼‰","ç¯å¢ƒ#ç¯å¢ƒ":"ç¯å¢ƒ k8sä»£ç ç‰ˆæœ¬ï¼šrelease-1.9 å·¥å…·ï¼švscode, dlv ä¸‹è½½ä»£ç ï¼Œå¹¶æ”¾å…¥gopathä¸­ï¼Œæ–¹ä¾¿ç¼–è¯‘ï¼š\n$ mkdir -p $GOPATH/src/k8s.io \u0026\u0026 cd $GOPATH/src/k8s.io $ git clone https://github.com/kubernetes/kubernetes # æœ‰å¢™ "},"title":"k8sæºç é˜…è¯»(ä¸€)ï¼šæºç ç»“æ„"},"/blog/201809/over-the-wall-pull-docker-mirror/":{"data":{"å‚è€ƒèµ„æ–™#å‚è€ƒèµ„æ–™":" https://docs.docker.com/config/daemon/systemd/#httphttps-proxy","æ–¹å¼ä¸€-ç›´æ¥ä¿®æ”¹dockerservice-æ–‡ä»¶#æ–¹å¼ä¸€ï¼š ç›´æ¥ä¿®æ”¹docker.service æ–‡ä»¶":"docker serviceæ–‡ä»¶/usr/lib/systemd/system/docker.serviceï¼Œåœ¨Serviceæ®µé…ç½®ä¸­åŠ å…¥ã€‚","æ–¹å¼äºŒé€šè¿‡overrideconfæ–‡ä»¶æ¨è#æ–¹å¼äºŒï¼šé€šè¿‡override.confæ–‡ä»¶(æ¨è)":"æ–‡ä»¶è·¯å¾„ï¼š /etc/systemd/system/docker.service.d/override.conf\nå¯ä»¥ç›´æ¥é€šè¿‡systemctl edit dockeræ‰“å¼€æ–‡ä»¶è¿›è¡Œç¼–è¾‘ï¼ŒåŠ å…¥ä¸Šè¿°é…ç½®ï¼Œé‡å¯ç”Ÿæ•ˆã€‚\nè¿™ç§æ–¹å¼æ¥ä¹‹ @Feng_Yuçš„æé†’ï¼ŒTHK","è®¾ç½®å˜é‡-http_proxy#è®¾ç½®å˜é‡ http_proxy":"æˆ‘ä»¬ä¸€èˆ¬é€šè¿‡è®¾ç½®http_proxyç¯å¢ƒå˜é‡ï¼Œä½¿å¾—httpè¯·æ±‚ï¼Œå¯ä»¥èµ°æˆ‘ä»¬è®¾ç½®çš„proxyï¼Œï¼ˆä¸€äº›go geté•œåƒæ— æ³•ä¸‹è½½å¯ä»¥è¿™ä¹ˆç”¨ï¼‰ï¼Œä½†æ˜¯å¯¹äºdocker pullå‘½ä»¤æ˜¯ä¸ç”Ÿæ•ˆçš„ï¼Œå› ä¸ºsystemdå¼•å¯¼å¯åŠ¨çš„serviceé»˜è®¤ä¸ä¼šè¯»å–è¿™äº›å˜é‡ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨serviceæ–‡ä»¶ä¸­åŠ å…¥ç¯å¢ƒå˜é‡è§£å†³ï¼š\nè®¾ç½®å˜é‡ http_proxyä¸»è¦æ˜¯é€šè¿‡åœ¨dockerå¯åŠ¨çš„æ—¶å€™æŒ‡å®šHTTP_PROXY ï¼ŒHTTPS_PROXYã€‚\n[Service] Environment=\"HTTP_PROXY=http://proxy.example.com:80/\" \"HTTPS_PROXY=http://proxy.example.com:80/\"\"NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com\" å…¶ä¸­NO_PROXYå˜é‡æŒ‡çš„æ˜¯é‚£äº›httpè¯·æ±‚ä¸èµ°ä»£ç†ã€‚\nä¸‹é¢ä¸¤ç§éƒ½æ˜¯ä¸€æ ·çš„æ•ˆæœï¼Œæ¨èæ–¹å¼äºŒï¼Œå¯ä»¥é¿å…ç›´æ¥ä¿®æ”¹docker.serviceæ–‡ä»¶ï¼Œé˜²æ­¢å‡çº§ä¹‹åæ–‡ä»¶è¦†ç›–ã€‚","é‡å¯docker#é‡å¯docker":" systemctl daemon-reload systemctl restart docker TIPS: polipo å¯ä»¥å°†socks5åè®®è½¬æ¢æˆhttpä»£ç†ã€‚"},"title":"docker pull ç¿»å¢™ä¸‹è½½é•œåƒ"},"/blog/201810/calico-in-k8s/":{"data":{"calicoctl-å®‰è£…#calicoctl å®‰è£…":"calicoctl å·¥å…·ï¼Œä¸»è¦ç”¨æ¥é…ç½®calicoï¼Œä¾‹å¦‚é…ç½®calico ç½‘ç»œæ¨¡å¼ç­‰\nä¸‹è½½åœ°å€ï¼šhttps://github.com/projectcalico/calicoctl/releases\nå°†ä¸‹è½½å’ŒäºŒè¿›åˆ¶æ–‡ä»¶æ”¾åœ¨/usr/local/binç›®å½•ä¸‹\ncalicoctl é…ç½®æ–‡ä»¶\nå°†ä»¥ä¸‹å†…å®¹å†™å…¥æ–‡ä»¶/etc/calico/calicoctl.cfg:\napiVersion: projectcalico.org/v3 kind: CalicoAPIConfig metadata: spec: etcdEndpoints: https://192.168.99.101:2379 etcdKeyFile: /etc/kubernetes/ssl/kubernetes-key.pem etcdCertFile: /etc/kubernetes/ssl/kubernetes.pem etcdCACertFile: /etc/kubernetes/ssl/ca.pem æµ‹è¯•æˆåŠŸï¼š\n[root@192-168-99-101 calico]# calicoctl get node -o wide NAME ASN IPV4 IPV6 192-168-99-101 (unknown) 192.168.99.101/24 192-168-99-102 (unknown) 192.168.99.102/24 ###ä¿®æ”¹ipipMode\nipipModeæœ‰ä¸‰ç§ï¼š\nNeverï¼š bgpæ¨¡å¼ Alwaysï¼šIPIPæ¨¡å¼ CrossSubnetï¼šè‡ªåŠ¨é€‰æ‹©ï¼ŒåŒä¸€ç½‘æ®µé€‰æ‹©bgpæ¨¡å¼ï¼Œè·¨ç½‘æ®µIPIPæ¨¡å¼ é€šè¿‡calicoctl get ippool -o yamlå‘½ä»¤å¯ä»¥æŸ¥çœ‹åˆ°å½“å‰ä½¿ç”¨çš„ipipModeä¸ºCrossSubnetï¼Œé€šè¿‡å¦‚ä¸‹æ–¹å¼å¯ä»¥ä¿®æ”¹ï¼š\ncalictl apply -f ippool.yaml\nå…¶ä¸­ippool.yamlæ–‡ä»¶å†…å®¹ï¼š\napiVersion: projectcalico.org/v3 items: - apiVersion: projectcalico.org/v3 kind: IPPool metadata: name: default-ipv4-ippool spec: cidr: 172.23.0.0/16 ipipMode: Always natOutgoing: true kind: IPPoolList ","å®‰è£…#å®‰è£…":"å‰æå·²ç»å®‰è£…å¥½k8sé›†ç¾¤\nå®‰è£…calico å®‰è£…å…¶å®å¾ˆç®€å•ï¼Œå·²ç»é›†æˆåœ¨ä¸¤ä¸ªyamlæ–‡ä»¶ä¸­\ncalico ç‰ˆæœ¬: v3.2.3","å®‰è£…å¿…çœ‹#å®‰è£…å¿…çœ‹":" å¦‚æœå®‰è£…è¿‡flannelç»„ä»¶ï¼Œéœ€è¦å…ˆå»é™¤dockerå¯åŠ¨é¡¹ä¸­ $DOCKER_NETWORK_OPTIONSå‚æ•° åˆ é™¤å·²æœ‰çš„/etc/cni/net.dï¼Œ/opt/cni/binæ–‡ä»¶ kubeletå’Œkube-apiserverå¯åŠ¨é¡¹ä¸­éœ€è¦åŠ ä¸Š--allow-privileged=trueï¼Œä¿è¯calico-nodeéœ€è¦ä»¥ç‰¹æƒæ¨¡å¼è¿è¡Œ è¿™é‡Œcalicoæ–‡ä»¶é‡‡ç”¨äº†CrossSubnetæ¨¡å¼ ","æŒ‡å®šk8sä½¿ç”¨cniæ’ä»¶#æŒ‡å®šk8sä½¿ç”¨CNIæ’ä»¶":"åœ¨kubeletå¯åŠ¨å‚æ•°ä¸­åŠ å…¥ä»¥ä¸‹å‚æ•°:\n--network-plugin=cni: æŒ‡å®šä½¿ç”¨cniæ’ä»¶ --cni-bin-dir=/opt/cni/binï¼š å­˜æ”¾ç½‘ç»œé…ç½®çš„å¯æ‰§è¡Œæ–‡ä»¶ --cni-conf-dir=/etc/cni/net.d: å­˜æ”¾ç½‘ç»œé…ç½®æ–‡ä»¶ï¼Œå¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œåˆ™åªä¼šé€‰æ‹©ä¸€ä¸ª(æ ¹æ®æ–‡ä»¶åæ’åº) ","éƒ¨ç½²#éƒ¨ç½²":"å®‰è£…æ–‡ä»¶æ”¾åœ¨: https://github.com/silenceper/k8s-install/tree/master/calico\nä¸»è¦åŒ…å«ä¸¤ä¸ªæ–‡ä»¶calico.yamlï¼Œrbac.yaml:\néœ€è¦åšå¦‚ä¸‹å‚æ•°ä¿®æ”¹ï¼š\nå°†å…¶ä¸­çš„ETCD_LVS_HOSTä¿®æ”¹ä¸ºé›†ç¾¤çš„etcdåœ°å€ï¼Œå¹¶ä¸”å°†TLS_ETCD_KEY,TLS_ETCD_CERT ,TLS_ETCD_CAæ›¿æ¢ä¸ºè¯ä¹¦çš„å†…å®¹çš„base64åçš„ç»“æœï¼š\n# å…¶ä¸­è¯ä¹¦çš„è·¯å¾„æ ¹æ®è‡ªå·±ç¯å¢ƒæ›´æ”¹ä¸ºæ­£ç¡®çš„è·¯å¾„ TLS_ETCD_CA=$(cat /etc/kubernetes/ssl/ca.pem | base64 |tr -d \"\\n\") TLS_ETCD_KEY=$(cat /etc/kubernetes/ssl/etcd-key.pem | base64 |tr -d \"\\n\") TLS_ETCD_CERT=$(cat /etc/kubernetes/ssl/etcd.pem | base64 |tr -d \"\\n\") # æ›¿æ¢å†…å®¹ sed -i \"s#TLS_ETCD_CA#$TLS_ETCD_CA#g\" calico.yaml sed -i \"s#TLS_ETCD_CERT#$TLS_ETCD_CERT#g\" calico.yaml sed -i \"s#TLS_ETCD_KEY#$TLS_ETCD_KEY#g\" calico.yaml # æ›¿æ¢ETCD_LVS_HOSTåœ°å€ï¼Œæ›´æ¢ä¸ºè‡ªå·±çš„etcdåœ°å€ sed -i \"s#ETCD_LVS_HOST#192.168.99.101#g\" calico.yaml éƒ¨ç½²\nkubectl apply -f calico.yaml kubectl apply -f rbac.yaml "},"title":"k8sç½‘ç»œç»„ä»¶ï¼šcalico"},"/blog/201907/cluster-autoscaler-usage/":{"data":{"":"Cluster AutoScaler æ˜¯ä¸€ä¸ªè‡ªåŠ¨æ‰©å±•å’Œæ”¶ç¼© Kubernetes é›†ç¾¤ Node çš„æ‰©å±•ã€‚å½“é›†ç¾¤å®¹é‡ä¸è¶³æ—¶ï¼Œå®ƒä¼šè‡ªåŠ¨å» Cloud Provider ï¼ˆæ”¯æŒ GCEã€GKE å’Œ AWSï¼‰åˆ›å»ºæ–°çš„ Nodeï¼Œè€Œåœ¨ Node é•¿æ—¶é—´èµ„æºåˆ©ç”¨ç‡å¾ˆä½æ—¶è‡ªåŠ¨å°†å…¶åˆ é™¤ä»¥èŠ‚çœå¼€æ”¯ã€‚\nåœ¨Kubernetesä¸­å…³äºå¼¹æ€§ä¼¸ç¼©ä¸»è¦æœ‰ä¸‰ç§æ ¼å¼ï¼š\nHPAï¼šHorizontal Pod Autoscalingå¯ä»¥æ ¹æ®CPUåˆ©ç”¨ç‡è‡ªåŠ¨ä¼¸ç¼©ä¸€ä¸ªReplication Controllerã€Deployment æˆ–è€…Replica Setä¸­çš„Podæ•°é‡ VPAï¼šVertical Pod Autoscalerï¼ˆVPAï¼‰ä½¿ç”¨æˆ·æ— éœ€ä¸ºå…¶podsä¸­çš„å®¹å™¨è®¾ç½®æœ€æ–°çš„èµ„æºrequestã€‚é…ç½®åï¼Œå®ƒå°†æ ¹æ®ä½¿ç”¨æƒ…å†µè‡ªåŠ¨è®¾ç½®requestï¼Œä»è€Œå…è®¸åœ¨èŠ‚ç‚¹ä¸Šè¿›è¡Œé€‚å½“çš„è°ƒåº¦ï¼Œä»¥ä¾¿ä¸ºæ¯ä¸ªpodæä¾›é€‚å½“çš„èµ„æºé‡ã€‚ CAï¼šè‡ªåŠ¨ä¼¸ç¼©NODEèŠ‚ç‚¹ ","å®ç°cluster-provider#å®ç°Cluster Provider":"å¦‚æœä½ ä½¿ç”¨çš„ä»¥ä¸Šä¸»æµçš„å‡ ä¸ªäº‘å‚å•†çš„ä¸»æœºèµ„æº/k8sé›†ç¾¤ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨å®˜æ–¹çš„CAç‰ˆæœ¬ï¼Œåªéœ€è¦é€šè¿‡å‚æ•°--cloud-provideræ§åˆ¶æ¥è‡ªå“ªä¸ªäº‘å‚å•†å°±å¯ä»¥ã€‚\nå¦‚æœæƒ³è¦å¯¹æ¥è‡ªå·±çš„IaaSå±‚ï¼Œåªéœ€è¦å®ç°å…¶ä¸­çš„æ¥å£å°±å¯ä»¥äº†ï¼Œæ¥å£å®šä¹‰å¦‚ä¸‹ï¼š\n// CloudProvider contains configuration info and functions for interacting with // cloud provider (GCE, AWS, etc). type CloudProvider interface {Marcin Wielgus, 3 years ago: â€¢ Cluster-autoscaler: cloud provider interface // Name returns name of the cloud provider. Name() string // NodeGroups returns all node groups configured for this cloud provider. //è¿”å›æ‰€æœ‰ä¼¸ç¼©ç»„ NodeGroups() []NodeGroup // NodeGroupForNode returns the node group for the given node, nil if the node // should not be processed by cluster autoscaler, or non-nil error if such // occurred. Must be implemented. NodeGroupForNode(*apiv1.Node) (NodeGroup, error) // Pricing returns pricing model for this cloud provider or error if not available. // Implementation optional. Pricing() (PricingModel, errors.AutoscalerError) // GetAvailableMachineTypes get all machine types that can be requested from the cloud provider. // Implementation optional. GetAvailableMachineTypes() ([]string, error) // NewNodeGroup builds a theoretical node group based on the node definition provided. The node group is not automatically // created on the cloud provider side. The node group is not returned by NodeGroups() until it is created. // Implementation optional. NewNodeGroup(machineType string, labels map[string]string, systemLabels map[string]string, taints []apiv1.Taint, extraResources map[string]resource.Quantity) (NodeGroup, error) // GetResourceLimiter returns struct containing limits (max, min) for resources (cores, memory etc.). GetResourceLimiter() (*ResourceLimiter, error) // GPULabel returns the label added to nodes with GPU resource. GPULabel() string // GetAvailableGPUTypes return all available GPU types cloud provider supports. GetAvailableGPUTypes() map[string]struct{} // Cleanup cleans up open resources before the cloud provider is destroyed, i.e. go routines etc. Cleanup() error // Refresh is called before every main loop and can be used to dynamically update cloud provider state. // In particular the list of node groups returned by NodeGroups can change as a result of CloudProvider.Refresh(). Refresh() error } å…¶ä¸­NodeGroupæ¥å£å®šä¹‰ï¼š\n// NodeGroup contains configuration info and functions to control a set // of nodes that have the same capacity and set of labels. type NodeGroup interface { // MaxSize returns maximum size of the node group. MaxSize() int // MinSize returns minimum size of the node group. MinSize() int // TargetSize returns the current target size of the node group. It is possible that the // number of nodes in Kubernetes is different at the moment but should be equal // to Size() once everything stabilizes (new nodes finish startup and registration or // removed nodes are deleted completely). Implementation required. TargetSize() (int, error) // IncreaseSize increases the size of the node group. To delete a node you need // to explicitly name it and use DeleteNode. This function should wait until // node group size is updated. Implementation required. //æ‰©å®¹ä¼¸ç¼©ç»„ IncreaseSize(delta int) error // DeleteNodes deletes nodes from this node group. Error is returned either on // failure or if the given node doesn't belong to this node group. This function // should wait until node group size is updated. Implementation required. //ä»ä¼¸ç¼©ç»„ä¸­åˆ é™¤èŠ‚ç‚¹ DeleteNodes([]*apiv1.Node) error // DecreaseTargetSize decreases the target size of the node group. This function // doesn't permit to delete any existing node and can be used only to reduce the // request for new nodes that have not been yet fulfilled. Delta should be negative. // It is assumed that cloud provider will not delete the existing nodes when there // is an option to just decrease the target. Implementation required. DecreaseTargetSize(delta int) error // Id returns an unique identifier of the node group. Id() string // Debug returns a string containing all information regarding this node group. Debug() string // Nodes returns a list of all nodes that belong to this node group. // It is required that Instance objects returned by this method have Id field set. // Other fields are optional. Nodes() ([]Instance, error) // TemplateNodeInfo returns a schedulernodeinfo.NodeInfo structure of an empty // (as if just started) node. This will be used in scale-up simulations to // predict what would a new node look like if a node group was expanded. The returned // NodeInfo is expected to have a fully populated Node object, with all of the labels, // capacity and allocatable information as well as all pods that are started on // the node by default, using manifest (most likely only kube-proxy). Implementation optional. TemplateNodeInfo() (*schedulernodeinfo.NodeInfo, error) // Exist checks if the node group really exists on the cloud provider side. Allows to tell the // theoretical node group from the real one. Implementation required. Exist() bool // Create creates the node group on the cloud provider side. Implementation optional. Create() (NodeGroup, error) // Delete deletes the node group on the cloud provider side. // This will be executed only for autoprovisioned node groups, once their size drops to 0. // Implementation optional. Delete() error // Autoprovisioned returns true if the node group is autoprovisioned. An autoprovisioned group // was created by CA and can be deleted when scaled to 0. Autoprovisioned() bool } å…¶ä¸­IncreaseSizeï¼ŒIncreaseSizeæ‰æ˜¯å…³é”®çš„æ–¹æ³•ï¼Œåˆ†åˆ«å¯¹ç”¨æ‰©å®¹ä¼¸ç¼©ç»„å’Œå¢åŠ èŠ‚ç‚¹ã€‚\nåœ¨è°ƒç”¨IncreaseSizeæ¥å£åï¼Œéœ€è¦å®ŒæˆèŠ‚ç‚¹è‡ªåŠ¨æ·»åŠ è¿›é›†ç¾¤ã€‚å‚è€ƒé˜¿é‡Œäº‘æ˜¯é€šè¿‡é…ç½®shellè„šæœ¬åˆ°ä¼¸ç¼©ç»„ä¸­çš„ECSå¯åŠ¨è„šæœ¬ä¸­ï¼Œå½“ECSå¯åŠ¨ï¼Œè‡ªåŠ¨æ‰§è¡Œè¯¥è„šæœ¬ã€‚å½“ç„¶æˆ‘ä»¬ä¹Ÿå¯ä»¥è‡ªå®šä¹‰é€šè¿‡å…¶ä»–æ–¹å¼åŠ å…¥é›†ç¾¤ã€‚","å·¥ä½œåŸç†#å·¥ä½œåŸç†":"æ‰©å®¹ CAä¼šå®šæœŸ(é»˜è®¤10s,é€šè¿‡å‚æ•°--scan-intervalè®¾ç½®)æ£€æµ‹å½“å‰é›†ç¾¤çŠ¶æ€ä¸‹æ˜¯å¦å­˜åœ¨pendingçš„podï¼Œç„¶åç»è¿‡è®¡ç®—ï¼Œåˆ¤æ–­éœ€è¦æ‰©å®¹å‡ ä¸ªèŠ‚ç‚¹ï¼Œæœ€ç»ˆä»node groupä¸­è¿›è¡ŒèŠ‚ç‚¹çš„æ‰©å®¹ï¼š\nNode Group å°±å¯¹åº”ä¼¸ç¼©ç»„çš„æ¦‚å¿µï¼Œå¯ä»¥æ”¯æŒé…ç½®æ”¯æŒå¤šä¸ªä¼¸ç¼©ç»„ï¼Œé€šè¿‡ç­–ç•¥æ¥è¿›è¡Œé€‰æ‹©ï¼Œç›®å‰æ”¯æŒçš„ç­–ç•¥ä¸ºï¼š\nrandomï¼šéšæœºé€‰æ‹© most-podsï¼šé€‰æ‹©èƒ½å¤Ÿåˆ›å»ºpodæœ€å¤šçš„Node Group least-wasteï¼šä»¥æœ€å°æµªè´¹åŸåˆ™é€‰æ‹©ï¼Œå³é€‰æ‹©æœ‰æœ€å°‘å¯ç”¨èµ„æºçš„ Node Group priceï¼šæ ¹æ®ä¸»æœºçš„ä»·æ ¼é€‰æ‹©ï¼Œé€‰æ‹©æœ€ä¾¿å®œçš„ priorityï¼šæ ¹æ®ä¼˜å…ˆçº§è¿›è¡Œé€‰æ‹©ï¼Œé€šè¿‡é…ç½®cluster-autoscaler-priority-expander configMapï¼Œå…·ä½“å‚è€ƒï¼šhttps://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler/expander/priority ç¼©å®¹ é›†ç¾¤ç¼©å®¹å…¶å®æ˜¯ä¸€ä¸ªå¯é€‰çš„é€‰é¡¹ï¼Œé€šè¿‡å‚æ•°--scale-down-enabledæ§åˆ¶æ˜¯å¦å¼€å¯ç¼©å®¹ã€‚\nCAå®šæœŸä¼šæ£€æµ‹é›†ç¾¤çŠ¶æ€ï¼Œåˆ¤æ–­å½“å‰é›†ç¾¤çŠ¶æ€ä¸‹ï¼Œå“ªäº›èŠ‚ç‚¹èµ„æºåˆ©ç”¨ç‡å°äº50%(é€šè¿‡å‚æ•°--scale-down-utilization-thresholdæ§åˆ¶)ã€‚\nèµ„æºåˆ©ç”¨ç‡è®¡ç®—æ˜¯é€šè¿‡åˆ¤æ–­é›†ç¾¤cpuï¼Œmem ä¸­requestå€¼å ç”¨ç‡è®¡ç®—çš„ï¼Œåªè¦æœ‰ä¸€ä¸ªæŒ‡æ ‡è¶…äº†å°±å¯èƒ½ä¼šå‡ºå‘ç¼©å®¹ï¼Œä¹‹æ‰€ä»¥è¯´æ˜¯å¯èƒ½ä¼šè§¦å‘æ‰©å®¹ï¼Œæ˜¯å› ä¸ºè¦ä¿è¯è¢«é©±é€èŠ‚ç‚¹ä¸Šçš„PODèƒ½å¤Ÿæ­£ç¡®è°ƒåº¦åˆ°å…¶ä»–èŠ‚ç‚¹ä¸Šã€‚\nå“ªäº›NODEä¸ä¼šç¼©å®¹ï¼š\nå½“æ‚¨è®¾ç½®äº†ä¸¥æ ¼çš„ PodDisruptionBudget çš„ Pod ä¸æ»¡è¶³ PDB æ—¶ï¼Œä¸ä¼šç¼©å®¹ã€‚ Kube-system ä¸‹çš„ Podã€‚é€šè¿‡å‚æ•°--skip-nodes-with-system-podsæ§åˆ¶ èŠ‚ç‚¹ä¸Šæœ‰é deploymentï¼Œreplica setï¼Œjobï¼Œstateful set ç­‰æ§åˆ¶å™¨åˆ›å»ºçš„ Podã€‚ Pod æœ‰æœ¬åœ°å­˜å‚¨ã€‚é€šè¿‡å‚æ•°--skip-nodes-with-local-storageæ§åˆ¶ Pod ä¸èƒ½è¢«è°ƒåº¦åˆ°å…¶ä»–èŠ‚ç‚¹ä¸Šã€‚ä¾‹å¦‚èµ„æºä¸æ»¡è¶³ç­‰ ","éƒ¨ç½²#éƒ¨ç½²":"Cluster Autoscalerä»£ç åœ°å€ï¼šhttps://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler\nCA æä¾›äº†Cloud Provideræ¥å£ä¾›å„ä¸ªäº‘å‚å•†æ¥å…¥ï¼Œä¸»è¦æ˜¯é’ˆå¯¹å‚å•†è‡ªå·±çš„APIï¼Œåº”å¯¹èŠ‚ç‚¹æ·»åŠ ä»¥åŠåˆ é™¤çš„è¯·æ±‚ã€‚\nç›®å‰äº‘å‚å•†çš„ECSäº§å“éƒ½ä¼šæœ‰æ‰©ç¼©å®¹çš„åŠŸèƒ½ï¼ˆä¾‹å¦‚é˜¿é‡Œäº‘ESSï¼Œå°±æ˜¯CAä¸­ä¼¸ç¼©ç»„çš„æ¦‚å¿µï¼‰ï¼ŒCAå°±å¯ä»¥ç»“åˆESSå®Œæˆé›†ç¾¤çš„æ‰©ç¼©å®¹åŠŸèƒ½ã€‚\nå„å¤§å‚å•†èŠ‚ç‚¹æ‰©ç¼©å®¹å®‰è£…ï¼š\nGCE: https://kubernetes.io/docs/concepts/cluster-administration/cluster-management/ GKE: https://cloud.google.com/container-engine/docs/cluster-autoscaler AWS: https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md Azure: https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler/cloudprovider/azure alicloudï¼šhttps://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/alicloud/README.md baiducloudï¼šhttps://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/baiducloud/README.md ä»¥é˜¿é‡Œäº‘ä¸ºä¾‹ï¼Œå…·ä½“å®‰è£…å¯ä»¥å‚è€ƒè¿™ç¯‡æ–‡ç« ï¼šé˜¿é‡Œäº‘ä¸Šå¼¹æ€§ä¼¸ç¼©kubernetesé›†ç¾¤ - autoscaler å…¶ä¸­å…³é”®yamlæ–‡ä»¶å¦‚ä¸‹ï¼š\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: cluster-autoscaler namespace: kube-system labels: app: cluster-autoscaler spec: replicas: 1 selector: matchLabels: app: cluster-autoscaler template: metadata: labels: app: cluster-autoscaler spec: serviceAccountName: admin containers: - image: registry.cn-hangzhou.aliyuncs.com/google-containers/cluster-autoscaler:v1.1.0 name: cluster-autoscaler resources: limits: cpu: 100m memory: 300Mi requests: cpu: 100m memory: 300Mi command: - ./cluster-autoscaler - --v=4 - --stderrthreshold=info - --cloud-provider=alicloud - --skip-nodes-with-local-storage=false - --nodes=1:100:${AUTO_SCALER_GROUP} env: - name: ACCESS_KEY_ID valueFrom: secretKeyRef: name: cloud-config key: access-key-id - name: ACCESS_KEY_SECRET valueFrom: secretKeyRef: name: cloud-config key: access-key-secret imagePullPolicy: \"Always\" å…¶ä¸­ --nodes=1:100:${AUTO_SCALER_GROUP}å‚æ•°ï¼Œè¡¨ç¤ºæ‰©å®¹æœ€å¤§100ä¸ªï¼Œç¼©å®¹æœ€å°1ä¸ªèŠ‚ç‚¹ï¼Œåé¢${AUTO_SCALER_GROUP}è¡¨ç¤ºä¼¸ç¼©ç»„ID"},"title":"Cluster Autoscaler:é›†ç¾¤è‡ªåŠ¨æ‰©ç¼©å®¹"},"/blog/201910/kubernetes-log/":{"data":{"log-pilot-ä»£ç åˆ†æ#log-pilot ä»£ç åˆ†æ":"è¿™é‡Œä»¥log-pilotä¸ºä¾‹ï¼Œæ¥åˆ†æä¸‹\nä»£ç åœ°å€ï¼š https://github.com/AliyunContainerService/log-pilot\nåŸºæœ¬æµç¨‹:\nç›‘å¬docker-serviceçš„äº‹ä»¶ï¼ˆstartï¼Œrestartï¼Œdestoryï¼‰ï¼Œä»containerä¿¡æ¯ä¸­æå–pod_name,namespaceä¿¡æ¯ï¼ˆå¯é€šè¿‡docker inspect [container ID]æŸ¥çœ‹åˆ°ï¼‰ï¼Œå¹¶å†™å…¥filebeatä¸­çš„prospector.dä¸­çš„é…ç½®æ–‡ä»¶ã€‚\näº‹ä»¶ç›‘å¬ï¼š pilot/pilot.go#L134\nmsgs, errs := p.client.Events(ctx, options)chenqz1987, 1 year ago: â€¢ fix issue #40 and update log-pilot capabilityâ€¦ go func() { defer func() { log.Warn(\"finish to watch event\") p.stopChan \u003c- true }() log.Info(\"begin to watch event\") for { select { case msg := \u003c-msgs: if err := p.processEvent(msg); err != nil { log.Errorf(\"fail to process event: %v, %v\", msg, err) } case err := \u003c-errs: log.Warnf(\"error: %v\", err) if err == io.EOF || err == io.ErrUnexpectedEOF { return } msgs, errs = p.client.Events(ctx, options) } } }() å¯¹æ¥ä¸åŒæ”¶é›†å™¨\nlog-pilotæ”¯æŒfilebeatå’Œfluentdä¸¤ç§æ—¥å¿—æ”¶é›†å™¨ï¼Œç›®çš„ä¸»è¦æ˜¯åˆ·æ–°å¯¹åº”çš„é…ç½®æ–‡ä»¶ã€‚ä¸»è¦æ˜¯å®ç°äº†Piloteræ¥å£ï¼š\npilot/piloter.go#L17\n// Piloter interface for piloter type Piloter interface { Name() string Start() error Reload() error Stop() error GetBaseConf() string GetConfHome() string GetConfPath(container string) string OnDestroyEvent(container string) error } è‡³äºåœ¨å¯åŠ¨log-piloté€‰æ‹©å“ªç§é‡‡é›†å™¨è¿›è¡Œé‡‡é›†ï¼Œæ˜¯é€šè¿‡åœ¨å®¹å™¨çš„entrypointæ–‡ä»¶ä¸­é€šè¿‡åˆ¶å®šç¯å¢ƒå˜é‡PILOT_TYPEçš„æ–¹å¼è¿›è¡Œé€‰æ‹©æ€§æ¸²æŸ“çš„ã€‚\nå®Œå–„\nå½“å‰æœ€æ–°ç‰ˆæœ¬[0.9.7]\n1ã€ç›®å‰log-pilotè¿˜æ˜¯åªèƒ½é€šè¿‡ç›‘å¬docker-servierçš„eventè¿›è¡Œï¼Œå¯¹äºcontainerdï¼Œcri-oè¿˜æ²¡åŠæ³•é€‚é…ã€‚\ncontainerdç›®å‰æ²¡æä¾›ç›¸åº”çš„eventæ¥å£ï¼Œå¯ä»¥é€‰æ‹©ä»k8s api é€šè¿‡List-Watchä¸­è·å–\n2ã€filebeatå‡çº§\nfilebeat ç›®å‰ç”¨çš„ç‰ˆæœ¬æ˜¯6.1.1 ï¼Œfilebeatæœ¬èº«å°±æ˜¯ä¸€ä¸ªæ¯”è¾ƒåƒèµ„æºçš„è¿›ç¨‹ï¼Œfilebeatæœ‰äº›issueæ˜¯7820bugï¼Œå¯ä»¥å°†filebeatå‡çº§åˆ°ä¸€ä¸ªæ–°çš„ç‰ˆæœ¬ã€‚\n3ã€èµ„æºé™åˆ¶\nåœ¨k8sä¸­é€šè¿‡åˆ¶å®šlimitï¼Œé™åˆ¶log-pilotçš„èµ„æºå ç”¨ï¼ˆä¸»è¦è¿˜æ˜¯æ—¥å¿—é‡‡é›†å™¨ï¼‰","æ–¹æ¡ˆ#æ–¹æ¡ˆ":"æ”¶é›†PODä¸­containeræ—¥å¿—ï¼Œæ—¥å¿—è¿˜åˆ†ä¸ºä¸¤ç§ä¸€ç§æ˜¯å®¹å™¨æ ‡å‡†è¾“å‡ºæ—¥å¿—å’Œå®¹å™¨å†…æ—¥å¿—ã€‚\næ–¹æ¡ˆä»æ—¥å¿—çš„é‡‡é›†æ–¹å¼ä¸Šï¼Œåœ¨æˆ‘çœ‹æ¥æ–¹æ¡ˆå¤§è‡´ä¸»è¦åˆ†ä¸ºä¸¤ç§ï¼š\nï¼ˆ1ï¼‰POD é‡Œé¢å®‰è£…logging agent\næ¯ä¸ªpodé‡Œé¢éƒ½è¦å®‰è£…ä¸€ä¸ªagentï¼Œæ— è®ºæ˜¯ä»¥æ”¾åœ¨æœ¬containerè¿˜æ˜¯ä»¥sidecarçš„æ–¹å¼éƒ¨ç½²ï¼Œå¾ˆæ˜æ˜¾ä¼šå ç”¨å¾ˆå¤šèµ„æºï¼ŒåŸºæœ¬ä¸æ¨è\nï¼ˆ2ï¼‰åœ¨èŠ‚ç‚¹ä¸Šå®‰è£…logging agentï¼ˆæ¨èï¼‰\nå…¶å®å®¹å™¨stdout,stderrçš„æ—¥å¿—æœ€ç»ˆä¹Ÿæ˜¯è½åœ¨å®¿ä¸»æœºä¸Šï¼Œè€Œå®¹å™¨å†…çš„è·¯å¾„å¯ä»¥é€šè¿‡é…ç½®volumeMount åœ¨å®¿ä¸»æœºä¸Šé…ç½®æ˜ å°„å³å¯ï¼Œæ‰€ä»¥è¿™ç§æ–¹å¼è¿˜æ˜¯æœ€å¯è¡Œçš„\nå½“ç„¶åº”ç”¨è¿˜å¯ä»¥è‡ªå·±é€šè¿‡ä»£ç ç›´æ¥ä¸ŠæŠ¥ç»™æ—¥å¿—æœåŠ¡ï¼Œä½†æ˜¯è¿™ç§æ–¹å¼ä¸å¤Ÿé€šç”¨ï¼Œè¿˜å¢åŠ äº†ä¸šåŠ¡ä»£ç çš„å¤æ‚æ€§"},"title":"Kuberneteså®¹å™¨æ—¥å¿—æ”¶é›†æ–¹æ¡ˆ"},"/blog/202001/go-import-version/":{"data":{"ä¸€ä¸ªå®Œæ•´çš„ä¾‹å­#ä¸€ä¸ªå®Œæ•´çš„ä¾‹å­":"è¿™é‡Œå°†versionåŒ…å•ç‹¬åšäº†ä¸€ä¸ªåŒ…å­˜æ”¾ï¼Œåªéœ€è¦å¼•å…¥å³å¯ï¼š\npackage main import ( \"flag\" \"github.com/go-demo/version\" ) //é€šè¿‡flagåŒ…è®¾ç½®-versionå‚æ•° var printVersion bool func init() { flag.BoolVar(\u0026printVersion, \"version\", false, \"print program build version\") flag.Parse() } func main() { if printVersion { version.PrintVersion() } } æ„å»ºçš„shellå¦‚ä¸‹(ä¹Ÿå¯ä»¥æ”¾åœ¨Makefileä¸­)ï¼š\n#!/bin/sh version=\"v0.1\" path=\"github.com/go-demo/version\" flags=\"-X $path.Version=$version -X '$path.GoVersion=$(go version)' -X '$path.BuildTime=`date +\"%Y-%m-%d %H:%m:%S\"`' -X $path.GitCommit=`git rev-parse HEAD`\" go build -ldflags \"$flags\" -o example example-version.go TIPS: å¦‚æœå€¼å†…å®¹ä¸­å«æœ‰ç©ºæ ¼ï¼Œå¯ä»¥ç”¨å•å¼•å·\næœ€ç»ˆç‰ˆæœ¬è¾“å‡º:\nâœ sh build.sh âœ ./example -version Version: v0.1 Go Version: go version go1.13.1 darwin/amd64 Git Commit: a775ecd27c5e78437b605c438905e9cc888fbc1c Build Time: 2020-01-09 19:01:51 å®Œæ•´ä»£ç ï¼šhttps://github.com/go-demo/version","å‚æ•°è¯´æ˜#å‚æ•°è¯´æ˜":"1ã€-ldflags buildå‘½ä»¤ä¸­ç”¨äºè°ƒç”¨æ¥é“¾æ¥å™¨çš„å‚æ•°\n-ldflags '[pattern=]arg list' arguments to pass on each go tool link invocation. 2ã€-X é“¾æ¥å™¨å‚æ•°ï¼Œä¸»è¦ç”¨äºè®¾ç½®å˜é‡\n-X importpath.name=value Set the value of the string variable in importpath named name to value. Note that before Go 1.5 this option took two separate arguments. Now it takes one argument split on the first = sign. ","å®ç°#å®ç°":"æˆ‘ä»¬ç»å¸¸åœ¨ä½¿ç”¨CLIå·¥å…·çš„æ—¶å€™ï¼Œéƒ½ä¼šæœ‰è¿™æ ·çš„å‚æ•°è¾“å‡ºï¼š\nâœ ~ docker version Client: Docker Engine - Community Version: 18.09.2 API version: 1.39 Go version: go1.10.8 Git commit: 6247962 Built: Sun Feb 10 04:12:39 2019 OS/Arch: darwin/amd64 Experimental: false âœ ~ å¯ä»¥æ‰“å°å‡ºæ„å»ºæ—¶å¯¹åº”çš„ç‰ˆæœ¬ä¿¡æ¯ï¼Œæ¯”å¦‚ Versionï¼ŒGo Versionï¼ŒGit Commitç­‰ï¼Œè¿™ä¸ªæ˜¯å¦‚ä½•å®ç°çš„å‘¢ï¼Ÿ\nå®ç°ä¸»è¦æ˜¯é€šè¿‡ldflagså‚æ•°æ¥å®ç°åœ¨æ„å»ºçš„æ—¶å€™å¯¹å˜é‡è¿›è¡Œèµ‹å€¼ã€‚\næ¯”å¦‚ä¸‹é¢ä¸€æ®µä»£ç ï¼š\npackage main import ( \"flag\" \"fmt\" \"os\" ) //éœ€è¦èµ‹å€¼çš„å˜é‡ var version = \"\" //é€šè¿‡flagåŒ…è®¾ç½®-versionå‚æ•° var printVersion bool func init() { flag.BoolVar(\u0026printVersion, \"version\", false, \"print program build version\") flag.Parse() } func main() { if printVersion { println(version) os.Exit(0) } fmt.Printf(\"example for print version\") } æ„å»ºå‘½ä»¤ï¼š\ngo build -ldflags \"-X main.version=v0.1\" -o example ç¨‹åºè¾“å‡ºï¼š\nâœ ./example version=v0.1 "},"title":"å¦‚ä½•åœ¨Goé¡¹ç›®ä¸­è¾“å‡ºç‰ˆæœ¬ä¿¡æ¯ï¼Ÿ"},"/blog/202002/kubernetes-leaderelection/":{"data":{"":"åœ¨Kubernetesä¸­ï¼Œé€šå¸¸kube-schdulerå’Œkube-controller-manageréƒ½æ˜¯å¤šå‰¯æœ¬è¿›è¡Œéƒ¨ç½²çš„æ¥ä¿è¯é«˜å¯ç”¨ï¼Œè€ŒçœŸæ­£åœ¨å·¥ä½œçš„å®ä¾‹å…¶å®åªæœ‰ä¸€ä¸ªã€‚è¿™é‡Œå°±åˆ©ç”¨åˆ° leaderelectionÂ çš„é€‰ä¸»æœºåˆ¶ï¼Œä¿è¯leaderæ˜¯å¤„äºå·¥ä½œçŠ¶æ€ï¼Œå¹¶ä¸”åœ¨leaderæŒ‚æ‰ä¹‹åï¼Œä»å…¶ä»–èŠ‚ç‚¹é€‰å–æ–°çš„leaderä¿è¯ç»„ä»¶æ­£å¸¸å·¥ä½œã€‚\nä¸å•å•åªæ˜¯k8sä¸­çš„è¿™ä¸¤ä¸ªç»„ä»¶ç”¨åˆ°ï¼Œåœ¨å…¶ä»–æœåŠ¡ä¸­ä¹Ÿå¯ä»¥çœ‹åˆ°è¿™ä¸ªåŒ…çš„ä½¿ç”¨ï¼Œæ¯”å¦‚cluster-autoscalerç­‰éƒ½èƒ½çœ‹å¾—åˆ°è¿™ä¸ªåŒ…çš„ï¼Œä»Šå¤©å°±æ¥çœ‹çœ‹è¿™ä¸ªåŒ…çš„ä½¿ç”¨ä»¥åŠå®ƒå†…éƒ¨æ˜¯å¦‚ä½•å®ç°çš„ã€‚","ä½¿ç”¨#ä½¿ç”¨":"ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•ä½¿ç”¨çš„ä¾‹å­ï¼Œç¼–è¯‘å®Œæˆä¹‹ååŒæ—¶å¯åŠ¨å¤šä¸ªè¿›ç¨‹ï¼Œä½†æ˜¯åªæœ‰ä¸€ä¸ªè¿›ç¨‹åœ¨å·¥ä½œï¼Œå½“æŠŠleaderè¿›ç¨‹killæ‰ä¹‹åï¼Œä¼šé‡æ–°é€‰ä¸¾å‡ºä¸€ä¸ªleaderè¿›è¡Œå·¥ä½œï¼Œå³æ‰§è¡Œå…¶ä¸­çš„ runÂ æ–¹æ³•ï¼š\n/* ä¾‹å­æ¥æºäºclient-goä¸­çš„exampleåŒ…ä¸­ */ package main import ( \"context\" \"flag\" \"os\" \"os/signal\" \"syscall\" \"time\" \"github.com/google/uuid\" metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" clientset \"k8s.io/client-go/kubernetes\" \"k8s.io/client-go/rest\" \"k8s.io/client-go/tools/clientcmd\" \"k8s.io/client-go/tools/leaderelection\" \"k8s.io/client-go/tools/leaderelection/resourcelock\" \"k8s.io/klog\" ) func buildConfig(kubeconfig string) (*rest.Config, error) { if kubeconfig != \"\" { cfg, err := clientcmd.BuildConfigFromFlags(\"\", kubeconfig) if err != nil { return nil, err } return cfg, nil } cfg, err := rest.InClusterConfig() if err != nil { return nil, err } return cfg, nil } func main() { klog.InitFlags(nil) var kubeconfig string var leaseLockName string var leaseLockNamespace string var id string flag.StringVar(\u0026kubeconfig, \"kubeconfig\", \"\", \"absolute path to the kubeconfig file\") flag.StringVar(\u0026id, \"id\", uuid.New().String(), \"the holder identity name\") flag.StringVar(\u0026leaseLockName, \"lease-lock-name\", \"\", \"the lease lock resource name\") flag.StringVar(\u0026leaseLockNamespace, \"lease-lock-namespace\", \"\", \"the lease lock resource namespace\") flag.Parse() if leaseLockName == \"\" { klog.Fatal(\"unable to get lease lock resource name (missing lease-lock-name flag).\") } if leaseLockNamespace == \"\" { klog.Fatal(\"unable to get lease lock resource namespace (missing lease-lock-namespace flag).\") } // leader election uses the Kubernetes API by writing to a // lock object, which can be a LeaseLock object (preferred), // a ConfigMap, or an Endpoints (deprecated) object. // Conflicting writes are detected and each client handles those actions // independently. config, err := buildConfig(kubeconfig) if err != nil { klog.Fatal(err) } client := clientset.NewForConfigOrDie(config) run := func(ctx context.Context) { // complete your controller loop here klog.Info(\"Controller loop...\") select {} } // use a Go context so we can tell the leaderelection code when we // want to step down ctx, cancel := context.WithCancel(context.Background()) defer cancel() // listen for interrupts or the Linux SIGTERM signal and cancel // our context, which the leader election code will observe and // step down ch := make(chan os.Signal, 1) signal.Notify(ch, os.Interrupt, syscall.SIGTERM) go func() { \u003c-ch klog.Info(\"Received termination, signaling shutdown\") cancel() }() // we use the Lease lock type since edits to Leases are less common // and fewer objects in the cluster watch \"all Leases\". // æŒ‡å®šé”çš„èµ„æºå¯¹è±¡ï¼Œè¿™é‡Œä½¿ç”¨äº†Leaseèµ„æºï¼Œè¿˜æ”¯æŒconfigmapï¼Œendpointï¼Œæˆ–è€…multilock(å³å¤šç§é…åˆä½¿ç”¨) lock := \u0026resourcelock.LeaseLock{ LeaseMeta: metav1.ObjectMeta{ Name: leaseLockName, Namespace: leaseLockNamespace, }, Client: client.CoordinationV1(), LockConfig: resourcelock.ResourceLockConfig{ Identity: id, }, } // start the leader election code loop leaderelection.RunOrDie(ctx, leaderelection.LeaderElectionConfig{ Lock: lock, // IMPORTANT: you MUST ensure that any code you have that // is protected by the lease must terminate **before** // you call cancel. Otherwise, you could have a background // loop still running and another process could // get elected before your background loop finished, violating // the stated goal of the lease. ReleaseOnCancel: true, LeaseDuration: 60 * time.Second,//ç§Ÿçº¦æ—¶é—´ RenewDeadline: 15 * time.Second,//æ›´æ–°ç§Ÿçº¦çš„ RetryPeriod: 5 * time.Second,//éleaderèŠ‚ç‚¹é‡è¯•æ—¶é—´ Callbacks: leaderelection.LeaderCallbacks{ OnStartedLeading: func(ctx context.Context) { //å˜ä¸ºleaderæ‰§è¡Œçš„ä¸šåŠ¡ä»£ç  // we're notified when we start - this is where you would // usually put your code run(ctx) }, OnStoppedLeading: func() { // è¿›ç¨‹é€€å‡º // we can do cleanup here klog.Infof(\"leader lost: %s\", id) os.Exit(0) }, OnNewLeader: func(identity string) { //å½“äº§ç”Ÿæ–°çš„leaderåæ‰§è¡Œçš„æ–¹æ³• // we're notified when new leader elected if identity == id { // I just got the lock return } klog.Infof(\"new leader elected: %s\", identity) }, }, }) } å…³é”®å¯åŠ¨å‚æ•°è¯´æ˜ï¼š\nkubeconfig: æŒ‡å®škubeconfigæ–‡ä»¶åœ°å€ lease-lock-nameï¼šæŒ‡å®šlockçš„åç§° lease-lock-namespaceï¼šæŒ‡å®šlockå­˜å‚¨çš„namespace id: ä¾‹å­ä¸­æä¾›çš„åŒºåˆ«å‚æ•°ï¼Œç”¨äºåŒºåˆ†å®ä¾‹ logtostderrï¼šklogæä¾›çš„å‚æ•°ï¼ŒæŒ‡å®šlogè¾“å‡ºåˆ°æ§åˆ¶å° v: æŒ‡å®šæ—¥å¿—è¾“å‡ºçº§åˆ« åŒæ—¶å¯åŠ¨ä¸¤ä¸ªè¿›ç¨‹ï¼š\nå¯åŠ¨è¿›ç¨‹1ï¼š\ngo run main.go -kubeconfig=/Users/silenceper/.kube/config -logtostderr=true -lease-lock-name=example -lease-lock-namespace=default -id=1 -v=4 I0215 19:56:37.049658 48045 leaderelection.go:242] attempting to acquire leader lease default/example... I0215 19:56:37.080368 48045 leaderelection.go:252] successfully acquired lease default/example I0215 19:56:37.080437 48045 main.go:87] Controller loop... å¯åŠ¨è¿›ç¨‹2ï¼š\nâœ leaderelection git:(master) âœ— go run main.go -kubeconfig=/Users/silenceper/.kube/config -logtostderr=true -lease-lock-name=example -lease-lock-namespace=default -id=2 -v=4 I0215 19:57:35.870051 48791 leaderelection.go:242] attempting to acquire leader lease default/example... I0215 19:57:35.894735 48791 leaderelection.go:352] lock is held by 1 and has not yet expired I0215 19:57:35.894769 48791 leaderelection.go:247] failed to acquire lease default/example I0215 19:57:35.894790 48791 main.go:151] new leader elected: 1 I0215 19:57:44.532991 48791 leaderelection.go:352] lock is held by 1 and has not yet expired I0215 19:57:44.533028 48791 leaderelection.go:247] failed to acquire lease default/example è¿™é‡Œå¯ä»¥çœ‹å‡ºæ¥id=1çš„è¿›ç¨‹æŒæœ‰é”ï¼Œå¹¶ä¸”è¿è¡Œçš„ç¨‹åºï¼Œè€Œid=2çš„è¿›ç¨‹è¡¨ç¤ºæ— æ³•è·å–åˆ°é”ï¼Œåœ¨ä¸æ–­çš„è¿›ç¨‹å°è¯•ã€‚\nç°åœ¨killæ‰id=1è¿›ç¨‹ï¼Œåœ¨ç­‰å¾…locké‡Šæ”¾ä¹‹åï¼ˆæœ‰ä¸ªLeaseDurationæ—¶é—´ï¼‰ï¼Œleaderå˜ä¸ºid=2çš„è¿›ç¨‹æ‰§è¡Œå·¥ä½œ\nI0215 20:01:41.489300 48791 leaderelection.go:252] successfully acquired lease default/example I0215 20:01:41.489577 48791 main.go:87] Controller loop... ","æ€»ç»“#æ€»ç»“":"leaderelection ä¸»è¦æ˜¯åˆ©ç”¨äº†k8s APIæ“ä½œçš„åŸå­æ€§å®ç°äº†ä¸€ä¸ªåˆ†å¸ƒå¼é”ï¼Œåœ¨ä¸æ–­çš„ç«äº‰ä¸­è¿›è¡Œé€‰ä¸¾ã€‚é€‰ä¸­ä¸ºleaderçš„è¿›è¡Œæ‰ä¼šæ‰§è¡Œå…·ä½“çš„ä¸šåŠ¡ä»£ç ï¼Œè¿™åœ¨k8sä¸­éå¸¸çš„å¸¸è§ï¼Œè€Œä¸”æˆ‘ä»¬å¾ˆæ–¹ä¾¿çš„åˆ©ç”¨è¿™ä¸ªåŒ…å®Œæˆç»„ä»¶çš„ç¼–å†™ï¼Œä»è€Œå®ç°ç»„ä»¶çš„é«˜å¯ç”¨ï¼Œæ¯”å¦‚éƒ¨ç½²ä¸ºä¸€ä¸ªå¤šå‰¯æœ¬çš„Deploymentï¼Œå½“leaderçš„podé€€å‡ºåä¼šé‡æ–°å¯åŠ¨ï¼Œå¯èƒ½é”å°±è¢«å…¶ä»–podè·å–ç»§ç»­æ‰§è¡Œã€‚\nå®Œæ•´ä»£ç ï¼šhttps://github.com/go-demo/leaderelection","æ·±å…¥ç†è§£#æ·±å…¥ç†è§£":"åŸºæœ¬åŸç†å…¶å®å°±æ˜¯åˆ©ç”¨é€šè¿‡Kubernetesä¸­ configmapÂ ï¼ŒÂ endpointsÂ æˆ–è€… leaseÂ èµ„æºå®ç°ä¸€ä¸ªåˆ†å¸ƒå¼é”ï¼ŒæŠ¢(acqure)åˆ°é”çš„èŠ‚ç‚¹æˆä¸ºleaderï¼Œå¹¶ä¸”å®šæœŸæ›´æ–°ï¼ˆrenewï¼‰ã€‚å…¶ä»–è¿›ç¨‹ä¹Ÿåœ¨ä¸æ–­çš„å°è¯•è¿›è¡ŒæŠ¢å ï¼ŒæŠ¢å ä¸åˆ°åˆ™ç»§ç»­ç­‰å¾…ä¸‹æ¬¡å¾ªç¯ã€‚å½“leaderèŠ‚ç‚¹æŒ‚æ‰ä¹‹åï¼Œç§Ÿçº¦åˆ°æœŸï¼Œå…¶ä»–èŠ‚ç‚¹å°±æˆä¸ºæ–°çš„leaderã€‚\nå…¥å£ é€šè¿‡ leaderelection.RunOrDieÂ å¯åŠ¨ï¼Œ\nfunc RunOrDie(ctx context.Context, lec LeaderElectionConfig) { le, err := NewLeaderElector(lec) if err != nil { panic(err) } if lec.WatchDog != nil { lec.WatchDog.SetLeaderElection(le) } le.Run(ctx) } ä¼ å…¥å‚æ•° LeaderElectionConfigÂ ï¼š\ntype LeaderElectionConfig struct { // Lock çš„ç±»å‹ Lock rl.Interface //æŒæœ‰é”çš„æ—¶é—´ LeaseDuration time.Duration //åœ¨æ›´æ–°ç§Ÿçº¦çš„è¶…æ—¶æ—¶é—´ RenewDeadline time.Duration //ç«äº‰è·å–é”çš„æ—¶é—´ RetryPeriod time.Duration //çŠ¶æ€å˜åŒ–æ—¶æ‰§è¡Œçš„å‡½æ•°ï¼Œæ”¯æŒä¸‰ç§ï¼š //1ã€OnStartedLeading å¯åŠ¨æ˜¯æ‰§è¡Œçš„ä¸šåŠ¡ä»£ç  //2ã€OnStoppedLeading leaderåœæ­¢æ‰§è¡Œçš„æ–¹æ³• //3ã€OnNewLeader å½“äº§ç”Ÿæ–°çš„leaderåæ‰§è¡Œçš„æ–¹æ³• Callbacks LeaderCallbacks //è¿›è¡Œç›‘æ§æ£€æŸ¥ // WatchDog is the associated health checker // WatchDog may be null if its not needed/configured. WatchDog *HealthzAdaptor //leaderé€€å‡ºæ—¶ï¼Œæ˜¯å¦æ‰§è¡Œreleaseæ–¹æ³• ReleaseOnCancel bool // Name is the name of the resource lock for debugging Name string } LeaderElectionConfig.lockÂ æ”¯æŒä¿å­˜åœ¨ä»¥ä¸‹ä¸‰ç§èµ„æºä¸­ï¼š\nconfigmapÂ endpointÂ leaseÂ åŒ…ä¸­è¿˜æä¾›äº†ä¸€ä¸ª multilockÂ ï¼Œå³å¯ä»¥è¿›è¡Œé€‰æ‹©ä¸¤ç§ï¼Œå½“å…¶ä¸­ä¸€ç§ä¿å­˜å¤±è´¥æ—¶ï¼Œé€‰æ‹©ç¬¬äºŒå¼ \nå¯ä»¥åœ¨interface.goä¸­çœ‹åˆ°ï¼š\nswitch lockType { case EndpointsResourceLock://ä¿å­˜åœ¨endpoints return endpointsLock, nil case ConfigMapsResourceLock://ä¿å­˜åœ¨configmaps return configmapLock, nil case LeasesResourceLock://ä¿å­˜åœ¨leases return leaseLock, nil case EndpointsLeasesResourceLock://ä¼˜å…ˆå°è¯•ä¿å­˜åœ¨endpointå¤±è´¥æ—¶ä¿å­˜åœ¨lease return \u0026MultiLock{ Primary: endpointsLock, Secondary: leaseLock, }, nil case ConfigMapsLeasesResourceLock://ä¼˜å…ˆå°è¯•ä¿å­˜åœ¨configmapï¼Œå¤±è´¥æ—¶ä¿å­˜åœ¨lease return \u0026MultiLock{ Primary: configmapLock, Secondary: leaseLock, }, nil default: return nil, fmt.Errorf(\"Invalid lock-type %s\", lockType) } ä»¥leaseèµ„æºå¯¹è±¡ä¸ºä¾‹ï¼Œå¯ä»¥åœ¨æŸ¥çœ‹åˆ°ä¿å­˜çš„å†…å®¹:\nâœ ~ kubectl get lease example -n default -o yaml apiVersion: coordination.k8s.io/v1 kind: Lease metadata: creationTimestamp: \"2020-02-15T11:56:37Z\" name: example namespace: default resourceVersion: \"210675\" selfLink: /apis/coordination.k8s.io/v1/namespaces/default/leases/example uid: a3470a06-6fc3-42dc-8242-9d6cebdf5315 spec: acquireTime: \"2020-02-15T12:01:41.476971Z\"//è·å¾—é”æ—¶é—´ holderIdentity: \"2\"//æŒæœ‰é”è¿›ç¨‹çš„æ ‡è¯† leaseDurationSeconds: 60//leaseç§Ÿçº¦ leaseTransitions: 1//leaderæ›´æ¢æ¬¡æ•° renewTime: \"2020-02-15T12:05:37.134655Z\"//æ›´æ–°ç§Ÿçº¦çš„æ—¶é—´ å…³æ³¨å…¶specä¸­çš„å­—æ®µï¼Œåˆ†åˆ«è¿›è¡Œæ ‡æ³¨,å¯¹åº”ç»“æ„ä½“å¦‚ä¸‹ï¼š\ntype LeaderElectionRecord struct { HolderIdentity string `json:\"holderIdentity\"`//æŒæœ‰é”è¿›ç¨‹çš„æ ‡è¯†ï¼Œä¸€èˆ¬å¯ä»¥åˆ©ç”¨ä¸»æœºå LeaseDurationSeconds int `json:\"leaseDurationSeconds\"`// lockçš„ç§Ÿçº¦ AcquireTime metav1.Time `json:\"acquireTime\"`//æŒæœ‰é”çš„æ—¶é—´ RenewTime metav1.Time `json:\"renewTime\"`//æ›´æ–°æ—¶é—´ LeaderTransitions int `json:\"leaderTransitions\"`//leaderæ›´æ¢çš„æ¬¡æ•° } è·å–çš„é”ä»¥åŠæ›´æ–°é” Runæ–¹æ³•ä¸­åŒ…å«äº†è·å–é”ä»¥åŠæ›´æ–°é”çš„å…¥å£\n// Run starts the leader election loop func (le *LeaderElector) Run(ctx context.Context) { defer func() { //è¿›è¡Œé€€å‡ºæ‰§è¡Œ runtime.HandleCrash() //åœæ­¢æ—¶æ‰§è¡Œå›è°ƒæ–¹æ³• le.config.Callbacks.OnStoppedLeading() }() //ä¸æ–­çš„è¿›è¡Œè·å¾—é”ï¼Œå¦‚æœè·å¾—é”æˆåŠŸåˆ™æ‰§è¡Œåé¢çš„æ–¹æ³•ï¼Œå¦åˆ™ä¸æ–­çš„è¿›è¡Œé‡è¯• if !le.acquire(ctx) { return // ctx signalled done } ctx, cancel := context.WithCancel(ctx) defer cancel() //è·å–é”æˆåŠŸï¼Œå½“å‰è¿›ç¨‹å˜ä¸ºleaderï¼Œæ‰§è¡Œå›è°ƒå‡½æ•°ä¸­çš„ä¸šåŠ¡ä»£ç  go le.config.Callbacks.OnStartedLeading(ctx) //ä¸æ–­çš„å¾ªç¯è¿›è¡Œè¿›è¡Œç§Ÿçº¦çš„æ›´æ–°ï¼Œä¿è¯é”ä¸€ç›´è¢«å½“å‰è¿›è¡ŒæŒæœ‰ le.renew(ctx) } le.acquire å’Œ le.renew å†…éƒ¨éƒ½æ˜¯è°ƒç”¨äº† le.tryAcquireOrRenew å‡½æ•°ï¼Œåªæ˜¯å¯¹äºè¿”å›ç»“æœçš„å¤„ç†ä¸ä¸€æ ·ã€‚\nle.acquire å¯¹äº le.tryAcquireOrRenew è¿”å›æˆåŠŸåˆ™é€€å‡ºï¼Œå¤±è´¥åˆ™ç»§ç»­ã€‚\nle.renew åˆ™ç›¸åï¼ŒæˆåŠŸåˆ™ç»§ç»­ï¼Œå¤±è´¥åˆ™é€€å‡ºã€‚\næˆ‘ä»¬æ¥çœ‹çœ‹ tryAcquireOrRenewÂ æ–¹æ³•ï¼š\nfunc (le *LeaderElector) tryAcquireOrRenew() bool { now := metav1.Now() //é”èµ„æºå¯¹è±¡å†…å®¹ leaderElectionRecord := rl.LeaderElectionRecord{ HolderIdentity: le.config.Lock.Identity(),//å”¯ä¸€æ ‡è¯† LeaseDurationSeconds: int(le.config.LeaseDuration / time.Second), RenewTime: now, AcquireTime: now, } // 1. obtain or create the ElectionRecord // ç¬¬ä¸€æ­¥ï¼šä»k8sèµ„æºä¸­è·å–åŸæœ‰çš„é” oldLeaderElectionRecord, oldLeaderElectionRawRecord, err := le.config.Lock.Get() if err != nil { if !errors.IsNotFound(err) { klog.Errorf(\"error retrieving resource lock %v: %v\", le.config.Lock.Describe(), err) return false } //èµ„æºå¯¹è±¡ä¸å­˜åœ¨ï¼Œè¿›è¡Œé”èµ„æºåˆ›å»º if err = le.config.Lock.Create(leaderElectionRecord); err != nil { klog.Errorf(\"error initially creating leader election record: %v\", err) return false } le.observedRecord = leaderElectionRecord le.observedTime = le.clock.Now() return true } // 2. Record obtained, check the Identity \u0026 Time // ç¬¬äºŒæ­¥ï¼Œå¯¹æ¯”å­˜å‚¨åœ¨k8sä¸­çš„é”èµ„æºä¸ä¸Šä¸€æ¬¡è·å–çš„é”èµ„æºæ˜¯å¦ä¸€è‡´ if !bytes.Equal(le.observedRawRecord, oldLeaderElectionRawRecord) { le.observedRecord = *oldLeaderElectionRecord le.observedRawRecord = oldLeaderElectionRawRecord le.observedTime = le.clock.Now() } //åˆ¤æ–­æŒæœ‰çš„é”æ˜¯å¦åˆ°æœŸä»¥åŠæ˜¯å¦è¢«è‡ªå·±æŒæœ‰ if len(oldLeaderElectionRecord.HolderIdentity) \u003e 0 \u0026\u0026 le.observedTime.Add(le.config.LeaseDuration).After(now.Time) \u0026\u0026 !le.IsLeader() { klog.V(4).Infof(\"lock is held by %v and has not yet expired\", oldLeaderElectionRecord.HolderIdentity) return false } // 3. We're going to try to update. The leaderElectionRecord is set to it's default // here. Let's correct it before updating. //ç¬¬ä¸‰æ­¥ï¼šè‡ªå·±ç°åœ¨æ˜¯leaderï¼Œä½†æ˜¯åˆ†ä¸¤ç»„æƒ…å†µï¼Œä¸Šä¸€æ¬¡ä¹Ÿæ˜¯leaderå’Œé¦–æ¬¡å˜ä¸ºleader if le.IsLeader() { //è‡ªå·±æœ¬èº«å°±æ˜¯leaderåˆ™ä¸éœ€è¦æ›´æ–°AcquireTimeå’ŒLeaderTransitions leaderElectionRecord.AcquireTime = oldLeaderElectionRecord.AcquireTime leaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions } else { //é¦–æ¬¡è‡ªå·±å˜ä¸ºleaderåˆ™æ›´æ–°leaderçš„æ›´æ¢æ¬¡æ•° leaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions + 1 } //æ›´æ–°é”èµ„æºï¼Œè¿™é‡Œå¦‚æœåœ¨ Get å’Œ Update ä¹‹é—´æœ‰å˜åŒ–ï¼Œå°†ä¼šæ›´æ–°å¤±è´¥ // update the lock itself if err = le.config.Lock.Update(leaderElectionRecord); err != nil { klog.Errorf(\"Failed to update lock: %v\", err) return false } le.observedRecord = leaderElectionRecord le.observedTime = le.clock.Now() return true } åœ¨è¿™ä¸€æ­¥å¦‚æœå‘ç”Ÿå¹¶å‘æ“ä½œæ€ä¹ˆæ ·ï¼Ÿ\nè¿™é‡Œå¾ˆé‡è¦ä¸€ç‚¹å°±æ˜¯åˆ©ç”¨åˆ°äº†k8s apiæ“ä½œçš„åŸå­æ€§ï¼š\nåœ¨ le.config.Lock.Get() ä¸­ä¼šè·å–åˆ°é”çš„å¯¹è±¡ï¼Œå…¶ä¸­æœ‰ä¸€ä¸ª resourceVersion å­—æ®µç”¨äºæ ‡è¯†ä¸€ä¸ªèµ„æºå¯¹è±¡çš„å†…éƒ¨ç‰ˆæœ¬ï¼Œæ¯æ¬¡æ›´æ–°æ“ä½œéƒ½ä¼šæ›´æ–°å…¶å€¼ã€‚å¦‚æœä¸€ä¸ªæ›´æ–°æ“ä½œé™„åŠ ä¸Šäº† resourceVersion å­—æ®µï¼Œé‚£ä¹ˆ apiserver å°±ä¼šé€šè¿‡éªŒè¯å½“å‰ resourceVersion çš„å€¼ä¸æŒ‡å®šçš„å€¼æ˜¯å¦ç›¸åŒ¹é…æ¥ç¡®ä¿åœ¨æ­¤æ¬¡æ›´æ–°æ“ä½œå‘¨æœŸå†…æ²¡æœ‰å…¶ä»–çš„æ›´æ–°æ“ä½œï¼Œä»è€Œä¿è¯äº†æ›´æ–°æ“ä½œçš„åŸå­æ€§ã€‚"},"title":"åˆ©ç”¨Kubernetesä¸­çš„leaderelectionå®ç°ç»„ä»¶é«˜å¯ç”¨"},"/blog/202003/kubernetes-event/":{"data":{"":"æˆ‘ä»¬é€šè¿‡ kubectl describe [èµ„æº]Â å‘½ä»¤ï¼Œå¯ä»¥åœ¨çœ‹åˆ°Eventè¾“å‡ºï¼Œå¹¶ä¸”ç»å¸¸ä¾èµ–eventè¿›è¡Œé—®é¢˜å®šä½ï¼Œä»eventä¸­å¯ä»¥åˆ†ææ•´ä¸ªPODçš„è¿è¡Œè½¨è¿¹ï¼Œä¸ºæœåŠ¡çš„å®¢è§‚æµ‹æ€§æä¾›æ•°æ®æ¥æºï¼Œç”±æ­¤å¯è§ï¼Œeventåœ¨Kubernetesä¸­èµ·ç€ä¸¾è¶³è½»é‡çš„ä½œç”¨ã€‚\neventå¹¶ä¸åªæ˜¯kubeletä¸­éƒ½æœ‰çš„ï¼Œå…³äºeventçš„æ“ä½œè¢«å°è£…åœ¨client-go/tools/recordåŒ…ï¼Œæˆ‘ä»¬å®Œå…¨å¯ä»¥åœ¨å†™å…¥è‡ªå®šä¹‰çš„eventã€‚\nç°åœ¨è®©æˆ‘ä»¬æ¥ä¸€æ­¥æ­¥æ­å¼€eventçš„é¢çº±ã€‚ ","eventå®šä¹‰#Eventå®šä¹‰":"å…¶å®eventä¹Ÿæ˜¯ä¸€ä¸ªèµ„æºå¯¹è±¡ï¼Œå¹¶ä¸”é€šè¿‡apiserverå°†eventå­˜å‚¨åœ¨etcdä¸­ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ kubectl get event å‘½ä»¤æŸ¥çœ‹å¯¹åº”çš„eventå¯¹è±¡ã€‚\nä»¥ä¸‹æ˜¯ä¸€ä¸ªeventçš„yamlæ–‡ä»¶ï¼š\napiVersion: v1 count: 1 eventTime: null firstTimestamp: \"2020-03-02T13:08:22Z\" involvedObject: apiVersion: v1 kind: Pod name: example-foo-d75d8587c-xsf64 namespace: default resourceVersion: \"429837\" uid: ce611c62-6c1a-4bd8-9029-136a1adf7de4 kind: Event lastTimestamp: \"2020-03-02T13:08:22Z\" message: Pod sandbox changed, it will be killed and re-created. metadata: creationTimestamp: \"2020-03-02T13:08:30Z\" name: example-foo-d75d8587c-xsf64.15f87ea1df862b64 namespace: default resourceVersion: \"479466\" selfLink: /api/v1/namespaces/default/events/example-foo-d75d8587c-xsf64.15f87ea1df862b64 uid: 9fe6f72a-341d-4c49-960b-e185982d331a reason: SandboxChanged reportingComponent: \"\" reportingInstance: \"\" source: component: kubelet host: minikube type: Normal **\nä¸»è¦å­—æ®µè¯´æ˜ï¼š\ninvolvedObjectï¼š è§¦å‘eventçš„èµ„æºç±»å‹ lastTimestampï¼šæœ€åä¸€æ¬¡è§¦å‘çš„æ—¶é—´ messageï¼šäº‹ä»¶è¯´æ˜ metadata :eventçš„å…ƒä¿¡æ¯ï¼Œnameï¼Œnamespaceç­‰ reasonï¼ševentçš„åŸå›  sourceï¼šä¸ŠæŠ¥äº‹ä»¶çš„æ¥æºï¼Œæ¯”å¦‚kubeletä¸­çš„æŸä¸ªèŠ‚ç‚¹ type:äº‹ä»¶ç±»å‹ï¼ŒNormalæˆ–Warning eventå­—æ®µå®šä¹‰å¯ä»¥çœ‹è¿™é‡Œï¼štypes.go#L5078\næ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹çœ‹ï¼Œæ•´ä¸ªeventæ˜¯å¦‚ä½•ä¸‹å…¥çš„ã€‚","å†™å…¥äº‹ä»¶#å†™å…¥äº‹ä»¶":" 1ã€è¿™é‡Œä»¥kubeletä¸ºä¾‹ï¼Œçœ‹çœ‹æ˜¯å¦‚ä½•è¿›è¡Œäº‹ä»¶å†™å…¥çš„\n2ã€æ–‡ä¸­ä»£ç ä»¥Kubernetes 1.17.3ä¸ºä¾‹è¿›è¡Œåˆ†æ\nå…ˆä»¥ä¸€å¹…å›¾æ¥çœ‹ä¸‹æ•´ä¸ªçš„å¤„ç†æµç¨‹ åˆ›å»ºæ“ä½œäº‹ä»¶çš„å®¢æˆ·ç«¯ï¼š\nkubelet/app/server.go#L461\n// makeEventRecorder sets up kubeDeps.Recorder if it's nil. It's a no-op otherwise. func makeEventRecorder(kubeDeps *kubelet.Dependencies, nodeName types.NodeName) { if kubeDeps.Recorder != nil { return } //äº‹ä»¶å¹¿æ’­ eventBroadcaster := record.NewBroadcaster() //åˆ›å»ºEventRecorder kubeDeps.Recorder = eventBroadcaster.NewRecorder(legacyscheme.Scheme, v1.EventSource{Component: componentKubelet, Host: string(nodeName)}) //å‘é€eventè‡³logè¾“å‡º eventBroadcaster.StartLogging(klog.V(3).Infof) if kubeDeps.EventClient != nil { klog.V(4).Infof(\"Sending events to api server.\") //å‘é€eventè‡³apiserver eventBroadcaster.StartRecordingToSink(\u0026v1core.EventSinkImpl{Interface: kubeDeps.EventClient.Events(\"\")}) } else { klog.Warning(\"No api server defined - no events will be sent to API server.\") } } é€šè¿‡ makeEventRecorderÂ åˆ›å»ºäº† EventRecorderÂ å®ä¾‹ï¼Œè¿™æ˜¯ä¸€ä¸ªäº‹ä»¶å¹¿æ’­å™¨ï¼Œé€šè¿‡å®ƒæä¾›äº†StartLoggingå’ŒStartRecordingToSinkä¸¤ä¸ªäº‹ä»¶å¤„ç†å‡½æ•°ï¼Œåˆ†åˆ«å°†eventå‘é€ç»™logå’Œapiserverã€‚\nNewRecorderåˆ›å»ºäº† EventRecorderÂ çš„å®ä¾‹ï¼Œå®ƒæä¾›äº† EventÂ ï¼ŒEventfÂ ç­‰æ–¹æ³•ä¾›äº‹ä»¶è®°å½•ã€‚\nEventBroadcaster æˆ‘ä»¬æ¥çœ‹ä¸‹EventBroadcasteræ¥å£å®šä¹‰ï¼ševent.go#L113\n// EventBroadcaster knows how to receive events and send them to any EventSink, watcher, or log. type EventBroadcaster interface { // StartEventWatcher(eventHandler func(*v1.Event)) watch.Interface StartRecordingToSink(sink EventSink) watch.Interface StartLogging(logf func(format string, args ...interface{})) watch.Interface NewRecorder(scheme *runtime.Scheme, source v1.EventSource) EventRecorder Shutdown() } å…·ä½“å®ç°æ˜¯é€šè¿‡Â eventBroadcasterImplÂ structæ¥å®ç°äº†å„ä¸ªæ–¹æ³•ã€‚\nå…¶ä¸­StartLogging å’Œ StartRecordingToSink å…¶å®å°±æ˜¯å®Œæˆäº†å¯¹äº‹ä»¶çš„æ¶ˆè´¹ï¼ŒEventRecorderå®ç°å¯¹äº‹ä»¶çš„å†™å…¥ï¼Œä¸­é—´é€šè¿‡channelå®ç°äº†ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å‹ã€‚ EventRecorder æˆ‘ä»¬å…ˆæ¥çœ‹ä¸‹EventRecorderÂ æ¥å£å®šä¹‰ï¼ševent.go#L88ï¼Œæä¾›äº†ä¸€ä¸‹4ä¸ªæ–¹æ³•\n// EventRecorder knows how to record events on behalf of an EventSource. type EventRecorder interface { // Event constructs an event from the given information and puts it in the queue for sending. // 'object' is the object this event is about. Event will make a reference-- or you may also // pass a reference to the object directly. // 'type' of this event, and can be one of Normal, Warning. New types could be added in future // 'reason' is the reason this event is generated. 'reason' should be short and unique; it // should be in UpperCamelCase format (starting with a capital letter). \"reason\" will be used // to automate handling of events, so imagine people writing switch statements to handle them. // You want to make that easy. // 'message' is intended to be human readable. // // The resulting event will be created in the same namespace as the reference object. Event(object runtime.Object, eventtype, reason, message string) // Eventf is just like Event, but with Sprintf for the message field. Eventf(object runtime.Object, eventtype, reason, messageFmt string, args ...interface{}) // PastEventf is just like Eventf, but with an option to specify the event's 'timestamp' field. PastEventf(object runtime.Object, timestamp metav1.Time, eventtype, reason, messageFmt string, args ...interface{}) // AnnotatedEventf is just like eventf, but with annotations attached AnnotatedEventf(object runtime.Object, annotations map[string]string, eventtype, reason, messageFmt string, args ...interface{}) } ä¸»è¦å‚æ•°è¯´æ˜ï¼š\nobjectÂ å¯¹åº”eventèµ„æºå®šä¹‰ä¸­çš„ involvedObject eventtypeÂ å¯¹åº”eventèµ„æºå®šä¹‰ä¸­çš„typeï¼Œå¯é€‰Normalï¼ŒWarning. reasonÂ ï¼šäº‹ä»¶åŸå›  messageÂ ï¼šäº‹ä»¶æ¶ˆæ¯ æˆ‘ä»¬æ¥çœ‹ä¸‹å½“æˆ‘ä»¬è°ƒç”¨ Event(object runtime.Object, eventtype, reason, message string)Â çš„æ•´ä¸ªè¿‡ç¨‹ã€‚\nå‘ç°æœ€ç»ˆéƒ½è°ƒç”¨åˆ°äº† generateEventÂ æ–¹æ³•ï¼ševent.go#L316\nfunc (recorder *recorderImpl) generateEvent(object runtime.Object, annotations map[string]string, timestamp metav1.Time, eventtype, reason, message string) { ..... event := recorder.makeEvent(ref, annotations, eventtype, reason, message) event.Source = recorder.source go func() { // NOTE: events should be a non-blocking operation defer utilruntime.HandleCrash() recorder.Action(watch.Added, event) }() } æœ€ç»ˆäº‹ä»¶åœ¨ä¸€ä¸ª goroutineÂ ä¸­é€šè¿‡è°ƒç”¨ recorder.ActionÂ è¿›å…¥å¤„ç†ï¼Œè¿™é‡Œä¿è¯äº†æ¯æ¬¡è°ƒç”¨eventæ–¹æ³•éƒ½æ˜¯éé˜»å¡çš„ã€‚\nå…¶ä¸­ makeEventÂ çš„ä½œç”¨ä¸»è¦æ˜¯æ„é€ äº†ä¸€ä¸ªeventå¯¹è±¡ï¼Œäº‹ä»¶nameæ ¹æ®InvolvedObjectä¸­çš„nameåŠ ä¸Šæ—¶é—´æˆ³ç”Ÿæˆï¼š\næ³¨æ„çœ‹ï¼šå¯¹äºä¸€äº›énamespaceèµ„æºäº§ç”Ÿçš„eventï¼Œeventçš„namespaceæ˜¯default\nfunc (recorder *recorderImpl) makeEvent(ref *v1.ObjectReference, annotations map[string]string, eventtype, reason, message string) *v1.Event { t := metav1.Time{Time: recorder.clock.Now()} namespace := ref.Namespace if namespace == \"\" { namespace = metav1.NamespaceDefault } return \u0026v1.Event{ ObjectMeta: metav1.ObjectMeta{ Name: fmt.Sprintf(\"%v.%x\", ref.Name, t.UnixNano()), Namespace: namespace, Annotations: annotations, }, InvolvedObject: *ref, Reason: reason, Message: message, FirstTimestamp: t, LastTimestamp: t, Count: 1, Type: eventtype, } } è¿›ä¸€æ­¥è·Ÿè¸ªActionæ–¹æ³•ï¼Œapimachinery/blob/master/pkg/watch/mux.go#L188:23\n// Action distributes the given event among all watchers. func (m *Broadcaster) Action(action EventType, obj runtime.Object) { m.incoming \u003c- Event{action, obj} } å°†eventå†™å…¥åˆ°äº†ä¸€ä¸ªchannelé‡Œé¢ã€‚\næ³¨æ„ï¼š\nè¿™ä¸ªActionæ–¹å¼æ˜¯apimachineryåŒ…ä¸­çš„æ–¹æ³•ï¼Œå› ä¸ºå®ç°çš„sturtÂ recorderImpl\nå°† *watch.BroadcasterÂ ä½œä¸ºä¸€ä¸ªåŒ¿åstructï¼Œå¹¶ä¸”åœ¨ NewRecorderÂ è¿›è¡Œ BroadcasterÂ èµ‹å€¼ï¼Œè¿™ä¸ªBroadcasterå…¶å®å°±æ˜¯ eventBroadcasterImplÂ ä¸­çš„Broadcasterã€‚\nåˆ°æ­¤ï¼ŒåŸºæœ¬æ¸…æ¥šäº†eventæœ€ç»ˆè¢«å†™å…¥åˆ°äº† BroadcasterÂ ä¸­çš„ incomingÂ channelä¸­ï¼Œä¸‹é¢çœ‹ä¸‹æ˜¯æ€ä¹ˆè¿›è¡Œæ¶ˆè´¹çš„ã€‚","æ€»ç»“#æ€»ç»“":"å¥½äº†ï¼Œeventå¤„ç†çš„æ•´ä¸ªæµç¨‹åŸºæœ¬å°±æ˜¯è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥æ¦‚æ‹¬ä¸€ä¸‹ï¼Œå¯ä»¥ç»“åˆæ–‡ä¸­çš„å›¾å¯¹æ¯”ä¸€èµ·çœ‹ä¸‹ï¼š\nåˆ›å»º EventRecorderÂ å¯¹è±¡ï¼Œé€šè¿‡å…¶æä¾›çš„ EventÂ ç­‰æ–¹æ³•ï¼Œåˆ›å»ºå¥½eventå¯¹è±¡ å°†åˆ›å»ºå‡ºæ¥çš„å¯¹è±¡å‘é€ç»™ EventBroadcasterÂ ä¸­çš„channelä¸­ EventBroadcasterÂ é€šè¿‡åå°è¿è¡Œçš„goroutineï¼Œä»ç®¡é“ä¸­å–å‡ºäº‹ä»¶ï¼Œå¹¶å¹¿æ’­ç»™æå‰æ³¨å†Œå¥½çš„handlerå¤„ç† å½“è¾“å‡ºlogçš„handleræ”¶åˆ°äº‹ä»¶å°±ç›´æ¥æ‰“å°äº‹ä»¶ å½“ EventSinkÂ handleræ”¶åˆ°å¤„ç†äº‹ä»¶å°±é€šè¿‡é¢„å¤„ç†ä¹‹åå°†äº‹ä»¶å‘é€ç»™apiserver å…¶ä¸­é¢„å¤„ç†åŒ…å«ä¸‰ä¸ªåŠ¨ä½œï¼Œ1ã€é™æµ 2ã€èšåˆ 3ã€è®¡æ•° apiserveræ”¶åˆ°äº‹ä»¶å¤„ç†ä¹‹åå°±å­˜å‚¨åœ¨etcdä¸­ å›é¡¾eventçš„æ•´ä¸ªæµç¨‹ï¼Œå¯ä»¥çœ‹åˆ°eventå¹¶ä¸æ˜¯ä¿è¯100%äº‹ä»¶å†™å…¥ï¼ˆä»é¢„å¤„ç†çš„è¿‡ç¨‹æ¥çœ‹ï¼‰ï¼Œè¿™æ ·åšæ˜¯ä¸ºäº†åç«¯æœåŠ¡etcdçš„å¯ç”¨æ€§ï¼Œå› ä¸ºeventäº‹ä»¶åœ¨æ•´ä¸ªé›†ç¾¤ä¸­äº§ç”Ÿæ˜¯éå¸¸é¢‘ç¹çš„ï¼Œå°¤å…¶åœ¨æœåŠ¡ä¸ç¨³å®šçš„æ—¶å€™ï¼Œè€Œç›¸æ¯”Deployment,Podç­‰å…¶ä»–èµ„æºï¼Œåˆæ²¡é‚£ä¹ˆçš„é‡è¦ã€‚æ‰€ä»¥è¿™é‡Œåšäº†ä¸ªå–èˆã€‚\nå‚è€ƒæ–‡æ¡£ï¼š\nhttps://cizixs.com/2017/06/22/kubelet-source-code-analysis-part4-event/ ","æ¶ˆè´¹äº‹ä»¶#æ¶ˆè´¹äº‹ä»¶":"åœ¨ makeEventRecorderÂ è°ƒç”¨çš„ StartLoggingÂ å’Œ StartRecordingToSinkÂ å…¶å®å°±æ˜¯å®Œæˆäº†å¯¹äº‹ä»¶çš„æ¶ˆè´¹ã€‚\nStartLoggingç›´æ¥å°†eventè¾“å‡ºåˆ°æ—¥å¿— StartRecordingToSinkå°†äº‹ä»¶å†™å…¥åˆ°apiserver ä¸¤ä¸ªæ–¹æ³•å†…éƒ¨éƒ½è°ƒç”¨äº† StartEventWatcherÂ æ–¹æ³•ï¼Œå¹¶ä¸”ä¼ å…¥ä¸€ä¸ª eventHandlerÂ æ–¹æ³•å¯¹eventè¿›è¡Œå¤„ç†\nfunc (e *eventBroadcasterImpl) StartEventWatcher(eventHandler func(*v1.Event)) watch.Interface { watcher := e.Watch() go func() { defer utilruntime.HandleCrash() for watchEvent := range watcher.ResultChan() { event, ok := watchEvent.Object.(*v1.Event) if !ok { // This is all local, so there's no reason this should // ever happen. continue } eventHandler(event) } }() return watcher } å…¶ä¸­ watcher.ResultChanÂ æ–¹æ³•å°±æ‹¿åˆ°äº†äº‹ä»¶ï¼Œè¿™é‡Œæ˜¯åœ¨ä¸€ä¸ªgoroutineä¸­é€šè¿‡func (m *Broadcaster) loop() ==\u003efunc (m *Broadcaster) distribute(event Event)Â æ–¹æ³•è°ƒç”¨å°†eventåˆå†™å…¥äº†broadcasterWatcher.result\nä¸»è¦çœ‹ä¸‹ StartRecordingToSinkÂ æä¾›çš„çš„eventHandlerï¼Œ recordToSinkÂ æ–¹æ³•ï¼š\nfunc recordToSink(sink EventSink, event *v1.Event, eventCorrelator *EventCorrelator, sleepDuration time.Duration) { // Make a copy before modification, because there could be multiple listeners. // Events are safe to copy like this. eventCopy := *event event = \u0026eventCopy result, err := eventCorrelator.EventCorrelate(event) if err != nil { utilruntime.HandleError(err) } if result.Skip { return } tries := 0 for { if recordEvent(sink, result.Event, result.Patch, result.Event.Count \u003e 1, eventCorrelator) { break } tries++ if tries \u003e= maxTriesPerEvent { klog.Errorf(\"Unable to write event '%#v' (retry limit exceeded!)\", event) break } // Randomize the first sleep so that various clients won't all be // synced up if the master goes down. // ç¬¬ä¸€æ¬¡é‡è¯•å¢åŠ éšæœºæ€§ï¼Œé˜²æ­¢ apiserver é‡å¯çš„æ—¶å€™æ‰€æœ‰çš„äº‹ä»¶éƒ½åœ¨åŒä¸€æ—¶é—´å‘é€äº‹ä»¶ if tries == 1 { time.Sleep(time.Duration(float64(sleepDuration) * rand.Float64())) } else { time.Sleep(sleepDuration) } } } å…¶ä¸­eventè¢«ç»è¿‡äº†ä¸€ä¸ª eventCorrelator.EventCorrelate(event)Â æ–¹æ³•åšé¢„å¤„ç†ï¼Œä¸»è¦æ˜¯èšåˆç›¸åŒçš„äº‹ä»¶ï¼ˆé¿å…äº§ç”Ÿçš„äº‹ä»¶è¿‡å¤šï¼Œå¢åŠ  etcd å’Œ apiserver çš„å‹åŠ›ï¼Œä¹Ÿä¼šå¯¼è‡´æŸ¥çœ‹ pod äº‹ä»¶å¾ˆä¸æ¸…æ™°ï¼‰\nä¸‹é¢ä¸€ä¸ªforå¾ªç¯å°±æ˜¯åœ¨è¿›è¡Œé‡è¯•ï¼Œæœ€å¤§é‡è¯•æ¬¡æ•°æ˜¯12æ¬¡ï¼Œè°ƒç”¨ recordEventÂ æ–¹æ³•æ‰çœŸæ­£å°†eventå†™å…¥åˆ°äº†apiserverã€‚\näº‹ä»¶å¤„ç† æˆ‘ä»¬æ¥çœ‹ä¸‹EventCorrelateæ–¹æ³•ï¼š\n// EventCorrelate filters, aggregates, counts, and de-duplicates all incoming events func (c *EventCorrelator) EventCorrelate(newEvent *v1.Event) (*EventCorrelateResult, error) { if newEvent == nil { return nil, fmt.Errorf(\"event is nil\") } aggregateEvent, ckey := c.aggregator.EventAggregate(newEvent) observedEvent, patch, err := c.logger.eventObserve(aggregateEvent, ckey) if c.filterFunc(observedEvent) { return \u0026EventCorrelateResult{Skip: true}, nil } return \u0026EventCorrelateResult{Event: observedEvent, Patch: patch}, err } åˆ†åˆ«è°ƒç”¨äº† aggregator.EventAggregateÂ ï¼Œ logger.eventObserveÂ ï¼Œ filterFuncÂ ä¸‰ä¸ªæ–¹æ³•ï¼Œåˆ†åˆ«ä½œç”¨æ˜¯ï¼š\naggregator.EventAggregateï¼šèšåˆeventï¼Œå¦‚æœåœ¨æœ€è¿‘ 10 åˆ†é’Ÿå‡ºç°è¿‡ 10 ä¸ªç›¸ä¼¼çš„äº‹ä»¶ï¼ˆé™¤äº† message å’Œæ—¶é—´æˆ³ä¹‹å¤–å…¶ä»–å…³é”®å­—æ®µéƒ½ç›¸åŒçš„äº‹ä»¶ï¼‰ï¼Œaggregator ä¼šæŠŠå®ƒä»¬çš„ message è®¾ç½®ä¸ºÂ (combined from similar events)+event.Message logger.eventObserveï¼šå®ƒä¼šæŠŠç›¸åŒçš„äº‹ä»¶ä»¥åŠåŒ…å« aggregatorÂ è¢«èšåˆäº†çš„ç›¸ä¼¼çš„äº‹ä»¶ï¼Œé€šè¿‡å¢åŠ  CountÂ å­—æ®µæ¥è®°å½•äº‹ä»¶å‘ç”Ÿäº†å¤šå°‘æ¬¡ã€‚ filterFunc: è¿™é‡Œå®ç°äº†ä¸€ä¸ªåŸºäºä»¤ç‰Œæ¡¶çš„é™æµç®—æ³•ï¼Œå¦‚æœè¶…è¿‡è®¾å®šçš„é€Ÿç‡åˆ™ä¸¢å¼ƒï¼Œä¿è¯äº†apiserverçš„å®‰å…¨ã€‚ æˆ‘ä»¬ä¸»è¦æ¥çœ‹ä¸‹aggregator.EventAggregateæ–¹æ³•ï¼š\nfunc (e *EventAggregator) EventAggregate(newEvent *v1.Event) (*v1.Event, string) { now := metav1.NewTime(e.clock.Now()) var record aggregateRecord // eventKey is the full cache key for this event //eventKey æ˜¯å°†é™¤äº†æ—¶é—´æˆ³å¤–æ‰€æœ‰å­—æ®µç»“åˆåœ¨ä¸€èµ· eventKey := getEventKey(newEvent) // aggregateKey is for the aggregate event, if one is needed. //aggregateKey æ˜¯é™¤äº†messageå’Œæ—¶é—´æˆ³å¤–çš„å­—æ®µç»“åˆåœ¨ä¸€èµ·ï¼ŒlocalKey æ˜¯message aggregateKey, localKey := e.keyFunc(newEvent) // Do we have a record of similar events in our cache? e.Lock() defer e.Unlock() //ä»cacheä¸­æ ¹æ®aggregateKeyæŸ¥è¯¢æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœæ˜¯ç›¸åŒæˆ–è€…ç›¸ç±»ä¼¼çš„äº‹ä»¶ä¼šè¢«æ”¾å…¥cacheä¸­ value, found := e.cache.Get(aggregateKey) if found { record = value.(aggregateRecord) } //åˆ¤æ–­ä¸Šæ¬¡äº‹ä»¶äº§ç”Ÿçš„æ—¶é—´æ˜¯å¦è¶…è¿‡10åˆ†é’Ÿï¼Œå¦‚ä½•æ“ä½œåˆ™é‡æ–°ç”Ÿæˆä¸€ä¸ªlocalKeysé›†åˆï¼ˆé›†åˆä¸­å­˜æ”¾messageï¼‰ maxInterval := time.Duration(e.maxIntervalInSeconds) * time.Second interval := now.Time.Sub(record.lastTimestamp.Time) if interval \u003e maxInterval { record = aggregateRecord{localKeys: sets.NewString()} } // Write the new event into the aggregation record and put it on the cache //å°†locakKeyä¹Ÿå°±æ˜¯messageæ”¾å…¥é›†åˆä¸­ï¼Œå¦‚æœmessageç›¸åŒå°±æ˜¯è¦†ç›–äº† record.localKeys.Insert(localKey) record.lastTimestamp = now e.cache.Add(aggregateKey, record) // If we are not yet over the threshold for unique events, don't correlate them //åˆ¤æ–­localKeysé›†åˆä¸­å­˜æ”¾çš„ç±»ä¼¼äº‹ä»¶æ˜¯å¦è¶…è¿‡10ä¸ªï¼Œ if uint(record.localKeys.Len()) \u003c e.maxEvents { return newEvent, eventKey } // do not grow our local key set any larger than max record.localKeys.PopAny() // create a new aggregate event, and return the aggregateKey as the cache key // (so that it can be overwritten.) eventCopy := \u0026v1.Event{ ObjectMeta: metav1.ObjectMeta{ Name: fmt.Sprintf(\"%v.%x\", newEvent.InvolvedObject.Name, now.UnixNano()), Namespace: newEvent.Namespace, }, Count: 1, FirstTimestamp: now, InvolvedObject: newEvent.InvolvedObject, LastTimestamp: now, //è¿™é‡Œä¼šå¯¹messageåŠ ä¸ªå‰ç¼€ï¼š(combined from similar events): Message: e.messageFunc(newEvent), Type: newEvent.Type, Reason: newEvent.Reason, Source: newEvent.Source, } return eventCopy, aggregateKey } aggregator.EventAggregateæ–¹æ³•ä¸­å…¶å®å°±æ˜¯åˆ¤æ–­äº†é€šè¿‡cacheå’ŒlocalKeysåˆ¤æ–­äº‹ä»¶æ˜¯å¦ç›¸ä¼¼ï¼Œå¦‚æœæœ€è¿‘ 10 åˆ†é’Ÿå‡ºç°è¿‡ 10 ä¸ªç›¸ä¼¼çš„äº‹ä»¶å°±åˆå¹¶å¹¶åŠ ä¸Šå‰ç¼€ï¼Œåç»­é€šè¿‡logger.eventObserveæ–¹æ³•è¿›è¡Œcountç´¯åŠ ï¼Œå¦‚æœmessageä¹Ÿç›¸åŒï¼Œè‚¯å®šå°±æ˜¯ç›´æ¥count++ã€‚"},"title":"åˆ†ækubernetesä¸­çš„äº‹ä»¶æœºåˆ¶"},"/blog/202003/singleflight/":{"data":{"åŸç†è§£æ#åŸç†è§£æ":"singleflightÂ åŒ…ä¸»è¦æ˜¯ç”¨æ¥åšå¹¶å‘æ§åˆ¶ï¼Œå¸¸è§çš„æ¯”å¦‚é˜²æ­¢ ç¼“å­˜å‡»ç©¿Â ï¼Œæˆ‘ä»¬æ¥æ¨¡æ‹Ÿä¸€ä¸‹è¿™ç§åœºæ™¯ï¼š\nç¼“å­˜å‡»ç©¿ï¼šç¼“å­˜åœ¨æŸä¸ªæ—¶é—´ç‚¹è¿‡æœŸçš„æ—¶å€™ï¼Œæ°å¥½åœ¨è¿™ä¸ªæ—¶é—´ç‚¹å¯¹è¿™ä¸ªKeyæœ‰å¤§é‡çš„å¹¶å‘è¯·æ±‚è¿‡æ¥ï¼Œè¿™äº›è¯·æ±‚å‘ç°ç¼“å­˜è¿‡æœŸä¸€èˆ¬éƒ½ä¼šä»åç«¯DBåŠ è½½æ•°æ®å¹¶å›è®¾åˆ°ç¼“å­˜ï¼Œè¿™ä¸ªæ—¶å€™å¤§å¹¶å‘çš„è¯·æ±‚å¯èƒ½ä¼šç¬é—´æŠŠåç«¯DBå‹å®ã€‚Â package main import ( \"errors\" \"log\" \"sync\" \"golang.org/x/sync/singleflight\" ) var errorNotExist = errors.New(\"not exist\") func main() { var wg sync.WaitGroup wg.Add(10) //æ¨¡æ‹Ÿ10ä¸ªå¹¶å‘ for i := 0; i \u003c 10; i++ { go func() { defer wg.Done() data, err := getData(\"key\") if err != nil { log.Print(err) return } log.Println(data) }() } wg.Wait() } //è·å–æ•°æ® func getData(key string) (string, error) { data, err := getDataFromCache(key) if err == errorNotExist { //æ¨¡æ‹Ÿä»dbä¸­è·å–æ•°æ® data, err = getDataFromDB(key) if err != nil { log.Println(err) return \"\", err } //TOOD: set cache } else if err != nil { return \"\", err } return data, nil } //æ¨¡æ‹Ÿä»cacheä¸­è·å–å€¼ï¼Œcacheä¸­æ— è¯¥å€¼ func getDataFromCache(key string) (string, error) { return \"\", errorNotExist } //æ¨¡æ‹Ÿä»æ•°æ®åº“ä¸­è·å–å€¼ func getDataFromDB(key string) (string, error) { log.Printf(\"get %s from database\", key) return \"data\", nil } å…¶ä¸­é€šè¿‡ getData(key)æ–¹æ³•è·å–æ•°æ®ï¼Œé€»è¾‘æ˜¯ï¼š\nå…ˆå°è¯•ä»cacheä¸­è·å– å¦‚æœcacheä¸­ä¸å­˜åœ¨å°±ä»dbä¸­è·å– æˆ‘ä»¬æ¨¡æ‹Ÿäº†10ä¸ªå¹¶å‘è¯·æ±‚ï¼Œæ¥åŒæ—¶è°ƒç”¨ getDataÂ å‡½æ•°ï¼Œæ‰§è¡Œç»“æœå¦‚ä¸‹ï¼š\n2020/03/08 17:13:11 get key from database 2020/03/08 17:13:11 data 2020/03/08 17:13:11 get key from database 2020/03/08 17:13:11 data 2020/03/08 17:13:11 get key from database 2020/03/08 17:13:11 data 2020/03/08 17:13:11 get key from database 2020/03/08 17:13:11 data 2020/03/08 17:13:11 get key from database 2020/03/08 17:13:11 data 2020/03/08 17:13:11 get key from database 2020/03/08 17:13:11 data 2020/03/08 17:13:11 get key from database 2020/03/08 17:13:11 data 2020/03/08 17:13:11 get key from database 2020/03/08 17:13:11 data 2020/03/08 17:13:11 get key from database 2020/03/08 17:13:11 data 2020/03/08 17:13:11 get key from database 2020/03/08 17:13:11 data å¯ä»¥çœ‹å¾—åˆ°10ä¸ªè¯·æ±‚éƒ½æ˜¯èµ°çš„dbï¼Œå› ä¸ºcacheä¸­ä¸å­˜åœ¨è¯¥å€¼ï¼Œå½“æˆ‘ä»¬åˆ©ç”¨ä¸Š singlefligthÂ åŒ…ï¼Œ getDataÂ æ”¹åŠ¨ä¸€ä¸‹ï¼š\nimport \"golang.org/x/sync/singleflight\" var g singleflight.Group //è·å–æ•°æ® func getData(key string) (string, error) { data, err := getDataFromCache(key) if err == errorNotExist { //æ¨¡æ‹Ÿä»dbä¸­è·å–æ•°æ® v, err, _ := g.Do(key, func() (interface{}, error) { return getDataFromDB(key) //set cache }) if err != nil { log.Println(err) return \"\", err } //TOOD: set cache data = v.(string) } else if err != nil { return \"\", err } return data, nil } æ‰§è¡Œç»“æœå¦‚ä¸‹ï¼Œå¯ä»¥çœ‹å¾—åˆ°åªæœ‰ä¸€ä¸ªè¯·æ±‚è¿›å…¥çš„dbï¼Œå…¶ä»–çš„è¯·æ±‚ä¹Ÿæ­£å¸¸è¿”å›äº†å€¼ï¼Œä»è€Œä¿æŠ¤äº†åç«¯DBã€‚\n2020/03/08 17:18:16 get key from database 2020/03/08 17:18:16 data 2020/03/08 17:18:16 data 2020/03/08 17:18:16 data 2020/03/08 17:18:16 data 2020/03/08 17:18:16 data 2020/03/08 17:18:16 data 2020/03/08 17:18:16 data 2020/03/08 17:18:16 data 2020/03/08 17:18:16 data 2020/03/08 17:18:16 data åŸç†è§£æsingleflightÂ åœ¨ golang.org/x/sync/singleflightÂ é¡¹ç›®ä¸‹ï¼Œå¯¹å¤–æä¾›äº†ä»¥ä¸‹å‡ ä¸ªæ–¹æ³•\n//Doæ–¹æ³•ï¼Œä¼ å…¥keyï¼Œä»¥åŠå›è°ƒå‡½æ•°ï¼Œå¦‚æœkeyç›¸åŒï¼Œfnæ–¹æ³•åªä¼šæ‰§è¡Œä¸€æ¬¡ï¼ŒåŒæ­¥ç­‰å¾… //è¿”å›å€¼v:è¡¨ç¤ºfnæ‰§è¡Œç»“æœ //è¿”å›å€¼err:è¡¨ç¤ºfnçš„è¿”å›çš„err //ç¬¬ä¸‰ä¸ªè¿”å›å€¼sharedï¼šè¡¨ç¤ºæ˜¯å¦æ˜¯çœŸå®fnè¿”å›çš„è¿˜æ˜¯ä»ä¿å­˜çš„map[key]è¿”å›çš„ï¼Œä¹Ÿå°±æ˜¯å…±äº«çš„ func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) { //DoChanæ–¹æ³•ç±»ä¼¼Doæ–¹æ³•ï¼Œåªæ˜¯è¿”å›çš„æ˜¯ä¸€ä¸ªchan func (g *Group) DoChan(key string, fn func() (interface{}, error)) \u003c-chan Result { //æš‚æ—¶æœªç”¨åˆ°ï¼šè®¾è®¡Forget æ§åˆ¶keyå…³è”çš„å€¼æ˜¯å¦å¤±æ•ˆï¼Œé»˜è®¤ä»¥ä¸Šä¸¤ä¸ªæ–¹æ³•åªè¦fnæ–¹æ³•æ‰§è¡Œå®Œæˆåï¼Œå†…éƒ¨ç»´æŠ¤çš„fnçš„å€¼ä¹Ÿåˆ é™¤ï¼ˆå³å¹¶å‘ç»“æŸåå°±å¤±æ•ˆäº†ï¼‰ func (g *Group) Forget(key string) { ä»£ç ä¹Ÿå¾ˆç®€å•ï¼Œæˆ‘ä»¬æ‰“å¼€ä¸Šçœ‹ä¸‹ï¼Œæˆªå–äº†éƒ¨åˆ†ï¼š singleflight/singleflight.go\npackage singleflight // import \"golang.org/x/sync/singleflight\" import \"sync\" // call is an in-flight or completed singleflight.Do call type call struct { wg sync.WaitGroup // These fields are written once before the WaitGroup is done // and are only read after the WaitGroup is done. //valå’Œerrç”¨æ¥è®°å½•fnå‘æ”¾æ‰§è¡Œçš„è¿”å›å€¼ val interface{} err error // forgotten indicates whether Forget was called with this call's key // while the call was still in flight. // ç”¨æ¥æ ‡è¯†fnæ–¹æ³•æ‰§è¡Œå®Œæˆä¹‹åç»“æœæ˜¯å¦ç«‹é©¬åˆ é™¤è¿˜æ˜¯ä¿ç•™åœ¨singleflightä¸­ forgotten bool // These fields are read and written with the singleflight // mutex held before the WaitGroup is done, and are read but // not written after the WaitGroup is done. //dups ç”¨æ¥è®°å½•fnæ–¹æ³•æ‰§è¡Œçš„æ¬¡æ•° dups int //ç”¨æ¥è®°å½•DoChanä¸­è°ƒç”¨æ¬¡æ•°ä»¥åŠéœ€è¦è¿”å›çš„æ•°æ® chans []chan\u003c- Result } // Group represents a class of work and forms a namespace in // which units of work can be executed with duplicate suppression. type Group struct { mu sync.Mutex // protects m m map[string]*call // lazily initialized } // Do executes and returns the results of the given function, making // sure that only one execution is in-flight for a given key at a // time. If a duplicate comes in, the duplicate caller waits for the // original to complete and receives the same results. // The return value shared indicates whether v was given to multiple callers. func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) { g.mu.Lock() if g.m == nil { g.m = make(map[string]*call) } //check mapæ˜¯å¦å·²ç»å­˜åœ¨å€¼ if c, ok := g.m[key]; ok { c.dups++ g.mu.Unlock() c.wg.Wait() return c.val, c.err, true } c := new(call) c.wg.Add(1) g.m[key] = c g.mu.Unlock() g.doCall(c, key, fn) return c.val, c.err, c.dups \u003e 0 } //æ‰§è¡Œfnæ–¹æ³•ï¼Œå¹¶ä¸”wg.Done // doCall handles the single call for a key. func (g *Group) doCall(c *call, key string, fn func() (interface{}, error)) { c.val, c.err = fn() c.wg.Done() ... } åœ¨Doæ–¹æ³•ä¸­ä¸»è¦æ˜¯é€šè¿‡waitgroupæ¥æ§åˆ¶çš„ï¼Œä¸»è¦æµç¨‹å¦‚ä¸‹ï¼š\nåœ¨Groupä¸­è®¾ç½®äº†ä¸€ä¸ªmapï¼Œå¦‚æœkeyä¸å­˜åœ¨ï¼Œåˆ™å®ä¾‹åŒ–call(ç”¨æ¥ä¿å­˜å€¼ä¿¡æ¯)ï¼Œå¹¶å°†key=\u003ecallçš„å¯¹åº”å…³ç³»å­˜å…¥mapä¸­ï¼ˆé€šè¿‡mutexä¿è¯äº†å¹¶å‘å®‰å…¨ï¼‰ å¦‚æœå·²ç»åœ¨è°ƒç”¨ä¸­åˆ™keyå·²ç»å­˜åœ¨mapï¼Œåˆ™wg.Wait åœ¨fnæ‰§è¡Œç»“æŸä¹‹åï¼ˆåœ¨doCallæ–¹æ³•ä¸­æ‰§è¡Œï¼‰æ‰§è¡Œwg.Done å¡åœ¨ç¬¬2æ­¥çš„æ–¹æ³•å¾—åˆ°æ‰§è¡Œï¼Œè¿”å›ç»“æœ å…¶ä»–çš„DoChanæ–¹æ³•ä¹Ÿæ˜¯ç±»ä¼¼çš„é€»è¾‘ï¼Œåªæ˜¯è¿”å›çš„æ˜¯ä¸€ä¸ªchanã€‚\næ–‡ä¸­ç”¨åˆ°çš„å®ä¾‹ä»£ç æ”¾åœ¨githubä¸Šï¼š https://github.com/go-demo/singleflight-demo"},"title":"singleflightåŒ…åŸç†è§£æ"},"/blog/202004/bridge-hairpin-mod/":{"data":{"":"","æ€»ç»“#æ€»ç»“":"å…¶å®æˆ‘ä»¬é›†ç¾¤é€šè¿‡è¿™ç§æ¯”è¾ƒå¦ç±»çš„æ–¹å¼æ¥åˆ†é…POD IPä¹Ÿç”¨äº†äº†å¾ˆä¹…äº†ï¼Œä¹‹æ‰€ä»¥æ²¡å‡ºé—®é¢˜ï¼Œåº”è¯¥æ˜¯ä¸šåŠ¡åŸºæœ¬æ²¡é‡åˆ°è¿™ç§podå†…é€šè¿‡serviceè®¿é—®è‡ªå·±çš„æƒ…å†µã€‚\næ‰€ä»¥è¿˜æ˜¯è¦è·Ÿç€æ ‡å‡†çš„k8sæ–¹å¼æ¥å®‰è£…cniï¼Œé¿å…å…¥å‘ï¼Œæ¯”å¦‚flannelå°±å·²ç»æä¾›ç»™äº†hairpinMode å‚æ•°æ¥è¿›è¡Œé…ç½®å¼€å¯ã€‚","æ’æŸ¥è¿‡ç¨‹#æ’æŸ¥è¿‡ç¨‹":"1ã€é¦–å…ˆå°è¯•é€šè¿‡pod ipå°è¯•æ˜¯å¦å¯è®¿é—®ï¼Œå·²éªŒè¯æ˜¯å¯é€šçš„ã€‚\n2ã€å°è¯•å¯¹docker0ç½‘æ¡¥è¿›è¡ŒæŠ“åŒ…\ntcpdump -i docker0 ç¥å¥‡çš„åœ¨è¿™é‡Œï¼Œå†æ¬¡å°è¯•é€šè¿‡service è®¿é—®æ˜¯å±…ç„¶å¯ä»¥é€šï¼Œå‘ç°åªè¦tcpdumpæ–­å¼€å°±ä¸è¡Œäº†ã€‚\nåˆ°è¿™é‡Œçš„æ—¶å€™æœ‰ç‚¹è§‰å¾—è¯¡å¼‚äº†\nåœ¨podå†…é€šè¿‡serviceè®¿é—®çš„æ—¶å€™ç½‘ç»œçš„æµå‘åº”è¯¥æ˜¯\npodå†…éƒ¨è®¿é—®service-\u003edocker0ç½‘æ¡¥-\u003eå®¿ä¸»æœºçš„iptablesè§„åˆ™-\u003edocker0ç½‘æ¡¥-\u003epodå†…éƒ¨ æŸ¥é˜…äº†ç›¸å…³èµ„æ–™åï¼Œçœ‹åˆ°kubeletæœ‰ä¸ª--hairpin-modå‚æ•°ï¼š\næ–‡æ¡£è¯´æ˜ï¼š\nå¦‚æœç½‘ç»œæ²¡æœ‰ä¸ºâ€œå‘å¤¹æ¨¡å¼â€æµé‡ç”Ÿæˆæ­£ç¡®é…ç½®ï¼Œé€šå¸¸å½“ kube-proxy ä»¥ iptables æ¨¡å¼è¿è¡Œï¼Œå¹¶ä¸” Pod ä¸æ¡¥æ¥ç½‘ç»œè¿æ¥æ—¶ï¼Œå°±ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µã€‚Kubelet å…¬å¼€äº†ä¸€ä¸ª hairpin-mode æ ‡å¿—ï¼Œå¦‚æœ pod è¯•å›¾è®¿é—®å®ƒä»¬è‡ªå·±çš„ Service VIPï¼Œå°±å¯ä»¥è®© Service çš„ç«¯ç‚¹é‡æ–°è´Ÿè½½åˆ°ä»–ä»¬è‡ªå·±èº«ä¸Šã€‚hairpin-mode æ ‡å¿—å¿…é¡»è®¾ç½®ä¸º hairpin-veth æˆ–è€… promiscuous-bridgeã€‚\nå¯æ˜¯æˆ‘è®¾ç½®ä¹‹åè¿˜æ˜¯æ²¡æœ‰è¿˜æ˜¯ä¸è¡Œï¼Œç¿»äº†ä¸€ä¸‹kubeleté‡Œé¢çš„ä»£ç ï¼Œå‘ç°cniç»„ä»¶å¹¶æ²¡æœ‰å–è¿™ä¸ªå€¼åšä»»ä½•æ‰åšï¼ˆåœ¨kubnetä¸­æœ‰ï¼‰\næŸ¥çœ‹è¿™ä¸ªè®¨è®ºï¼š https://github.com/kubernetes/kubernetes/issues/45790\nå¤§è‡´ç»“è®ºæ˜¯ï¼Œåº”è¯¥ç”±cniæ’ä»¶æ¥æ ¹æ®è¿™ä¸ªå€¼æ¥åšå¯¹åº”çš„æ“ä½œã€‚\nè¿˜æ˜¯æ²¡è§£å†³æˆ‘çš„é—®é¢˜ï¼Ÿ\nä¸è¿‡æˆ‘çœ‹åˆ°hairpinå¼€å¯çš„æ ‡å¿—ä½æ˜¯é€šè¿‡/sys/devices/virtual/net/docker0/brif/veth-xxx/hairpin_mod å†…å®¹è®¾ç½®ä¸º1å¼€å¯çš„ã€‚\næ‰€ä»¥æˆ‘å°†æ‰€æœ‰vethè¯¥æ–‡ä»¶å†…å®¹è®¾ç½®1\nfor intf in /sys/devices/virtual/net/docker0/brif/*; do echo 1\u003e $intf/hairpin_mod; done å¯ä»¥è®¿é—®äº†ã€‚ğŸ˜º","ç¯å¢ƒé…ç½®#ç¯å¢ƒé…ç½®":"ä½¿ç”¨çš„cniæ’ä»¶æ˜¯flannelï¼Œä½†ä¸æ˜¯å®¹å™¨åŒ–å®‰è£…ï¼Œä¹Ÿä¸æ˜¯æ ‡å‡†åŒ–çš„é€šè¿‡kubeletæŒ‡å®šcni pluginï¼ˆâ€“cni-bin-dir,â€“cni-conf-dirå‚æ•°ï¼‰ï¼Œè€Œæ˜¯é€šè¿‡dockerd æä¾›çš„-bipå‚æ•°æŒ‡å®šå®¹å™¨çš„å­ç½‘ï¼Œè€Œè¿™ä¸ªå€¼æ˜¯ä»/run/flannel/subnet.env(flannelä¼šå°†è·å–åˆ°çš„å­ç½‘å†™å…¥åˆ°è¯¥æ–‡ä»¶)","è§£ç–‘promiscuous-bridge-ä¸-hairpin-veth#è§£ç–‘ï¼špromiscuous-bridge ä¸ hairpin-veth":"ä¸ºä»€ä¹ˆæˆ‘æ— æ³•è®¿é—®\nbridgeä¸å…è®¸åŒ…ä»æ”¶åˆ°åŒ…çš„ç«¯å£å‘å‡ºï¼Œæ¯”å¦‚è¿™ç§æƒ…å†µï¼Œåœ¨podå†…é€šè¿‡docker0è®¿é—®serviceï¼Œåç»­åˆé€šè¿‡docker0ç½‘æ¡¥è¿›æ¥ï¼Œæ‰€ä»¥éœ€è¦å¼€å¯hairpin_mod\nä¸ºä»€ä¹ˆä½¿ç”¨tcpdump å¯ä»¥è®©è®¿é—®å¯é€šï¼Ÿ\nå› ä¸ºtcpdumpè¦æŠ“å–æ‰€æœ‰ç»è¿‡è¯¥ç½‘å¡ï¼Œæ‰€ä»¥éœ€è¦å¼€å¯æ··æ‚æ¨¡å¼ã€‚å¯ä»¥åœ¨/var/log/messageçœ‹åˆ°device docker0 entered promiscuous modeçš„logã€‚\næ··æ‚æ¨¡å¼ï¼ˆè‹±èªï¼špromiscuous modeï¼‰æ˜¯ç”µè„‘ç½‘ç»œä¸­çš„æœ¯è¯­ã€‚ æ˜¯æŒ‡ä¸€å°æœºå™¨çš„ç½‘å¡èƒ½å¤Ÿæ¥æ”¶æ‰€æœ‰ç»è¿‡å®ƒçš„æ•°æ®æµï¼Œè€Œä¸è®ºå…¶ç›®çš„åœ°å€æ˜¯å¦æ˜¯å®ƒã€‚ ä¸€èˆ¬è®¡ç®—æœºç½‘å¡éƒ½å·¥ä½œåœ¨éæ··æ‚æ¨¡å¼ä¸‹ï¼Œæ­¤æ—¶ç½‘å¡åªæ¥å—æ¥è‡ªç½‘ç»œç«¯å£çš„ç›®çš„åœ°å€æŒ‡å‘è‡ªå·±çš„æ•°æ®ã€‚ å½“ç½‘å¡å·¥ä½œåœ¨æ··æ‚æ¨¡å¼ä¸‹æ—¶ï¼Œç½‘å¡å°†æ¥è‡ªæ¥å£çš„æ‰€æœ‰æ•°æ®éƒ½æ•è·å¹¶äº¤ç»™ç›¸åº”çš„é©±åŠ¨ç¨‹åºã€‚\næ‰‹åŠ¨å¼€å…³å‘½ä»¤ï¼š ifconfig docker0 promisc on/off","é—®é¢˜ç°è±¡#é—®é¢˜ç°è±¡":"åˆ›å»ºä¸€ä¸ªnginx podï¼Œå¹¶é…ç½®äº†serviceè®¿é—®ï¼Œserviceåç«¯æŒ‡å‘podã€‚\nè¿›å…¥podä¸­ä½¿ç”¨service ip æˆ–è€…service åŸŸåï¼Œæ— æ³•è®¿é—®ã€‚\nä¸€å¼€å§‹ä»¥ä¸ºæ˜¯ç¯å¢ƒé…ç½®æˆ–è€…k8sç‰ˆæœ¬ï¼ˆ1.9ï¼‰çš„é—®é¢˜ï¼Œåœ¨å…¶ä»–1.13çš„kubernetesç¯å¢ƒä¸‹ä¹Ÿè¯•äº†ï¼Œè¿˜æ˜¯åŒæ ·çš„é—®é¢˜ã€‚"},"title":"è®°ä¸€æ¬¡é—®é¢˜æ’æŸ¥ï¼šä¸ºä»€ä¹ˆåœ¨PODæ— æ³•é€šè¿‡Serviceè®¿é—®è‡ªå·±ï¼Ÿ"},"/blog/202005/custom-resources-and-controllers/":{"data":{"":"","crdèµ„æºå®šä¹‰#CRDèµ„æºå®šä¹‰":"ä»¥sample-controlerä¸­çš„ä¸ºä¾‹ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºçš„ä¸€ä¸ª FooÂ å¦‚ä¸‹example-foo.yamlï¼š\nåˆ›å»ºè¯¥ FooÂ è‡ªå®šä¹‰èµ„æºåï¼ŒæœŸæœ›åˆ›å»ºå‡ºä¸€ä¸ªåç§°ä¸º example-fooÂ ï¼Œå‰¯æœ¬æ•°ä¸º 1Â çš„deploymentã€‚\napiVersion: samplecontroller.k8s.io/v1alpha1 kind: Foo metadata: name: example-foo spec: deploymentName: example-foo replicas: 1 å®ƒçš„CRDå®šä¹‰å¦‚ä¸‹ï¼š\napiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: foos.samplecontroller.k8s.io spec: group: samplecontroller.k8s.io version: v1alpha1 #ç‰ˆæœ¬ names: kind: Foo # kindç±»å‹ plural: foos # APIä¸­ä½¿ç”¨çš„åç§°ï¼š/apis/\u003cgroup\u003e/\u003cversion\u003e/\u003cplural\u003e scope: Namespaced # Namespaced/Clusterï¼Œè¡¨ç¤ºè¯¥CRDæ˜¯å‘½ä»¤ç©ºé—´å±æ€§è¿˜æ˜¯é›†ç¾¤å±æ€§ validation: # å¯¹å‚æ•°è¿›è¡ŒéªŒè¯ï¼Œåº”ç”¨openAPIV3Schemaè§„åˆ™ openAPIV3Schema: properties: spec: properties: # å®šä¹‰äº†ä¸€ä¸ª replicas å­—æ®µï¼Œç±»å‹ä¸ºinteger ï¼Œå¹¶ä¸”åœ¨1-10çš„èŒƒå›´å†… replicas: type: integer minimum: 1 maximum: 10 æ›´å¤šå…³äºcrdå®šä¹‰è§„åˆ™å¯ä»¥å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼š\nhttps://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/\nå½“æŠŠè¿™ä¸ªcrdèµ„æºapplyåˆ°é›†ç¾¤ä¸­åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ kubectl get apiservice v1alpha1.samplecontroller.k8s.io -o yamlÂ å‘½ä»¤çœ‹åˆ°æ³¨å†Œè¿™ä¸ª apiserviceÂ ","ä»£ç ç¼–å†™#ä»£ç ç¼–å†™":"åªéœ€è¦å°†æˆ‘ä»¬ FooÂ resourceç›¸å…³çš„structï¼Œå…¶ä½™çš„ç±»ä¼¼è‡ªå®šä¹‰èµ„æºçš„ informersÂ , listersÂ , clientsetÂ ä»¥åŠ deepcopyÂ çš„ä»£ç éƒ½å¯ä»¥é€šè¿‡å·¥å…·code-generatorè‡ªåŠ¨ç”Ÿæˆã€‚\nä»¥åŠç¼–å†™æˆ‘ä»¬è‡ªå®šä¹‰Controllerçš„ä¸šåŠ¡é€»è¾‘ä»£ç å°±å¥½äº† structèµ„æºå®šä¹‰ type.go\npackage v1alpha1 import ( metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" ) // +genclient // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object // Foo is a specification for a Foo resource type Foo struct { metav1.TypeMeta `json:\",inline\"` metav1.ObjectMeta `json:\"metadata,omitempty\"` Spec FooSpec `json:\"spec\"` Status FooStatus `json:\"status\"` } // FooSpec is the spec for a Foo resource // FooSpec å®šä¹‰ type FooSpec struct { DeploymentName string `json:\"deploymentName\"` Replicas *int32 `json:\"replicas\"` } // FooStatus is the status for a Foo resource type FooStatus struct { AvailableReplicas int32 `json:\"availableReplicas\"` } // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object // FooList is a list of Foo resources type FooList struct { metav1.TypeMeta `json:\",inline\"` metav1.ListMeta `json:\"metadata\"` Items []Foo `json:\"items\"` } å…¶ä¸­ç±»ä¼¼ +k8s:Â çš„æ³¨é‡Šæ˜¯ä»£ç ç”Ÿæˆæ¥è¯†åˆ«çš„ã€‚\nregister.goÂ ä¸­å°† FooÂ , FooListÂ æ³¨å†Œè¿›å…¥ schemeÂ ä¸­ã€‚ ä»£ç ç”Ÿæˆ ä»£ç ç”Ÿæˆèƒ½å¸®æˆ‘å¤„ç†å¤§éƒ¨åˆ†é‡å¤ä»£ç ï¼Œä¸»è¦é€šè¿‡ https://github.com/kubernetes/code-generator è¿™ä¸ªåŒ…è¿›è¡Œè§£ætagå¹¶ç”Ÿæˆã€‚ å…¨å±€tag å¿…é¡»åœ¨ç›®æ ‡åŒ…çš„doc.goæ–‡ä»¶ä¸­å£°æ˜ï¼Œå…¸å‹è·¯å¾„æ˜¯ pkg/apis///doc.goã€‚\nå†…å®¹ç¤ºä¾‹ï¼š\n// ä¸ºåŒ…ä¸­ä»»ä½•ç±»å‹ç”Ÿæˆæ·±æ‹·è´æ–¹æ³•ï¼Œå¯ä»¥åœ¨å±€éƒ¨tagè¦†ç›–æ­¤é»˜è®¤è¡Œä¸º // +groupName=example.com // +k8s:deepcopy-gen=package // +groupName=samplecontroller.k8s.io // groupNameæŒ‡å®šAPIç»„çš„å…¨é™å®šå // Package v1alpha1 is the v1alpha1 version of the API. package v1alpha1 // import \"k8s.io/sample-controller/pkg/apis/samplecontroller/v1alpha1\" å±€éƒ¨tag +genclient: ä¸ºè¿™ä¸ª package åˆ›å»º clientã€‚ +genclient:noStatus: å½“åˆ›å»º client æ—¶ï¼Œä¸å­˜å‚¨ statusã€‚ +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object: ä¸ºç»“æ„ä½“ç”Ÿæˆ deepcopy çš„ä»£ç ï¼Œå®ç°äº† runtime.Object çš„ Interfaceã€‚ ä»£ç ç”Ÿæˆï¼š\né€šè¿‡./hack/update-codegen.shæ–¹æ³•å¯ä»¥ç”Ÿæˆï¼Œclientä»¥åŠdeepcopyä»£ç ã€‚\nåŒ…å«ï¼š\nsample-controller/pkg/apis/samplecontroller/v1alpha1/zz_generated.deepcopy.go sample-controller/pkg/generated/clientset sample-controller/pkg/generated/informers sample-controller/pkg/generated/informers _å‰æï¼šcode-generator å·²ç»åœ¨vendorä¸­ï¼Œæ‰§è¡Œ go mod vendorÂ _\nupdate-codegen.shå†…å®¹å¦‚ä¸‹\nbash \"${CODEGEN_PKG}\"/generate-groups.sh \"deepcopy,client,informer,lister\" \\ k8s.io/sample-controller/pkg/generated k8s.io/sample-controller/pkg/apis \\ samplecontroller:v1alpha1 \\ --output-base \"$(dirname \"${BASH_SOURCE[0]}\")/../../..\" \\ --go-header-file \"${SCRIPT_ROOT}\"/hack/boilerplate.go.txt å®Œæ•´ä½¿ç”¨è¯´æ˜ï¼š\nUsage: generate-groups.sh \u003cgenerators\u003e \u003coutput-package\u003e \u003capis-package\u003e \u003cgroups-versions\u003e ... \u003cgenerators\u003e the generators comma separated to run (deepcopy,defaulter,client,lister,informer) or \"all\". \u003coutput-package\u003e the output package name (e.g. github.com/example/project/pkg/generated). \u003capis-package\u003e the external types dir (e.g. github.com/example/api or github.com/example/project/pkg/apis). \u003cgroups-versions\u003e the groups and their versions in the format \"groupA:v1,v2 groupB:v1 groupC:v2\", relative to \u003capi-package\u003e. ... arbitrary flags passed to all generator binaries. Examples: generate-groups.sh all github.com/example/project/pkg/client github.com/example/project/pkg/apis \"foo:v1 bar:v1alpha1,v1beta1\" generate-groups.sh deepcopy,client github.com/example/project/pkg/client github.com/example/project/pkg/apis \"foo:v1 bar:v1alpha1,v1beta1\" interface{}å¤„ç† åœºæ™¯ï¼šå¦‚æœæˆ‘ä»¬éœ€è¦ä¸€ä¸ªé€šç”¨çš„ç±»å‹çš„objectï¼Œå¦‚ä¸‹ï¼š\nvalidation: openAPIV3Schema: properties: spec: properties: fields: type: object æˆ‘ä»¬åœ¨specé‡Œé¢å®šä¹‰äº†ä¸€ä¸ªfieldså­—æ®µï¼Œç±»å‹æ˜¯objectï¼ˆå³key ,valueçš„å½¢å¼ï¼‰ï¼Œvalueçš„å€¼å¯èƒ½æ˜¯intä¹Ÿå¯èƒ½æ˜¯stringæˆ–è€…bool\nåœ¨typeå®šä¹‰çš„æ—¶å€™æˆ‘æ˜¯è¿™ä¹ˆå†™çš„ï¼Œå®šä¹‰ä¸ºmap[string]interface{}\n// FooSpec is the spec for a Foo resource type FooSpec struct { Fields map[string]interface{} `json:\"fields\"` } å½“åœ¨ä»£ç ç”Ÿæˆçš„æ—¶å€™ï¼Œå‘ç°ä¼šæŠ¥é”™ï¼š\nGenerating deepcopy funcs F0518 17:53:33.568567 39986 deepcopy.go:750] DeepCopy of \"interface{}\" is unsupported. Instead, use named interfaces with DeepCopy\u003cnamed-interface\u003e as one of the methods. goroutine 1 [running]: k8s.io/klog/v2.stacks(0xc000132001, 0xc0002e9000, 0xad, 0xfd) /Users/silenceper/workspace/golang/pkg/mod/k8s.io/klog/v2@v2.0.0/klog.go:972 +0xb8 ...... é‡åˆ°è¿™ç§é—®é¢˜ï¼Œéœ€è¦è‡ªå·±å®ç°æ·±æ‹·è´ï¼Œä¾‹å¦‚è¿™ç§ï¼š\ntype HelmReleaseSpec struct { HelmValues `json:\",inline\"` } // +k8s:deepcopy-gen=false type HelmValues struct { helm.Values `json:\"values,omitempty\"` } // helm.Valueså®šä¹‰ï¼š type Values map[string]interface{} // è‡ªå·±å®ç°æ·±æ‹·è´ func (in *HelmValues) DeepCopyInto(out *HelmValues) { if in == nil { return } b, err := yaml.Marshal(in.Values) if err != nil { return } var values helm.Values err = yaml.Unmarshal(b, \u0026values) if err != nil { return } out.Values = values } Controllerç¼–å†™ åœ¨ç¼–å†™Controllerä¹‹å‰éœ€è¦äº†è§£client-goä¸­çš„informeræœºåˆ¶ï¼š\né»„è‰²çš„éƒ¨åˆ†æ˜¯controllerç›¸å…³çš„æ¡†æ¶ï¼ŒåŒ…æ‹¬workqueueã€‚è“è‰²éƒ¨åˆ†æ˜¯client-goçš„ç›¸å…³å†…å®¹ï¼ŒåŒ…æ‹¬informer, reflector(å…¶å®å°±æ˜¯informerçš„å°è£…), indexerã€‚ä»æµç¨‹ä¸Šçœ‹ï¼Œreflectorä»apiserverä¸­é€šè¿‡list\u0026watchæœºåˆ¶æ¥æ”¶äº‹ä»¶å˜åŒ–ï¼Œè¿›å…¥Delta FIFOé˜Ÿåˆ—ä¸­ï¼Œç”±informerè¿›è¡Œå¤„ç†ã€‚informerä¼šå°†delta FIFOé˜Ÿåˆ—ä¸­çš„äº‹ä»¶äº¤ç»™indexerç»„ä»¶ï¼Œindexerç»„ä»¶ä¼šå°†äº‹ä»¶æŒä¹…åŒ–å­˜å‚¨åœ¨æœ¬åœ°çš„ç¼“å­˜ä¸­ã€‚ä¹‹åï¼Œç”±äºç”¨æˆ·äº‹å…ˆå°†ä¸ºinformeræ³¨å†Œå„ç§äº‹ä»¶çš„å›è°ƒå‡½æ•°ï¼Œè¿™äº›å›è°ƒå‡½æ•°å°†é’ˆå¯¹ä¸åŒçš„ç»„ä»¶åšä¸åŒçš„å¤„ç†ã€‚ä¾‹å¦‚åœ¨controllerä¸­ï¼Œå°†æŠŠobjectæ”¾å…¥workqueueä¸­ï¼Œä¹‹åç”±controllerçš„ä¸šåŠ¡é€»è¾‘ä¸­è¿›è¡Œå¤„ç†ã€‚å¤„ç†çš„æ—¶å€™å°†ä»ç¼“å­˜ä¸­è·å–objectçš„å¼•ç”¨ã€‚å³å„ç»„ä»¶å¯¹èµ„æºçš„å¤„ç†ä»…é™äºæœ¬åœ°ç¼“å­˜ä¸­ï¼Œç›´åˆ°updateèµ„æºçš„æ—¶å€™æ‰ä¸apiserveräº¤äº’ã€‚\nç®€å•æ¥è®²é€šè¿‡list/watchæœºå™¨æä¾›äº†æœ¬åœ°ç¼“å­˜é¿å…æ¯æ¬¡å»è¯·æ±‚apiserverã€‚\nå¹¶ä¸”æä¾›äº†Event Handleræ–¹æ³•ï¼Œåœ¨å°†æ•°æ®ä¿å­˜è¿›å…¥cacheæ—¶ï¼Œé€šè¿‡è°ƒç”¨è‡ªå®šä¹‰handleræ–¹æ³•ï¼Œå¢åŠ è‡ªå®šä¹‰å¤„ç†ã€‚\næ‰€ä»¥Controller çš„ä»£ç ç»“æ„ï¼Œå°±æ˜¯å¦‚ä¸‹ï¼š\nfunc NewController( kubeclientset kubernetes.Interface, sampleclientset clientset.Interface, deploymentInformer appsinformers.DeploymentInformer, fooInformer informers.FooInformer) *Controller { .... fooInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{ AddFunc: controller.enqueueFoo, UpdateFunc: func(old, new interface{}) { controller.enqueueFoo(new) }, }) .... } func (c *Controller) Run(threadiness int, stopCh \u003c-chan struct{}) error { // Launch two workers to process Foo resources for i := 0; i \u003c threadiness; i++ { go wait.Until(c.runWorker, time.Second, stopCh) } } func (c *Controller) runWorker() { for c.processNextWorkItem() { } } func (c *Controller) processNextWorkItem() bool { obj, shutdown := c.workqueue.Get() ... err := func(obj interface{}) error { ... // Run the syncHandler, passing it the namespace/name string of the // Foo resource to be synced. if err := c.syncHandler(key); err != nil { // Put the item back on the workqueue to handle any transient errors. c.workqueue.AddRateLimited(key) return fmt.Errorf(\"error syncing '%s': %s, requeuing\", key, err.Error()) } ... }(obj) ... } func (c *Controller) syncHandler(key string) error { // Convert the namespace/name string into a distinct namespace and name namespace, name, err := cache.SplitMetaNamespaceKey(key) if err != nil { utilruntime.HandleError(fmt.Errorf(\"invalid resource key: %s\", key)) return nil } //TODO å¤„ç†é€»è¾‘ } func (c *Controller) enqueueFoo(obj interface{}) { ... c.workqueue.Add(key) } åœ¨NewControllerä¸­é€šè¿‡fooInformeræ·»åŠ  AddEventHandlerÂ ï¼Œæ‰§è¡Œ enqueueFooÂ enqueueFoo ä¸­å°†è·å–çš„å˜æ›´æ”¾å…¥é˜Ÿåˆ— å¯åŠ¨ä¸€ä¸ªæˆ–å¤šä¸ªworkä»é˜Ÿåˆ—ä¸­å–æ•°æ®ï¼Œæœ€ç»ˆé€šè¿‡syncHandlerè¿›è¡Œä¸šåŠ¡åˆ¤æ–­ åœ¨sample-controllerä¸­åŒæ—¶è¿˜ç›‘å¬äº†deploymentï¼Œåœ¨ handleObjectÂ åˆ¤æ–­æ˜¯å¦å½’å± FooÂ Kind ï¼ŒåŒæ—¶æ‰§è¡Œ enqueueFooÂ å…¥é˜Ÿã€‚ å…·ä½“ä»£ç åˆ¤æ–­å‚è€ƒcontroller.go\nåœ¨main.goæ–¹æ³•ä¸­è°ƒç”¨å¦‚ä¸‹ï¼š\nexampleClient, err := clientset.NewForConfig(cfg) if err != nil { klog.Fatalf(\"Error building example clientset: %s\", err.Error()) }\tkubeInformerFactory := kubeinformers.NewSharedInformerFactory(kubeClient, time.Second*30) exampleInformerFactory := informers.NewSharedInformerFactory(exampleClient, time.Second*30) controller := NewController(kubeClient, exampleClient, kubeInformerFactory.Apps().V1().Deployments(), exampleInformerFactory.Samplecontroller().V1alpha1().Foos()) // notice that there is no need to run Start methods in a separate goroutine. (i.e. go kubeInformerFactory.Start(stopCh) // Start method is non-blocking and runs all registered informers in a dedicated goroutine. kubeInformerFactory.Start(stopCh) exampleInformerFactory.Start(stopCh) //å¯åŠ¨informer å°±æ˜¯è°ƒç”¨é€šè¿‡coge-genç”Ÿæˆä»£ç åˆ›å»ºinformerå¹¶å¯åŠ¨ï¼Œåˆ›å»ºclientã€‚\n**æ€è€ƒï¼šä¸ºä»€ä¹ˆè¦é€šè¿‡é˜Ÿåˆ—æ¥æ§åˆ¶æ•°æ®çš„å˜åŒ–ï¼ŸÂ **\næˆ‘è§‰å¾—ç”¨é˜Ÿåˆ—ä¸€æ–¹é¢æ˜¯è§£è€¦ï¼Œå› ä¸ºå¾€å¾€ä¸€ä¸ªControlleré‡Œé¢å¯èƒ½è¦é€šè¿‡informerç›‘å¬å„ç±»èµ„æºå¯¹è±¡ï¼Œé€šè¿‡é˜Ÿåˆ—å€ŸåŠ©äº†å„ä¸ªinformerçš„ä¾èµ–ã€‚å¦ä¸€æ–¹ä¾¿å¯ä»¥é€šè¿‡ä¸åŒç±»å‹çš„é˜Ÿåˆ—æ¯”å¦‚é™é€Ÿé˜Ÿåˆ—ï¼Œå»¶è¿Ÿé˜Ÿåˆ—è¾¾åˆ°ä¸åŒçš„å¹¶å‘æ§åˆ¶ã€‚","æ€»ç»“#æ€»ç»“":" å…ˆå®šä¹‰crdï¼Œå†å®ç°Controlleré€»è¾‘ å¯ä»¥é€šè¿‡code-generatorç”Ÿæˆinformerï¼Œclientï¼Œlistersä»£ç  æ³¨æ„é’ˆå¯¹interface{}ç±»å‹éœ€è¦è‡ªå·±å®ç°deepCopyæ–¹æ³• å®ç°ä¸€ä¸ªOperatorï¼Œé›†æˆæ›´å¤šæ›´å¤æ‚çš„Controllerçš„è¯ï¼Œæˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨Operatoræ¡†æ¶ï¼Œæ¯”å¦‚kubebuilder å‚è€ƒ https://juejin.im/post/5de097bbf265da05d849ab53 https://blog.fatedier.com/2019/04/02/k8s-custom-controller/ https://blog.gmem.cc/crd ","ç›®çš„#ç›®çš„":"Custom Resourceæ˜¯æ‰©å±•Kubernetesçš„ä¸€ç§æ–¹å¼ï¼ˆå¦å¤–ä¸€ç§å°±æ˜¯é€šè¿‡èšåˆå±‚API apiserver-aggregationï¼‰ï¼Œè€Œcontrollerå¯¹æŒ‡å®šçš„resourceè¿›è¡Œç›‘å¬å’Œæ‰§è¡Œå¯¹åº”çš„åŠ¨ä½œ(watch,diff,action)ã€‚\nOperatorä¸ControlleråŒºåˆ«\næ‰€æœ‰çš„Operatoréƒ½æ˜¯ç”¨äº†Controlleræ¨¡å¼ï¼Œä½†å¹¶ä¸æ˜¯æ‰€æœ‰Controlleréƒ½æ˜¯Operatorã€‚åªæœ‰å½“å®ƒæ»¡è¶³: controlleræ¨¡å¼ + APIæ‰©å±• + ä¸“æ³¨äºæŸä¸ªApp/ä¸­é—´ä»¶æ—¶ï¼Œæ‰æ˜¯ä¸€ä¸ªOperatorã€‚ Operatorå°±æ˜¯ä½¿ç”¨CRDå®ç°çš„å®šåˆ¶åŒ–çš„Controller. å®ƒä¸å†…ç½®K8S Controlleréµå¾ªåŒæ ·çš„è¿è¡Œæ¨¡å¼(æ¯”å¦‚ watch, diff, action) Operatoræ˜¯ç‰¹å®šé¢†åŸŸçš„Controllerå®ç° è®¨è®ºä¸¤è€…åŒºåˆ«ï¼šhttps://github.com/kubeflow/tf-operator/issues/300\næ‰€ä»¥å…ˆå­¦ä¹ å¦‚ä½•æ„å»ºå‡ºä¸€äº›è‡ªå®šä¹‰çš„Controllerè‚¯å®šæ˜¯ä¹‹åå®ç°Operatorçš„åŸºç¡€ã€‚\nå®ç°ä¸€ä¸ªè‡ªå®šä¹‰çš„Controllerç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šCRDå’ŒControlleré€»è¾‘ä»£ç \nè¿™é‡Œä»¥sample-controllerçš„ä»£ç ä¸ºä¾‹ï¼ŒåŒæ—¶æˆ‘ä»¬è‡ªå·±å†™çš„Controllerä¹Ÿå¯ä»¥å‚è€ƒè¿™ä¸ªä»£ç ç»“æ„ã€‚ "},"title":"å¦‚ä½•åœ¨Kubernetesä¸­åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰Controller?"},"/blog/202005/difference-vim-and-echo/":{"data":{"":"","æ€»ç»“#æ€»ç»“":" vimç¼–è¾‘æ˜¯äº§ç”Ÿäº†ä¸€ä¸ªæ–°çš„æ–‡ä»¶ï¼Œæ‰€ä»¥çœ‹åˆ°inodeä¿¡æ¯å˜åŒ–äº†ï¼Œè€Œechoä»…ä»…åªæ˜¯å¯¹æ–‡ä»¶è¿›è¡Œå†™å…¥ã€‚ åœ¨vimç¼–è¾‘è¿‡ç¨‹ä¸­ï¼Œä¼šç”Ÿæˆswpç¼“å†²åŒºæ–‡ä»¶ï¼Œåœ¨è¿›è¡Œvimç¼–è¾‘æ—¶æ—¶åˆ»å°†å†…å®¹ä¿å­˜è¿›å…¥swpï¼Œé˜²æ­¢ç¨‹åºé€€å‡ºæœªä¿å­˜ äº§ç”Ÿåç¼€å¸¦ ~ çš„å¤‡ä»½æ–‡ä»¶ï¼Œè¿™ä¸ªæ˜¯åœ¨å¯¹æ–‡ä»¶è¿›è¡Œä¿å­˜æ—¶äº§ç”Ÿï¼Œå¦‚æœæ–‡ä»¶è¢«æ­£å¸¸ä¿å­˜åˆ™è¯¥æ–‡ä»¶ä¼šè¢«ç«‹å³åˆ é™¤ï¼Œæ­£å¸¸æƒ…å†µä¸‹æ˜¯çœ‹ä¸åˆ°è¿™ä¸ªæ–‡ä»¶ å¦‚æœæ–‡ä»¶otheræœ‰writeæƒé™ï¼ˆchmod o+w xxxï¼‰ï¼Œåˆ™å½“è¿›è¡Œviå†™å…¥å†…å®¹çš„æ—¶å€™æ–‡ä»¶inodeä¸ä¼šæ”¹å˜ã€‚ å¦‚æœå…³é—­vimå¤‡ä»½ï¼Œåˆ™inodeä¿¡æ¯ä¹Ÿä¸ä¼šæ”¹å˜ ","ç°è±¡#ç°è±¡":"æœ€è¿‘åœ¨è°ƒè¯•ä¸€ä¸ªfilebeatç¨‹åºæ—¶éœ€è¦åˆ¶é€ ä¸€äº›logï¼Œæˆ‘æ˜¯ç›´æ¥ä½¿ç”¨vimç›´æ¥å¯¹æ–‡ä»¶æ‰“å¼€ç„¶åç›´æ¥ä¿å­˜çš„ã€‚\nä½†æ˜¯æœ‰ä¸ªå¥‡æ€ªçš„ç°è±¡ï¼šæ¯æ¬¡å†™å…¥ä¸€è¡Œæ–°çš„æ—¥å¿—ï¼Œfilebeatéƒ½ä¼šå°†æ•´ä¸ªæ–‡ä»¶çš„å†…å®¹åˆé‡æ–°è¿›è¡Œä¸ŠæŠ¥ä¸€éå¯¼è‡´æ—¥å¿—ä¸Šä¼ é‡å¤ï¼ŒåŒæ—¶è§‚å¯Ÿåˆ°filebeatçš„æ–‡ä»¶é‡‡é›†çŠ¶æ€æ–‡ä»¶registryéƒ½ä¼šè¿›è¡Œå¢åŠ ä¸€ä¸ªé‡å¤çš„æ–‡ä»¶(sourceç›¸åŒï¼Œinodeä¸åŒ)ã€‚\næ“ä½œä¸€ç•ªåä»¥ä¸ºæ˜¯ç¨‹åºçš„é—®é¢˜ï¼Œæœ€åæ‰ååº”è¿‡æ¥ï¼ˆä¸€å¼€å§‹æ²¡æ³¨æ„åˆ°inodeä¸åŒ :\u003cï¼‰ï¼Œæœ€ç»ˆä½¿ç”¨echo \"test some log\"\u003e\u003etest.logè¿½åŠ çš„æ–¹å¼å‘ç°ä¸ä¼šæœ‰æ­¤é—®é¢˜ã€‚\nåŒæ—¶çœ‹äº†ä¸‹ä¸¤è€…çš„inodeä¿¡æ¯ï¼Œç¡®è®¤äº†æ˜¯å› ä¸ºvimä¼šæ”¹å˜æ–‡ä»¶çš„inode(ä¸€ä¸ªæ–°çš„æ–‡ä»¶)ï¼Œechoåˆ™ä¸ä¼šï¼š\n2020-05-14æ›´æ–°ï¼šä¹Ÿè·Ÿæ–‡ä»¶æƒé™æœ‰å…³ï¼Œå¦‚æœæ–‡ä»¶æ²¡æœ‰oæ²¡æœ‰wæƒé™ï¼Œåˆ™inodeä¿¡æ¯ä¼šæ”¹å˜ï¼Œå¦‚æœchmod o+w test.logåˆ™inodeä¿¡æ¯ä¸ä¼šå˜\nåŒæ—¶vimä¹Ÿæ˜¯å¼€äº†å¤‡ä»½æ–‡ä»¶\n1ã€æŸ¥çœ‹æ–‡ä»¶inodeä¸º908488\n[root@localhost work]# stat test.log æ–‡ä»¶ï¼š\"test.log\" å¤§å°ï¼š0 å—ï¼š0 IO å—ï¼š4096 æ™®é€šç©ºæ–‡ä»¶ è®¾å¤‡ï¼šfd00h/64768d\tInodeï¼š908488 ç¡¬é“¾æ¥ï¼š1 æƒé™ï¼š(0644/-rw-r--r--) Uidï¼š( 0/ root) Gidï¼š( 0/ root) ç¯å¢ƒï¼šunconfined_u:object_r:admin_home_t:s0 æœ€è¿‘è®¿é—®ï¼š2020-05-10 04:38:39.399791808 -0400 æœ€è¿‘æ›´æ”¹ï¼š2020-05-10 04:38:39.399791808 -0400 æœ€è¿‘æ”¹åŠ¨ï¼š2020-05-10 04:38:39.399791808 -0400 åˆ›å»ºæ—¶é—´ï¼š- 2ã€å½“æˆ‘ç”¨vim/viå·¥å…·è¿›è¡Œç¼–è¾‘ä¿å­˜ä¹‹åï¼Œå˜ä¸ºäº†ï¼š908490\n[root@localhost work]# vi test.log [root@localhost work]# stat test.log æ–‡ä»¶ï¼š\"test.log\" å¤§å°ï¼š7 å—ï¼š8 IO å—ï¼š4096 æ™®é€šæ–‡ä»¶ è®¾å¤‡ï¼šfd00h/64768d\tInodeï¼š908490 ç¡¬é“¾æ¥ï¼š1 æƒé™ï¼š(0644/-rw-r--r--) Uidï¼š( 0/ root) Gidï¼š( 0/ root) ç¯å¢ƒï¼šunconfined_u:object_r:admin_home_t:s0 æœ€è¿‘è®¿é—®ï¼š2020-05-10 04:39:01.950055784 -0400 æœ€è¿‘æ›´æ”¹ï¼š2020-05-10 04:39:01.950055784 -0400 æœ€è¿‘æ”¹åŠ¨ï¼š2020-05-10 04:39:01.953305882 -0400 åˆ›å»ºæ—¶é—´ï¼š- 3ã€è€Œç”¨echoå‘½ä»¤ä¿®æ”¹çœ‹åˆ°inodeä¿¡æ¯å¹¶æ²¡æœ‰æ”¹å˜, 908490\n[root@localhost work]# echo \"test some log\"\u003e\u003etest.log [root@localhost work]# stat test.log æ–‡ä»¶ï¼š\"test.log\" å¤§å°ï¼š21 å—ï¼š8 IO å—ï¼š4096 æ™®é€šæ–‡ä»¶ è®¾å¤‡ï¼šfd00h/64768d\tInodeï¼š908490 ç¡¬é“¾æ¥ï¼š1 æƒé™ï¼š(0644/-rw-r--r--) Uidï¼š( 0/ root) Gidï¼š( 0/ root) ç¯å¢ƒï¼šunconfined_u:object_r:admin_home_t:s0 æœ€è¿‘è®¿é—®ï¼š2020-05-10 04:39:01.950055784 -0400 æœ€è¿‘æ›´æ”¹ï¼š2020-05-10 04:41:16.794459151 -0400 æœ€è¿‘æ”¹åŠ¨ï¼š2020-05-10 04:41:16.794459151 -0400 åˆ›å»ºæ—¶é—´ï¼š- ","éªŒè¯#éªŒè¯":"å…¶å®é€šè¿‡inodeçš„æ”¹å˜ä»¥åŠå¯ä»¥çŒœæµ‹å‡ºåœ¨ä½¿ç”¨vi/vimè¿›è¡Œç¼–è¾‘çš„æ—¶å€™ï¼Œæ–‡ä»¶ä»¥åŠå˜ä¸ºäº†ä¸€ä¸ªæ–°çš„æ–‡ä»¶ï¼Œè¿™é‡Œæˆ‘ä¸»è¦é€šè¿‡inotifywaitæ¥çœ‹ä¸€ä¸‹ï¼Œåœ¨è¿›è¡Œvimç¼–è¾‘çš„æ—¶å€™ï¼Œæ–‡ä»¶ä¼šäº§ç”Ÿä»€ä¹ˆæ—¶é—´\nä¸€å¼€å§‹æœ¬æ¥æ‰“ç®—ä½¿ç”¨golangä¸­github.com/fsnotify/fsnotifyå»çœ‹çš„ï¼Œä½†æ˜¯å‘ç°åŒ…ä¸­å¯¹eventè¿›è¡Œäº†åˆå¹¶ï¼Œä¸å¤ŸåŸå§‹ã€‚æ‰€ä»¥æ‰ç›´æ¥ä½¿ç”¨inotifywait æ¥çœ‹\ninotifywaitå‘½ä»¤ï¼š\ninotifywait -rm test.log æ–‡ä»¶æƒé™ï¼š\n-rw-r--r--. 1 root root 49 5æœˆ 14 05:40 test.log 1ã€ä½¿ç”¨vimè¿›è¡Œç¼–è¾‘çš„ç»“æœï¼š\n[root@localhost work]# inotifywait -rm test.log Setting up watches. Beware: since -r was given, this may take a while! Watches established. test.log OPEN test.log ACCESS test.log CLOSE_NOWRITE,CLOSE test.log MOVE_SELF test.log ATTRIB test.log DELETE_SELF å¯ä»¥çœ‹åˆ°å¯¹æ–‡ä»¶è¿›è¡Œäº†DELETE_SELF\næ³¨æ„å½“å†æ¬¡è¿›è¡Œç¼–è¾‘çš„æ—¶å€™ï¼Œå·²ç»æ— æ³•ç›‘å¬åˆ°äº†ï¼Œå› ä¸ºåŸæœ‰æ–‡ä»¶å·²ç»è¢«åˆ é™¤ï¼Œéœ€è¦é‡æ–°ç›‘å¬\n2ã€ä½¿ç”¨echoè¿›è¡Œè¿½åŠ å†™å…¥çš„ç»“æœ\n[root@localhost work]# inotifywait -rm test.log Setting up watches. Beware: since -r was given, this may take a while! Watches established. test.log OPEN test.log MODIFY test.log CLOSE_WRITE,CLOSE 3ã€ç›‘å¬æ•´ä¸ªç›®å½•ï¼Œå¯ä»¥çœ‹åˆ°æ›´å¤šä¿¡æ¯\n[root@localhost work]# inotifywait -rm ./dir/ Setting up watches. Beware: since -r was given, this may take a while! Watches established. # å½“è¿›è¡Œæ–‡ä»¶å†™å…¥æ—¶ ./dir/ OPEN test.log ./dir/ CREATE .test.log.swp ./dir/ OPEN .test.log.swp ./dir/ CREATE .test.log.swx ./dir/ OPEN .test.log.swx ./dir/ CLOSE_WRITE,CLOSE .test.log.swx ./dir/ DELETE .test.log.swx ./dir/ CLOSE_WRITE,CLOSE .test.log.swp ./dir/ DELETE .test.log.swp ./dir/ CREATE .test.log.swp ./dir/ OPEN .test.log.swp ./dir/ MODIFY .test.log.swp ./dir/ ATTRIB .test.log.swp ./dir/ ACCESS test.log ./dir/ CLOSE_NOWRITE,CLOSE test.log ./dir/ MODIFY .test.log.swp # å½“è¿›è¡Œæ–‡ä»¶ä¿å­˜æ˜¯ ./dir/ CREATE 4913 ./dir/ OPEN 4913 ./dir/ ATTRIB 4913 ./dir/ CLOSE_WRITE,CLOSE 4913 ./dir/ DELETE 4913 ./dir/ MOVED_FROM test.log ./dir/ MOVED_TO test.log~ ./dir/ CREATE test.log ./dir/ OPEN test.log ./dir/ MODIFY test.log ./dir/ CLOSE_WRITE,CLOSE test.log ./dir/ ATTRIB test.log ./dir/ MODIFY .test.log.swp ./dir/ DELETE test.log~ ./dir/ CLOSE_WRITE,CLOSE .test.log.swp ./dir/ DELETE .test.log.swp å¯ä»¥çœ‹åˆ°åœ¨è¿›è¡Œæ–‡ä»¶ä¿å­˜æ—¶ï¼Œå°†åŸæœ‰test.log ç§»åŠ¨ä¸ºtest.log~ï¼Œå¹¶æ–°åˆ›å»ºä¸€ä¸ªæ–‡ä»¶test.logï¼Œæœ€åå¯¹test.log~å¤‡ä»½æ–‡ä»¶å’Œ.test.log.swpç¼“å†²åŒºæ–‡ä»¶è¿›è¡Œåˆ é™¤\n4ã€å½“è¿›è¡Œchmod o+w test.logæ—¶ï¼Œçœ‹åˆ°çš„ä¿¡æ¯å¦‚ä¸‹ï¼š\n./dir/ CREATE 4913 ./dir/ OPEN 4913 ./dir/ ATTRIB 4913 ./dir/ CLOSE_WRITE,CLOSE 4913 ./dir/ DELETE 4913 ./dir/ OPEN test.log ./dir/ CREATE test.log~ ./dir/ OPEN test.log~ ./dir/ ATTRIB test.log~ ./dir/ ACCESS test.log ./dir/ MODIFY test.log~ ./dir/ CLOSE_WRITE,CLOSE test.log~ ./dir/ ATTRIB test.log~ ./dir/ CLOSE_NOWRITE,CLOSE test.log ./dir/ MODIFY test.log ./dir/ OPEN test.log ./dir/ MODIFY test.log ./dir/ CLOSE_WRITE,CLOSE test.log ./dir/ ATTRIB test.log ./dir/ MODIFY .test.log.swp ./dir/ DELETE test.log~ ./dir/ CLOSE_WRITE,CLOSE .test.log.swp ./dir/ DELETE .test.log.swp å¯¹æ¯”3ä¸­çš„ç»“æœæ²¡æœ‰å°†test.log move to test.log~çš„æ“ä½œï¼Œè€Œæ˜¯ç›´æ¥å¯¹test.logæ–‡ä»¶è¿›è¡Œæ›´æ”¹ï¼Œæ‰€ä»¥æ­¤æ—¶inodeä¿¡æ¯å¹¶æ²¡æœ‰æ”¹å˜\n5ã€å¦‚æœå…³é—­vimå¤‡ä»½\né€šè¿‡è®¾ç½®vimå‚æ•°set nobackup nowritebackupå…³é—­vimçš„å¤‡ä»½ï¼Œåˆ™åœ¨ä¿å­˜çš„æ—¶å€™ä¸ä¼šç”Ÿæˆtest.log~æ–‡ä»¶ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œinodeä¿¡æ¯ä¹Ÿæ˜¯ä¸ä¼šæ”¹å˜çš„"},"title":"ç”¨vimä¿å­˜æ–‡ä»¶å’Œechoå‘½ä»¤åˆ°åº•æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ"},"/blog/202005/getting-started-with-postgres/":{"data":{"":"æœ€è¿‘éœ€è¦å°†mysqlæ•°æ®åº“åˆ‡æ¢åˆ°pgæ•°æ®åº“ï¼ˆå…¬å¸è¦æ±‚æ–°ä¸Šçš„åº”ç”¨DBé¦–é€‰postgresï¼‰ï¼Œæ‰€ä»¥å¯¹pgè¿›è¡ŒåŸºæœ¬å­¦ä¹ äº†ä¸‹ï¼Œæ€»ä½“æ„Ÿè§‰ç›¸å·®ä¸å¤§ï¼Œåœ¨ä¸€äº›ç»†èŠ‚ä»¥åŠéœ€è¦ä¸Šå¯èƒ½éœ€è¦æ³¨æ„ã€‚","ä¸mysqlå¯¹æ¯”#ä¸mysqlå¯¹æ¯”":" åŸå…ˆåœ¨mysqlä¸­ä¼šæ¯”è¾ƒå»ºè®®ç”¨åå¼•å·(`)æ¥å¯¹å­—æ®µè¿›è¡Œè½¬ä¹‰ï¼Œåœ¨postgresä¸­å°±ä¸è¡Œäº† MySQL å¯ä»¥ä½¿ç”¨å•å¼•å·ï¼ˆâ€™ï¼‰æˆ–è€…åŒå¼•å·ï¼ˆ\"ï¼‰è¡¨ç¤ºå€¼ï¼Œä½†æ˜¯ PG åªèƒ½ç”¨å•å¼•å·ï¼ˆâ€™ï¼‰è¡¨ç¤ºå€¼ï¼ŒPG çš„åŒå¼•å·ï¼ˆ\"ï¼‰æ˜¯è¡¨ç¤ºç³»ç»Ÿæ ‡è¯†ç¬¦çš„ï¼Œæ¯”å¦‚è¡¨åæˆ–è€…å­—æ®µåã€‚MySQLå¯ä»¥ä½¿ç”¨åå•å¼•å·ï¼ˆ`ï¼‰è¡¨ç¤ºç³»ç»Ÿæ ‡è¯†ç¬¦ï¼Œæ¯”å¦‚è¡¨åã€å­—æ®µåï¼ŒPG ä¹Ÿæ˜¯ä¸æ”¯æŒçš„\næ—¶é—´ç±»å‹ï¼špostgresä¸­æ—¶é—´ç±»å‹å¸¦ä¸Šwith time zoneæ—¶åŒº è¿™ä¸ªåœ¨ç”¨çš„æ—¶å€™æŒºæ–¹ä¾¿çš„ï¼Œé¿å…æ—¶åŒºä¸å¯¹ã€‚\nåŸå…ˆä¸€ç›´ç”¨https://github.com/silenceper/gogen(ä¸€ä¸ªè‡ªåŠ¨åŒ–ormç”Ÿæˆå·¥å…·)æ¥ç”Ÿæˆdbç›¸å…³çš„æ“ä½œä¸€å¼€å§‹åªæ”¯æŒmysqlï¼Œåé¢åŠ å…¥äº†postgresçš„æ”¯æŒå°±å±è”½äº†å¯¹åº•å±‚dbçš„é€‰æ‹©ï¼Œæ–¹ä¾¿ã€‚\nä¸è¿‡å¯¹äºgoå¼€å‘æ¥è¯´ï¼Œåªè¦ä¸æ˜¯æ‰‹å†™sqlå–æ‰§è¡Œï¼Œè€Œæ˜¯åˆ©ç”¨ä¸€äº›ormå·¥å…·ï¼Œåº•å±‚éƒ½å°è£…äº†å¯¹å¤šç§æ•°æ®åº“çš„æ”¯æŒï¼Œåˆ‡æ¢å°±å˜å¾—æ›´ç®€å•ã€‚\nè¿™é‡Œå¼•å…¥ä¸€ä¸ªè¯é¢˜ï¼šgolangå¼€å‘è€…åˆ°åº•è¯¥ä¸è¯¥ç”¨ormï¼Ÿ\næˆ‘è‡ªå·±è§‰å¾—ï¼Œæœ‰ä¸ªå–èˆï¼Œå¦‚æœéœ€è¦å†™çš„sqlæ¯”è¾ƒå¤æ‚ï¼Œå…³è”å…³ç³»åˆå¤ªå¤šï¼Œè™½ç„¶ormå·¥å…·ä¹Ÿæä¾›äº†è¿™ç§å…³ç³»çš„å¯¹åº”ï¼Œä½†æ˜¯ç”¨çš„è¯è¿˜ä¸å¦‚è‡ªå·±æ¥å†™sqlç®€å•ï¼Œè€Œä¸”ä¹Ÿæ˜“è¯»ã€‚\nå¦‚æœæ˜¯ä¸šåŠ¡ç³»ç»Ÿæ˜¯æ¯”è¾ƒæ¸…æ™°çš„ï¼Œå·²ç»è¢«æ‹†åˆ†çš„å¤Ÿç®€å•ï¼Œæˆ‘åŸºæœ¬ä¸Šéƒ½ä¼šä½¿ç”¨ormå·¥å…·ã€‚\nå‚è€ƒæ–‡æ¡£ï¼šhttps://www.ruanyifeng.com/blog/2013/12/getting_started_with_postgresql.html","åŸºæœ¬æ“ä½œ#åŸºæœ¬æ“ä½œ":"ç™»å½•æ•°æ®åº“ï¼ˆä½¿ç”¨psqlå‘½ä»¤ï¼‰ï¼š\n# è¿›å…¥å®¹å™¨æ‰èƒ½ä½¿ç”¨psqlå‘½ä»¤ docker exec -it postgres bash # ä»¥postgresè§’è‰²ç™»å½• psql -U postgres å¯ä»¥é€šè¿‡ \\?æŸ¥çœ‹ä¸€äº›å¸¸ç”¨çš„æ“ä½œã€‚\n\\hï¼šæŸ¥çœ‹SQLå‘½ä»¤çš„è§£é‡Šï¼Œæ¯”å¦‚\\h selectã€‚ \\?ï¼šæŸ¥çœ‹psqlå‘½ä»¤åˆ—è¡¨ã€‚ \\lï¼šåˆ—å‡ºæ‰€æœ‰æ•°æ®åº“ã€‚ \\c [database_name]ï¼šè¿æ¥å…¶ä»–æ•°æ®åº“ã€‚ \\dï¼šåˆ—å‡ºå½“å‰æ•°æ®åº“çš„æ‰€æœ‰è¡¨æ ¼ã€‚ \\d [table_name]ï¼šåˆ—å‡ºæŸä¸€å¼ è¡¨æ ¼çš„ç»“æ„ã€‚ \\duï¼šåˆ—å‡ºæ‰€æœ‰ç”¨æˆ·ã€‚ \\eï¼šæ‰“å¼€æ–‡æœ¬ç¼–è¾‘å™¨ã€‚ \\conninfoï¼šåˆ—å‡ºå½“å‰æ•°æ®åº“å’Œè¿æ¥çš„ä¿¡æ¯ã€‚ åˆ›å»ºç”¨æˆ·ä»¥åŠDB åˆ›å»ºç”¨æˆ·\nCREATE USER dbuser WITH PASSWORD 'password'; åˆ›å»ºç”¨æˆ·æ•°æ®åº“ï¼Œè¿™é‡Œä¸ºexampledbï¼Œå¹¶æŒ‡å®šæ‰€æœ‰è€…ä¸ºdbuser\nCREATE DATABASE exampledb OWNER dbuser; å°†exampledbæ•°æ®åº“çš„æ‰€æœ‰æƒé™éƒ½èµ‹äºˆdbuserï¼Œå¦åˆ™dbuseråªèƒ½ç™»å½•æ§åˆ¶å°ï¼Œæ²¡æœ‰ä»»ä½•æ•°æ®åº“æ“ä½œæƒé™ã€‚\nGRANT ALL PRIVILEGES ON DATABASE exampledb to dbuser; æœ€åï¼Œä½¿ç”¨\\qå‘½ä»¤é€€å‡ºæ§åˆ¶å°ï¼ˆä¹Ÿå¯ä»¥ç›´æ¥æŒ‰ctrl+Dï¼‰ã€‚\n\\q æ•°æ®åº“æ“ä½œ # åˆ›å»ºæ–°è¡¨ CREATE TABLE user_tbl(name VARCHAR(20), signup_date DATE); # æ’å…¥æ•°æ® INSERT INTO user_tbl(name, signup_date) VALUES('å¼ ä¸‰', '2013-12-22'); # é€‰æ‹©è®°å½• SELECT * FROM user_tbl; # æ›´æ–°æ•°æ® UPDATE user_tbl set name = 'æå››' WHERE name = 'å¼ ä¸‰'; # åˆ é™¤è®°å½• DELETE FROM user_tbl WHERE name = 'æå››' ; # æ·»åŠ æ ä½ ALTER TABLE user_tbl ADD email VARCHAR(40); # æ›´æ–°ç»“æ„ ALTER TABLE user_tbl ALTER COLUMN signup_date SET NOT NULL; # æ›´åæ ä½ ALTER TABLE user_tbl RENAME COLUMN signup_date TO signup; # åˆ é™¤æ ä½ ALTER TABLE user_tbl DROP COLUMN email; # è¡¨æ ¼æ›´å ALTER TABLE user_tbl RENAME TO backup_tbl; # åˆ é™¤è¡¨æ ¼ DROP TABLE IF EXISTS backup_tbl; ","å®‰è£…#å®‰è£…":"æˆ‘è¿™é‡Œæ˜¯ä»¥dockerçš„æ–¹å¼æ¥è¿›è¡Œå®‰è£…çš„ã€‚\nè¿™ç§å®‰è£…æ–¹å¼åªèƒ½ä½œä¸ºä½œä¸ºæœ¬åœ°å¼€å‘è°ƒè¯•ç”¨\ndocker run --name postgres -v /Users/silenceper/workspace/postgres/data:/var/lib/postgresql/data -e POSTGRES_PASSWORD=123 -p 5432:5432 -d postgres:10.3 æŒ‡å®šæ•°æ®å­˜å‚¨ç›®å½•æ˜ å°„åˆ°å®¿ä¸»æœºæœ¬åœ°ï¼Œé¿å…å®¹å™¨é”€æ¯åæ•°æ®ä¸¢å¤± æŒ‡å®šå¯†ç postgresç”¨æˆ·çš„å¯†ç ä¸º123 æŒ‡å®šä½¿ç”¨postgres:10.3é•œåƒ å¯ä»¥é€‰æ‹©pgAdmin4ä½œä¸ºå®¢æˆ·ç«¯ï¼Œæœ‰å›¾å½¢åŒ–UIç•Œé¢ï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨psqlå‘½ä»¤ã€‚"},"title":"postgreså…¥é—¨"},"/blog/202006/build-arm-image-on-x86_84/":{"data":{"":"","#":"æœ‰å‡ ç§åŠæ³•å¯ä»¥æ‰“åŒ…å‡ºarm64çš„é•œåƒ\nç›´æ¥åœ¨armæœºå™¨ä¸Šæ‰§è¡Œç¼–è¯‘å’Œæ‰“åŒ… é€šè¿‡qemuæ¨¡æ‹Ÿarmç¯å¢ƒ åˆ©ç”¨dockeræä¾›çš„buildxï¼ˆéœ€è¦å¯ç”¨è¯•éªŒæ€§ç‰¹æ€§ï¼‰ æˆ‘æ²¡æœ‰armçš„æœºå™¨~ï¼Œæ‰€ä»¥æˆ‘ä¸»è¦è¯•äº†ä¸€ä¸‹ä¸‹é¢ä¸¤ç§æ–¹å¼ã€‚\nå€ŸåŠ©qemu-user-staticé•œåƒæ‰“åŒ… æ–‡æ¡£ï¼šhttps://github.com/multiarch/qemu-user-static\nå¼€å¯armå¹³å°æ”¯æŒï¼š\n$ docker run --rm --privileged multiarch/qemu-user-static:register --reset $ docker build --rm -t \"test/integration/ubuntu\" -\u003c\u003cEOF FROM multiarch/qemu-user-static:x86_64-aarch64 as qemu FROM arm64v8/ubuntu COPY --from=qemu /usr/bin/qemu-aarch64-static /usr/bin EOF $ docker run --rm -t \"test/integration/ubuntu\" uname -m aarch64 åœ¨è¿è¡Œqemu-user-static:registeré•œåƒçš„æ—¶å€™ï¼Œå°±é€šè¿‡å†…æ ¸ä¸­çš„binfmt_miscæœºåˆ¶æ³¨å…¥äº†å“ªäº›å¯æ‰§è¡Œæ–‡ä»¶å¯ä»¥è¢«è¯†åˆ«ã€‚\næ³¨æ„ï¼šéœ€è¦å°†qemu-aarch64-staticæ–‡ä»¶ copy åˆ°/usr/binç›®å½•ã€‚\nbinfmt_miscæ˜¯Linuxå†…æ ¸è¯´æä¾›çš„ä¸€ç§æ‰©å±•æœºåˆ¶, ä½¿å¾—æ›´å¤šç±»å‹çš„æ–‡ä»¶å¾—ä»¥æˆä¸ºï¼‚å¯æ‰§è¡Œï¼‚æ–‡ä»¶ï¼Linuxå†…æ ¸æœ¬èº«æ”¯æŒELFã€a.outã€è„šæœ¬ï¼ˆä¹Ÿå°±æ˜¯ä¸Šé¢æ‰€è¯´çš„ç¬¬ä¸€è¡Œ#!æŒ‡å®šè§£é‡Šå™¨çš„æ–¹å¼ï¼‰è¿™é›†ä¸­ï¼‚å¯æ‰§è¡Œæ–‡ä»¶ï¼‚ï¼ä½†å®ƒè¿˜æä¾›äº†ä¸€ä¸ªç§°ä¸ºbinfmt_miscçš„å†…æ ¸æ¨¡å—, é€šè¿‡è¿™ä¸ªæ¨¡å—å¯ä»¥åŠ¨æ€æ³¨å†Œä¸€äº›ï¼‚å¯æ‰§è¡Œæ–‡ä»¶æ ¼å¼ï¼‚,æ³¨å†Œä¹‹åæˆ‘ä»¬å°±å¯ä»¥ç›´æ¥ï¼‚æ‰§è¡Œï¼‚è¿™ä¸ªç¨‹åºæ–‡ä»¶äº†ï¼\né€šè¿‡buildxæ‰“åŒ…æ”¯æŒå¤šæ¶æ„çš„é•œåƒ æ–‡æ¡£ï¼šhttps://docs.docker.com/buildx/working-with-buildx/\né¦–å…ˆéœ€è¦å¼€å¯è¿™ä¸ªå®éªŒæ€§çš„åŠŸèƒ½ï¼Œæ€ä¹ˆå¼€å¯çœ‹è¿™é‡Œï¼šhttps://github.com/docker/cli/blob/master/experimental/README.md\ndocker cloent: åœ¨~/.docker/config.json åŠ å…¥``å†™å…¥\"experimental\":\"enabled\" dcoker daemon: å¯åŠ¨å‚æ•°ä¸ŠåŠ ä¸Šâ€“experimentalæˆ–è€…/etc/docker/daemon.jsonå†™å…¥ \"experimental\": true è¿›è¡Œåˆå§‹åŒ–ï¼š\ndocker buildx create --name builderx docker buildx use builderx docker buildx inspect --bootstrap #è¿™ä¸€æ­¥ä¼šä»å¤–ç½‘æ‹‰å–`moby/buildkit`é•œåƒï¼Œè²Œä¼¼è¿˜æ”¹ä¸äº† æ¥ä¸‹æ¥ä½ å°±å¯ä»¥é€šè¿‡å¦‚ä¸‹å‘½ä»¤å»æ„å»ºå¤šç§æ¶æ„çš„é•œåƒï¼š\ndocker buildx build --platform linux/amd64,linux/arm64 -f Dockerfile -t silenceper/reverse-proxy . --push --pushå‚æ•°è¡¨ç¤ºæ„å»ºå®Œæˆä¹‹åï¼Œå¹¶pushåˆ°é•œåƒä»“åº“å½“ä¸­ã€‚\nå› ä¸ºé•œåƒä»“åº“æ”¯æŒä¸€ä¸ªä»“åº“ä¸Šä¼ å¤šç§æ¶æ„ï¼Œå¹¶ä¸”ä¼šæ ¹æ®æ„å»ºå¹³å°pullç›¸åŒ¹é…æ¶æ„çš„é•œåƒï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åœ¨ä¸€ä¸ªDockerfileï¼Œå¹¶ä¸”é€šè¿‡ä¸€ä¸ªå‘½ä»¤æ‰“åŒ…é•œåƒå¹¶pushã€‚\nè¿™é‡Œç”¨åˆ°çš„Dockerfileåœ¨è¿™é‡Œï¼šhttps://github.com/silenceper/reverse-proxy/blob/master/Dockerfile\né€šè¿‡dockerçš„å¤šé˜¶æ®µæ„å»ºå°†ç¼–è¯‘å’Œæ‰“åŒ…æ”¾åœ¨ä¸€èµ·äº†ï¼Œéš”ç¦»äº†ç¯å¢ƒçš„å·®å¼‚ã€‚\nFROM golang:alpine as builder ADD . /go/src/github.com/silenceper/reverse-proxy/ RUN cd /go/src/github.com/silenceper/reverse-proxy/ \\ \u0026\u0026 go get -v \\ \u0026\u0026 CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . FROM alpine MAINTAINER silenceper \u003csilenceper@gmail.com\u003e COPY --from=builder /go/src/github.com/silenceper/reverse-proxy/app /bin/app ENTRYPOINT [\"/bin/app\"] EXPOSE 80 ","æ€»ç»“#æ€»ç»“":"æœ€æ–¹ä¾¿çš„è‚¯å®šæ˜¯ç›´æ¥é€šè¿‡buildxè¿›è¡Œæ‰“åŒ…å’Œç¼–è¯‘ï¼Œä½†æ˜¯æˆ‘çš„ç¯å¢ƒæ²¡æ³•è®¿é—®å¤–ç½‘ï¼Œåˆæ²¡æ³•æ‹‰å–å¤–ç½‘çš„é•œåƒï¼Œæ‰€ä»¥æœ€ç»ˆè¿˜æ˜¯é€‰æ‹©ä½¿ç”¨qemu-user-staticæ‰“åŒ…å‡ºæ¥äº†ã€‚\nå‚è€ƒ https://blog.fleeto.us/post/buildx-and-osx/ https://juejin.im/post/5af86fb15188251b8015c102 https://www.cnblogs.com/bamanzi/p/run-x86-linux-progs-with-qemu-user-on-arm.html "},"title":"åœ¨x86_64æœºå™¨ä¸Šæ„å»ºarm64é•œåƒ"},"/blog/202007/docker-tar-push/":{"data":{"":"ä¸ºäº†å®ç°docker taråŒ…èƒ½å¤Ÿç›´æ¥é€šè¿‡é¡µé¢ä¸Šä¼ ï¼Œè°ƒç ”äº†ä¸€ä¸‹registryçš„apiï¼Œä»¥åŠå¦‚ä½•è§£ætaråŒ…ï¼ˆå…¶å®å°±æ˜¯docker daemonç¨‹åºå®ç°çš„éƒ¨åˆ†ï¼‰ã€‚\nè¦æƒ³å®ç°ï¼Œé¦–å…ˆè¦äº†è§£docker taråŒ…ä¸­ç»“æ„ç»„æˆï¼š","registry-api#registry api":"æµç¨‹ï¼š\n1ã€è·å–é‰´æƒä¿¡æ¯ 2ã€æ£€æŸ¥layer.taræ˜¯å¦å·²ç»å­˜åœ¨ 3ã€ä¸Šä¼ layer.tar 4ã€ä¸Šä¼ image config 5ã€ä¸Šä¼ manifestï¼ˆéåŒ…ä¸­çš„manifest.jsonè€Œæ˜¯Manifest structï¼‰ è¿™é‡Œåªåˆ—å‡ºäº†åœ¨ä¸Šä¼ çš„æ—¶å€™éœ€è¦ç”¨çš„api\n1ã€è·å–é‰´æƒä¿¡æ¯\nè¿™é‡Œè·Ÿregistryä»“åº“é€‰æ‹©çš„é‰´æƒæ–¹å¼æœ‰å…³ï¼Œå¯é€‰basic authæˆ–è€…tokené‰´æƒã€‚ è¿™é‡Œæˆ‘æ˜¯ä»¥æœ€åŸºæœ¬çš„basic authä¸ºä¾‹å­ï¼Œå¦‚æœæ˜¯tokené‰´æƒçš„æ–¹å¼å‚è€ƒè¿™é‡Œï¼š https://docs.docker.com/registry/spec/auth/jwt/\n2ã€æ£€æŸ¥ä¸Šä¼ \nHEAD /v2/image/blobs/\u003cdigest\u003e è‹¥è¿”å›200 OK åˆ™è¡¨ç¤ºå­˜åœ¨ï¼Œä¸ç”¨ä¸Šä¼ \n3ã€å¼€å§‹ä¸Šä¼ æœåŠ¡ æˆ‘è¿™é‡Œæ˜¯ä»¥åˆ†å—ä¸Šä¼ çš„æ–¹å¼è¿›è¡Œ\nPOST /v2/image/blobs/uploads/ å¦‚æœpostè¯·æ±‚è¿”å›202 acceptedï¼Œä¸€ä¸ªurlä¼šåœ¨locationå­—æ®µè¿”å›.\n202 Accepted Location: /v2/\\\u003cimage\u003e/blobs/uploads/\\\u003cuuid\u003e Range: bytes=0-\u003coffset\u003e Content-Length: 0 Docker-Upload-UUID: \u003cuuid\u003e # å¯ä»¥ç”¨æ¥æŸ¥çœ‹ä¸Šä¼ çŠ¶æ€å’Œå®ç°æ–­ç‚¹ç»­ä¼  4ã€åˆ†å—ä¸Šä¼  æ ¹æ®ä¸Šä¸€æ­¥è·å–çš„urlï¼Œä»¥PATCHçš„æ–¹å¼æäº¤åˆ†å—æ•°æ®ã€‚ å¦‚æœæ˜¯æœ€åä¸€å—æ•°æ®ä¸Šä¼ ï¼Œåˆ™ä»¥PUTçš„æ–¹å¼æäº¤ï¼Œå¦‚ä¸‹ï¼š\n\u003e PUT /v2/\u003cname\u003e/blob/uploads/\u003cuuid\u003e?digest=\u003cdigest\u003e \u003e Content-Length: \u003csize of chunk\u003e \u003e Content-Range: \u003cstart of range\u003e-\u003cend of range\u003e \u003e Content-Type: application/octet-stream \u003cLast Layer Chunk Binary Data\u003e ä¸Šä¼ layerï¼Œimage configï¼Œmanifestsä¿¡æ¯éƒ½æ˜¯ä¸€æ ·çš„ã€‚\næˆ‘æš‚æ—¶åªç”¨åˆ°äº†ä»¥ä¸Šapiï¼Œæ›´å¤šçš„apiå‚è€ƒï¼šhttps://docs.docker.com/registry/spec/api/","taråŒ…ç»“æ„#taråŒ…ç»“æ„":"æ‹¿äº†ä¸€ä¸ªåŒ…å«ä¸€ä¸ªé•œåƒçš„taråŒ…è¿›è¡Œè§£å‹ï¼š\n. â”œâ”€â”€ 1ecf8bc84a7c3d60c0a6bbdd294f12a6b0e17a8269616fc9bdbedd926f74f50c â”‚Â â”œâ”€â”€ VERSION â”‚Â â”œâ”€â”€ json â”‚Â â””â”€â”€ layer.tar â”œâ”€â”€ 6f4ec1f3d7ea33646d491a705f94442f5a706e9ac9acbca22fa9b117094eb720.json â”œâ”€â”€ aaac5bde2c2bcb6cc28b1e6d3f29fe13efce6d6b669300cc2c6bfab96b942af4 â”‚Â â”œâ”€â”€ VERSION â”‚Â â”œâ”€â”€ json â”‚Â â””â”€â”€ layer.tar â”œâ”€â”€ b63363f0d2ac8b3dca6f903bb5a7301bf497b1e5be8dc4f57a14e4dc649ef9bb â”‚Â â”œâ”€â”€ VERSION â”‚Â â”œâ”€â”€ json â”‚Â â””â”€â”€ layer.tar â”œâ”€â”€ c453224a84b8318b0a09a83052314dd876899d3a1a1cf2379e74bba410415059 â”‚Â â”œâ”€â”€ VERSION â”‚Â â”œâ”€â”€ json â”‚Â â””â”€â”€ layer.tar â”œâ”€â”€ dd8ef1d42fbcccc87927eee94e57519c401b84437b98fcf35505fb6b7267a375 â”‚Â â”œâ”€â”€ VERSION â”‚Â â”œâ”€â”€ json â”‚Â â””â”€â”€ layer.tar â”œâ”€â”€ manifest.json â””â”€â”€ repositories æ–‡ä»¶è¯´æ˜ï¼š\nmanifest.jsonæ–‡ä»¶ï¼š\n[ { \"Config\":\"6f4ec1f3d7ea33646d491a705f94442f5a706e9ac9acbca22fa9b117094eb720.json\", \"RepoTags\":[ \"alpine:filebeat-6.8.7-arm64\" ], \"Layers\":[ \"aaac5bde2c2bcb6cc28b1e6d3f29fe13efce6d6b669300cc2c6bfab96b942af4/layer.tar\", \"dd8ef1d42fbcccc87927eee94e57519c401b84437b98fcf35505fb6b7267a375/layer.tar\", \"c453224a84b8318b0a09a83052314dd876899d3a1a1cf2379e74bba410415059/layer.tar\", \"b63363f0d2ac8b3dca6f903bb5a7301bf497b1e5be8dc4f57a14e4dc649ef9bb/layer.tar\", \"1ecf8bc84a7c3d60c0a6bbdd294f12a6b0e17a8269616fc9bdbedd926f74f50c/layer.tar\" ] } ] manifest.json åŒ…å«äº†å¯¹è¿™ä¸ªtaråŒ…çš„æè¿°ä¿¡æ¯ï¼Œæ¯”å¦‚image configæ–‡ä»¶åœ°å€ï¼Œtagsè¯´æ˜ï¼Œé•œåƒlayerä¿¡æ¯ï¼Œåœ¨è§£æçš„æ—¶å€™ä¹Ÿæ˜¯æ ¹æ®è¿™ä¸ªæ–‡ä»¶å»è·å–å…³è”çš„æ–‡ä»¶ã€‚\nimage configæ–‡ä»¶\næ¯”å¦‚ï¼š6f4ec1f3d7ea33646d491a705f94442f5a706e9ac9acbca22fa9b117094eb720.jsonæ–‡ä»¶ï¼š\nå†…å®¹å¤ªå¤šå°±ä¸è´´äº† è¿™é‡ŒåŒ…å«äº†é•œåƒè¿è¡Œçš„ä¿¡æ¯ï¼Œæ¯”å¦‚envï¼Œæ‰§è¡Œå‚æ•°ï¼Œä»¥åŠé•œåƒå†å²ç­‰ã€‚\nlayerå±‚æ–‡ä»¶ï¼šlayer.tar\né•œåƒçš„æ¯ä¸€å±‚çš„æ–‡ä»¶ä¿¡æ¯éƒ½æ‰“åŒ…åœ¨äº†ä¸€ä¸ªå•ç‹¬çš„layer.taråŒ…ä¸­ï¼Œä¹Ÿæ˜¯åœ¨ä¸Šä¼ çš„æ—¶å€™éœ€è¦ç”¨åˆ°çš„ã€‚","å®ç°#å®ç°":"ä¸Šé¢è¯´APIæ²¡å•¥æ„Ÿè§‰ï¼Œè¿˜æ˜¯çœ‹ä»£ç æ¯”è¾ƒæ˜ç™½ï¼Œæ‰€ä»¥å®ç°äº†è¿™ä¹ˆä¸€ä¸ªå·¥å…·ï¼šhttps://github.com/silenceper/docker-tar-push Usage:\npush your docker tar archive image without docker. Usage: docker-tar-push [flags] Flags: -h, --help help for docker-tar-push --log-level int log-level, 0:Fatal,1:Error,2:Warn,3:Info,4:Debug (default 3) --password string registry auth password --registry string registry url --skip-ssl-verify skip ssl verify --username string registry auth username Example:\ndocker-tar-push alpine:latest --registry=http://localhost:5000 å‚è€ƒ\nhttps://www.jianshu.com/p/6a7b80122602 https://github.com/Razikus/dockerregistrypusher https://docs.docker.com/registry/spec/auth/jwt/ https://github.com/docker/distribution/ "},"title":"å°†é•œåƒtaråŒ…é€šè¿‡APIç›´æ¥pushåˆ°registryä»“åº“"},"/blog/202009/how-to-use-keda/":{"data":{"åŸºäºprometheusæŒ‡æ ‡è¿›è¡Œä¼¸ç¼©#åŸºäºprometheusæŒ‡æ ‡è¿›è¡Œä¼¸ç¼©":"æˆ‘è¿™é‡Œæœ‰ä¸ªhttp demoçš„åº”ç”¨ï¼Œä¸ŠæŠ¥äº†gin_requests_totalæŒ‡æ ‡åˆ°prometheusï¼Œé€šè¿‡abè¯·æ±‚httpæ¥å£æ¨¡æ‹Ÿå‹åŠ›ä¸Šå‡çš„æƒ…å†µï¼š\nè¿™é‡Œæˆ‘å°†minReplicaCountè®¾ç½®ä¸º2ï¼Œå› ä¸ºåœ¨æ²¡æœ‰æµé‡çš„æ—¶å€™å‰¯æœ¬æ•°å°†ä¼šè¢«kedaè®¾ç½®ä¸º0ã€‚\napiVersion: keda.k8s.io/v1alpha1 kind: ScaledObject metadata: name: prometheus-scaledobject namespace: default spec: scaleTargetRef: deploymentName: http-demo minReplicaCount: 2 triggers: - type: prometheus metadata: serverAddress: http://192.168.99.100:31046/ metricName: gin_requests_total threshold: '2' query: sum(rate(gin_requests_total{app=\"http-demo\",code=\"200\"}[2m])) å½“åˆ›å»ºè¯¥ScaledObject ï¼Œæˆ‘ä»¬çœ‹åˆ°åŒæ—¶åˆ›å»ºäº†ä¸€ä¸ªhpaèµ„æºï¼š\nâœ example kubectl get hpa NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE keda-hpa-http-demo Deployment/http-demo 0/2 (avg) 2 100 2 70m é€šè¿‡å‹æµ‹è§‚å¯Ÿhpaèµ„æºå˜åŒ–ï¼š\n\u003e ab -c 10 -n 1000 http://127.0.0.1:8080/ Every 1.0s: kubectl get hpa anymore.local: Mon Sep 14 14:23:59 2020 NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE keda-hpa-http-demo Deployment/http-demo 8/2 (avg) 2 100 4 73m å¯ä»¥çœ‹å¾—åˆ°éšç€æµé‡ä¸Šå‡ï¼Œç”±hpaæ§åˆ¶çš„å‰¯æœ¬æ•°åœ¨ä¸Šå‡ï¼Œè¿™å°±è¾¾åˆ°äº†æˆ‘ä»¬æ ¹æ®æµé‡æ‰©å®¹çš„ç›®çš„ï¼Œå½“æµé‡é™ä¸‹æ¥ä¹‹åï¼Œå‰¯æœ¬æ•°ä¹Ÿå‡å°‘ã€‚","å®‰è£…keda#å®‰è£…keda":" æ–‡ç« ä¸­ä½¿ç”¨çš„æ˜¯keda 1.5ç‰ˆæœ¬ï¼Œ2.0è¿˜æœªrelease 1.5ç‰ˆæœ¬æ”¯æŒdeploymentï¼Œjobä¸¤ç§èµ„æºã€‚è€Œåœ¨2.0å¢åŠ äº†StatefulSetä»¥åŠè‡ªå®šä¹‰èµ„æº\nkeda æ˜¯ä¸€ä¸ªæ”¯æŒå¤šç§äº‹ä»¶æºæ¥å¯¹åº”ç”¨è¿›è¡Œå¼¹æ€§ä¼¸ç¼©çš„æ§åˆ¶å™¨ã€‚ æˆ‘è§‰å¾—kedaå¯ä»¥è®¤ä¸ºæ˜¯åŸºäºHPAçš„external metricsçš„ä¸€ç§æ‰©å±•ï¼Œå› ä¸ºå®ƒåˆ©ç”¨äº†hpaä¸­external metricsçš„èƒ½åŠ›ï¼Œå…è®¸ç›´æ¥é…ç½®å¤šä¸ªäº‹ä»¶æºï¼š å®‰è£…kedaä» https://github.com/kedacore/keda/releases ä¸‹è½½1.5ç‰ˆæœ¬çš„zipåŒ…ï¼ŒåŒ…å«äº†yamlå’Œcrd:\nâ”œâ”€â”€ 00-namespace.yaml â”œâ”€â”€ 01-service_account.yaml â”œâ”€â”€ 10-cluster_role.yaml â”œâ”€â”€ 11-role_binding.yaml â”œâ”€â”€ 12-operator.yaml â”œâ”€â”€ 20-metrics-cluster_role.yaml â”œâ”€â”€ 21-metrics-role_binding.yaml â”œâ”€â”€ 22-metrics-deployment.yaml â”œâ”€â”€ 23-metrics-service.yaml â”œâ”€â”€ 24-metrics-api_service.yaml â””â”€â”€ crds â”œâ”€â”€ keda.k8s.io_scaledobjects_crd.yaml â””â”€â”€ keda.k8s.io_triggerauthentications_crd.yaml å®‰è£…ï¼š\nkubectl apply -f ./crds/ kubectl apply -f . ä»¥prometheus å’Œcronä¸¤ä¸ªäº‹ä»¶æºçœ‹ä¸‹å¦‚ä½•ä½¿ç”¨","æ€»ç»“#æ€»ç»“":"ä¹‹å‰ç”¨è¿‡k8s-prometheus-adapteré¡¹ç›®æ¥è¿›è¡Œåº”ç”¨çš„è‡ªå®šä¹‰æŒ‡æ ‡è¿›è¡Œæ‰©å±•ï¼Œå¯¹æ¯”kedaæ„Ÿè§‰kedaæ“ä½œæ›´ç®€å•ï¼Œé…ç½®æ›´åŠ åŠ¨æ€åŒ–ï¼Œå› ä¸ºæŠ½è±¡äº†hpaï¼Œç”¨æˆ·ç›´æ¥æ“ä½œScaledObjectå³å¯ï¼Œä¸éœ€è¦å…³æ³¨hpaå¦‚ä½•è¿›è¡Œé…ç½®ã€‚è€Œä¸”æ”¯æŒå°†å‰¯æœ¬æ•°è®¾ç½®ä¸º0ï¼ŒåŒæ—¶åˆæ‹¥æœ‰ç±»ä¼¼cronhpa(å®šæ—¶ä¼¸ç¼©)çš„åŠŸèƒ½ï¼Œæ‰©å±•èƒ½åŠ›æ¯”è¾ƒå¼ºã€‚\né˜…è¯»åŸæ–‡ä½“éªŒæ›´åŠ ï¼Œæ–‡ä¸­é“¾æ¥æ”¯æŒè·³è½¬","æ‰©å±•äº‹ä»¶æºexternal-scalers#æ‰©å±•äº‹ä»¶æº(external-scalers)":"å¯¹äºåœ¨kedaä¸æ”¯æŒçš„ä¸€äº›äº‹ä»¶æºï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨kedaæä¾›çš„æ‰©å±•æœºåˆ¶æ¥æ‰©å……è‡ªå·±çš„äº‹ä»¶æºã€‚ https://keda.sh/docs/1.5/concepts/external-scalers/ ä¸»è¦æ˜¯é€šè¿‡grpcå®ç°ä¸€ä¸‹æ¥å£å®ç°ï¼š\ntype Scaler interface { GetMetrics(ctx context.Context, metricName string, metricSelector labels.Selector) ([]external_metrics.ExternalMetricValue, error) GetMetricSpecForScaling() []v2beta2.MetricSpec IsActive(ctx context.Context) (bool, error) Close() error } IsActive åœ¨ScaledObject / ScaledJob CRDä¸­å®šä¹‰çš„pollingIntervalä¸Šï¼Œæ¯éš”pollingIntervalæ—¶é—´ï¼Œè°ƒç”¨IsActiveï¼Œå¦‚æœè¿”å›trueï¼Œåˆ™å°†æ¯”ä¾‹ç¼©æ”¾ä¸º1(é»˜è®¤1) Closeè°ƒç”¨Closeå¯ä»¥ä½¿ç¼©æ”¾å™¨æ¸…é™¤è¿æ¥æˆ–å…¶ä»–èµ„æºã€‚ GetMetricSpec è¿”å›ç¼©æ”¾å™¨çš„HPAå®šä¹‰çš„ç›®æ ‡å€¼ã€‚ GetMetrics è¿”å›ä»GetMetricSpecå¼•ç”¨çš„æŒ‡æ ‡çš„å€¼ã€‚ åœ¨2.0ä¸­è¿˜å¤šæ”¯æŒä¸€ç§PushScalerå½¢å¼çš„æ‰©å±•ï¼Œå…è®¸ç”¨æˆ·ä¸»åŠ¨pushæ¥æ˜¯å¦å¼€å¯/åœæ­¢åŸºäºäº‹ä»¶ä¼¸ç¼©","ç»„ä»¶ç»„æˆ#ç»„ä»¶ç»„æˆ":"kedaç”±ä¸¤ä¸ªç»„ä»¶ç»„æˆï¼š\nkeda operatorï¼š è´Ÿè´£åˆ›å»ºç»´æŠ¤hpaå¯¹è±¡èµ„æºï¼ŒåŒæ—¶æ¿€æ´»å’Œåœæ­¢hpaä¼¸ç¼©ã€‚åœ¨æ— äº‹ä»¶çš„æ—¶å€™å°†å‰¯æœ¬æ•°é™ä½ä¸º0(å¦‚æœæœªè®¾ç½®minReplicaCountçš„è¯) metrics server: å®ç°äº†hpaä¸­external metricsï¼Œæ ¹æ®äº‹ä»¶æºé…ç½®è¿”å›è®¡ç®—ç»“æœã€‚ å¯ä»¥çœ‹å¾—åˆ°HPAæ§åˆ¶äº†å‰¯æœ¬1-\u003eNå’ŒN-\u003e1çš„å˜åŒ–ã€‚ kedaæ§åˆ¶äº†å‰¯æœ¬0-\u003e1å’Œ1-\u003e0çš„å˜åŒ–ï¼ˆèµ·åˆ°äº†æ¿€æ´»å’Œåœæ­¢çš„ä½œç”¨ï¼Œå¯¹äºä¸€äº›æ¶ˆè´¹å‹çš„ä»»åŠ¡å‰¯æœ¬æ¯”è¾ƒæœ‰ç”¨ï¼Œæ¯”å¦‚åœ¨å‡Œæ™¨å¯åŠ¨ä»»åŠ¡è¿›è¡Œæ¶ˆè´¹ï¼‰","é…ç½®-scaledobject#é…ç½® ScaledObject":"ä»¥Deploymentä¸ºä¾‹ï¼Œçœ‹ä¸‹ScaledObjectæ”¯æŒå“ªäº›å˜é‡\napiVersion: keda.k8s.io/v1alpha1 kind: ScaledObject metadata: name: {scaled-object-name} spec: scaleTargetRef: deploymentName: {deployment-name} # must be in the same namespace as the ScaledObject containerName: {container-name} #Optional. Default: deployment.spec.template.spec.containers[0] pollingInterval: 30 # Optional. Default: 30 seconds cooldownPeriod: 300 # Optional. Default: 300 seconds minReplicaCount: 0 # Optional. Default: 0 maxReplicaCount: 100 # Optional. Default: 100 triggers: # {list of triggers to activate the deployment} "},"title":"ä½¿ç”¨kedaå®ŒæˆåŸºäºäº‹ä»¶çš„å¼¹æ€§ä¼¸ç¼©"},"/blog/202011/how-does-keda-work/":{"data":{"":" æ–‡ç« ä¸­æºç æ˜¯åŸºäºKEDA 2.0( 50bec80 )æ¥è¿›è¡Œåˆ†æ\nkeda 2.0 è¦æ±‚k8sé›†ç¾¤ç‰ˆæœ¬ \u003e=1.16\nKEDA åœ¨2020å¹´11æœˆ4å·releaseäº†2.0ç‰ˆæœ¬ï¼ŒåŒ…å«äº†ä¸€äº›æ–°çš„æ¯”è¾ƒæœ‰ç”¨çš„ç‰¹æ€§ï¼Œæ¯”å¦‚ScaledObject/ScaledJobä¸­æ”¯æŒå¤šè§¦å‘å™¨ã€æ”¯æŒHPAåŸå§‹çš„CPUã€Memory scalerç­‰ã€‚\nå…·ä½“çš„å®‰è£…ä½¿ç”¨è¯·å‚è€ƒä¸Šä¸€ç¯‡æ–‡ç« ä½¿ç”¨kedaå®ŒæˆåŸºäºäº‹ä»¶çš„å¼¹æ€§ä¼¸ç¼©ï¼Œè¿™ç¯‡æ–‡ç« ä¸»è¦æ·±å…¥çš„çœ‹ä¸‹KEDAå†…éƒ¨æœºåˆ¶ä»¥åŠæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚\næˆ‘ä»¬å…ˆæå‡ºå‡ ä¸ªé—®é¢˜ï¼Œå¸¦ç€é—®é¢˜å»çœ‹ä»£ç ï¼Œæ–¹ä¾¿æˆ‘ä»¬ç†è§£æ•´ä¸ªæœºåˆ¶ï¼š\nKEDAæ˜¯å¦‚ä½•è·å–åˆ°å¤šç§äº‹ä»¶çš„æŒ‡æ ‡ï¼Œä»¥åŠå¦‚ä½•åˆ¤æ–­æ‰©ç¼©å®¹çš„ï¼Ÿ KEDAæ˜¯å¦‚ä½•åšåˆ°å°†åº”ç”¨çš„å‰¯æœ¬æ•°ç¼©å®¹0ï¼Œä¾æ®æ˜¯ä»€ä¹ˆï¼Ÿ ","keda-metrics-apiserver#keda-metrics-apiserver":"keda-metrics-apiserverå®ç°äº†ExternalMetricsProvideræ¥å£ï¼š\ntype ExternalMetricsProvider interface { GetExternalMetric(namespace string, metricSelector labels.Selector, info ExternalMetricInfo) (*external_metrics.ExternalMetricValueList, error) ListAllExternalMetrics() []ExternalMetricInfo } GetExternalMetric ç”¨äºè¿”å›Scalerçš„æŒ‡æ ‡ï¼Œè°ƒç”¨scaler.GetMetricsæ–¹æ³• ListAllExternalMetrics è¿”å›æ‰€æœ‰æ”¯æŒçš„external metricsï¼Œä¾‹å¦‚prometheusï¼Œmysqlç­‰ å½“ä»£ç å†™å¥½ä¹‹åï¼Œå†é€šè¿‡apiserviceæ³¨å†Œåˆ°apiservierä¸Š(å½“ç„¶è¿˜æ¶‰åŠåˆ°é‰´æƒï¼Œè¿™é‡Œä¸å•°å—¦äº†)ï¼š\napiVersion: apiregistration.k8s.io/v1 kind: APIService metadata: labels: app.kubernetes.io/name: v1beta1.external.metrics.k8s.io app.kubernetes.io/version: latest app.kubernetes.io/part-of: keda-operator name: v1beta1.external.metrics.k8s.io spec: service: name: keda-metrics-apiserver namespace: keda group: external.metrics.k8s.io version: v1beta1 insecureSkipTLSVerify: true groupPriorityMinimum: 100 versionPriority: 100 ","keda-operator#keda-operator":"é¡¹ç›®ä¸­ç”¨åˆ°äº†kubebuilder SDKï¼Œç”¨æ¥å®Œæˆè¿™ä¸ªOperatorçš„ç¼–å†™ã€‚\nå¯¹äºk8sä¸­çš„è‡ªå®šä¹‰controllerä¸äº†è§£çš„å¯ä»¥çœ‹çœ‹è¿™è¾¹æ–‡ç« ï¼šå¦‚ä½•åœ¨Kubernetesä¸­åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰Controller?ã€‚\nkeda controllerçš„ä¸»è¦æµç¨‹ï¼Œç”»äº†å¹…å›¾ï¼š ç»„ä»¶å¯åŠ¨å…¥å£åœ¨äºmain.goæ–‡ä»¶ä¸­ï¼š\né€šè¿‡controller-runtimeç»„ä»¶å¯åŠ¨ä¸¤ä¸ªè‡ªå®šä¹‰controllerï¼šScaledObjectReconciler,ScaledJobReconciler:\nmgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options{ Scheme: scheme, MetricsBindAddress: metricsAddr, HealthProbeBindAddress: \":8081\", Port: 9443, LeaderElection: enableLeaderElection, LeaderElectionID: \"operator.keda.sh\", }) ... // Add readiness probe err = mgr.AddReadyzCheck(\"ready-ping\", healthz.Ping) ... // Add liveness probe err = mgr.AddHealthzCheck(\"health-ping\", healthz.Ping) .... //æ³¨å†Œ ScaledObject å¤„ç†çš„controller if err = (\u0026controllers.ScaledObjectReconciler{ Client: mgr.GetClient(), Log: ctrl.Log.WithName(\"controllers\").WithName(\"ScaledObject\"), Scheme: mgr.GetScheme(), }).SetupWithManager(mgr); err != nil { setupLog.Error(err, \"unable to create controller\", \"controller\", \"ScaledObject\") os.Exit(1) } ////æ³¨å†Œ ScaledJob å¤„ç†çš„controller if err = (\u0026controllers.ScaledJobReconciler{ Client: mgr.GetClient(), Log: ctrl.Log.WithName(\"controllers\").WithName(\"ScaledJob\"), Scheme: mgr.GetScheme(), }).SetupWithManager(mgr); err != nil { setupLog.Error(err, \"unable to create controller\", \"controller\", \"ScaledJob\") os.Exit(1) } if err := mgr.Start(ctrl.SetupSignalHandler()); err != nil { setupLog.Error(err, \"problem running manager\") os.Exit(1) } ScaledObjectReconciler å¤„ç† æˆ‘ä»¬ä¸»è¦å…³æ³¨Reconcileæ–¹æ³•ï¼Œå½“ScaledObjectå‘ç”Ÿå˜åŒ–æ—¶å°†ä¼šè§¦å‘è¯¥æ–¹æ³•ï¼š æ–¹æ³•å†…éƒ¨ä¸»è¦åŠŸèƒ½å®ç°ï¼š\n... // å¤„ç†åˆ é™¤ScaledObjectçš„æƒ…å†µ if scaledObject.GetDeletionTimestamp() != nil { //è¿›å…¥åƒåœ¾å›æ”¶ï¼ˆæ¯”å¦‚åœæ­¢goroutineä¸­Loopï¼Œæ¢å¤åŸæœ‰å‰¯æœ¬æ•°ï¼‰ return ctrl.Result{}, r.finalizeScaledObject(reqLogger, scaledObject) } // ç»™ScaledObjectèµ„æºåŠ ä¸ŠFinalizerï¼šfinalizer.keda.sh if err := r.ensureFinalizer(reqLogger, scaledObject); err != nil { return ctrl.Result{}, err } ... // çœŸæ­£å¤„ç†ScaledObjectèµ„æº msg, err := r.reconcileScaledObject(reqLogger, scaledObject) // è®¾ç½®Statuså­—æ®µè¯´æ˜ conditions := scaledObject.Status.Conditions.DeepCopy() if err != nil { reqLogger.Error(err, msg) conditions.SetReadyCondition(metav1.ConditionFalse, \"ScaledObjectCheckFailed\", msg) conditions.SetActiveCondition(metav1.ConditionUnknown, \"UnkownState\", \"ScaledObject check failed\") } else { reqLogger.V(1).Info(msg) conditions.SetReadyCondition(metav1.ConditionTrue, \"ScaledObjectReady\", msg) } kedacontrollerutil.SetStatusConditions(r.Client, reqLogger, scaledObject, \u0026conditions) return ctrl.Result{}, err r.reconcileScaledObjectæ–¹æ³•ï¼š\nè¿™ä¸ªæ–¹æ³•ä¸­ä¸»è¦ä¸¤ä¸ªåŠ¨ä½œï¼š\nensureHPAForScaledObjectExistsåˆ›å»ºHPAèµ„æº è¿›å…¥requestScaleLoopï¼ˆä¸æ–­çš„æ£€æµ‹scaler æ˜¯å¦activeï¼Œè¿›è¡Œå‰¯æœ¬æ•°çš„ä¿®æ”¹ï¼‰ ensureHPAForScaledObjectExists é€šè¿‡è·Ÿè¸ªè¿›å…¥åˆ°newHPAForScaledObjectæ–¹æ³•:\nscaledObjectMetricSpecs, err := r.getScaledObjectMetricSpecs(logger, scaledObject) ...çœç•¥ä»£ç  hpa := \u0026autoscalingv2beta2.HorizontalPodAutoscaler{ Spec: autoscalingv2beta2.HorizontalPodAutoscalerSpec{ MinReplicas: getHPAMinReplicas(scaledObject), MaxReplicas: getHPAMaxReplicas(scaledObject), Metrics: scaledObjectMetricSpecs, Behavior: behavior, ScaleTargetRef: autoscalingv2beta2.CrossVersionObjectReference{ Name: scaledObject.Spec.ScaleTargetRef.Name, Kind: gvkr.Kind, APIVersion: gvkr.GroupVersion().String(), }}, ObjectMeta: metav1.ObjectMeta{ Name: getHPAName(scaledObject), Namespace: scaledObject.Namespace, Labels: labels, }, TypeMeta: metav1.TypeMeta{ APIVersion: \"v2beta2\", }, } å¯ä»¥çœ‹åˆ°åˆ›å»ºScalerObjectå…¶å®æœ€ç»ˆä¹Ÿæ˜¯åˆ›å»ºäº†HPAï¼Œå…¶å®è¿˜æ˜¯é€šè¿‡HPAæœ¬èº«çš„ç‰¹æ€§æ¥æ§åˆ¶åº”ç”¨çš„å¼¹æ€§ä¼¸ç¼©ã€‚\nå…¶ä¸­getScaledObjectMetricSpecsæ–¹æ³•ä¸­å°±æ˜¯è·å–åˆ°triggersä¸­çš„metricsæŒ‡æ ‡ã€‚\nè¿™é‡Œæœ‰åŒºåˆ†ä¸€ä¸‹Externalçš„metricså’Œresource metricsï¼Œå› ä¸ºCPU/Memory scaleræ˜¯é€šè¿‡resource metrics æ¥è·å–çš„ã€‚\nrequestScaleLoop requestScaleLoopæ–¹æ³•ä¸­ç”¨æ¥å¾ªç¯check Scalerä¸­çš„IsActiveçŠ¶æ€å¹¶ä½œå‡ºå¯¹åº”çš„å¤„ç†ï¼Œæ¯”å¦‚ä¿®æ”¹å‰¯æœ¬æ•°ï¼Œç›´æ¥æ¥çœ‹æœ€ç»ˆçš„å¤„ç†å§ï¼š è¿™é‡Œæœ‰ä¸¤ç§æ¨¡å‹æ¥è§¦å‘RequestScaleï¼š\nPullæ¨¡å‹ï¼šå³ä¸»åŠ¨çš„è°ƒç”¨scaler ä¸­çš„IsActiveæ–¹æ³• Pushæ¨¡å‹ï¼šç”±Scaleræ¥è§¦å‘ï¼ŒPushScalerå¤šäº†ä¸€ä¸ªRunæ–¹æ³•ï¼Œé€šè¿‡channelä¼ å…¥activeçŠ¶æ€ã€‚ IsActiveæ˜¯ç”±Scalerå®ç°çš„ï¼Œæ¯”å¦‚å¯¹äºprometheusæ¥è¯´ï¼Œå¯èƒ½æŒ‡æ ‡ä¸º0åˆ™ä¸ºfalse\nè¿™ä¸ªå…·ä½“çš„scalerå®ç°åç»­å†è®²ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹RequestScaleåšäº†ä»€ä¹ˆäº‹ï¼š\n//å½“å‰å‰¯æœ¬æ•°ä¸º0ï¼Œå¹¶æ˜¯æ‰€æœ‰scalerå±äºactiveçŠ¶æ€ï¼Œåˆ™ä¿®æ”¹å‰¯æœ¬æ•°ä¸ºMinReplicaCount æˆ– 1 if currentScale.Spec.Replicas == 0 \u0026\u0026 isActive { e.scaleFromZero(ctx, logger, scaledObject, currentScale) } else if !isActive \u0026\u0026 currentScale.Spec.Replicas \u003e 0 \u0026\u0026 (scaledObject.Spec.MinReplicaCount == nil || *scaledObject.Spec.MinReplicaCount == 0) { // æ‰€æœ‰scaleréƒ½å¤„ç†not activeçŠ¶æ€ï¼Œå¹¶ä¸”å½“å‰å‰¯æœ¬æ•°å¤§äº0ï¼Œä¸”MinReplicaCountè®¾å®šä¸º0 // åˆ™ç¼©å®¹å‰¯æœ¬æ•°ä¸º0 e.scaleToZero(ctx, logger, scaledObject, currentScale) } else if !isActive \u0026\u0026 scaledObject.Spec.MinReplicaCount != nil \u0026\u0026 currentScale.Spec.Replicas \u003c *scaledObject.Spec.MinReplicaCount { // æ‰€æœ‰scaleréƒ½å¤„ç†not activeçŠ¶æ€ï¼Œå¹¶ä¸”å½“å‰å‰¯æœ¬æ•°å°äºMinReplicaCountï¼Œåˆ™ä¿®æ”¹ä¸ºMinReplicaCount currentScale.Spec.Replicas = *scaledObject.Spec.MinReplicaCount err := e.updateScaleOnScaleTarget(ctx, scaledObject, currentScale) .... } else if isActive { // å¤„ç†activeçŠ¶æ€ï¼Œå¹¶ä¸”å‰¯æœ¬æ•°å¤§äº0ï¼Œåˆ™æ›´æ–°LastActiveTime e.updateLastActiveTime(ctx, logger, scaledObject) } else { // ä¸å¤„ç† logger.V(1).Info(\"ScaleTarget no change\") } ScaledJobReconciler å¤„ç† ScaledJobReconcilerç›¸æ¯”ScalerObjectå°‘äº†åˆ›å»ºHPAçš„æ­¥éª¤ï¼Œå…¶ä½™çš„æ­¥éª¤ä¸»è¦æ˜¯é€šè¿‡checkScaledJobScalersï¼ŒRequestJobScaleä¸¤ä¸ªæ–¹æ³•æ¥åˆ¤æ–­Jobåˆ›å»ºï¼š\ncheckScaledJobScalers æ–¹æ³•ï¼Œç”¨äºè®¡ç®—isActiveï¼ŒmaxValueçš„å€¼ RequestJobScale æ–¹æ³•ï¼Œç”¨äºè´Ÿè´£åˆ›å»ºJobï¼Œé‡Œé¢è¿˜æ¶‰åŠåˆ°ä¸‰ç§æ‰©å®¹ç­–ç•¥ è¿™é‡Œç›´æ¥çœ‹ä»£ç å§ï¼Œä¸è´´ä»£ç äº†ã€‚\nå¦‚ä½•åœæ­¢Loop\nè¿™é‡Œæœ‰ä¸ªé—®é¢˜å°±æ˜¯startPushScalerså’ŒstartScaleLoopéƒ½æ˜¯åœ¨Goroutineä¸­å¤„ç†çš„ï¼Œæ‰€ä»¥å½“ScaleObject/ScalerJobè¢«åˆ é™¤çš„æ—¶å€™ï¼Œè¿™é‡Œéœ€è¦èƒ½å¤Ÿè¢«åˆ é™¤ï¼Œè¿™é‡Œå°±ç”¨åˆ°äº†context.Cancelæ–¹æ³•ï¼Œåœ¨Goroutineå¯åŠ¨çš„æ—¶å€™å°±å°†ï¼Œcontextä¿å­˜åœ¨scaleLoopContexts *sync.Mapä¸­(å¦‚æœå·²ç»æœ‰äº†ï¼Œå°±å…ˆCancelä¸€æ¬¡)ï¼Œåœ¨åˆ é™¤èµ„æºçš„æ—¶å€™ï¼Œè¿›è¡Œåˆ é™¤:\nfunc (h *scaleHandler) DeleteScalableObject(scalableObject interface{}) error { withTriggers, err := asDuckWithTriggers(scalableObject) if err != nil { h.logger.Error(err, \"error duck typing object into withTrigger\") return err } key := generateKey(withTriggers) result, ok := h.scaleLoopContexts.Load(key) if ok { cancel, ok := result.(context.CancelFunc) if ok { cancel() } h.scaleLoopContexts.Delete(key) } else { h.logger.V(1).Info(\"ScaleObject was not found in controller cache\", \"key\", key) } return nil } ps: è¿™é‡Œçš„å¦™å•Šï¼Œå­¦åˆ°äº†","ä»£ç ç»“æ„#ä»£ç ç»“æ„":"å¯¹ä¸€äº›ä¸»è¦ç›®å½•è¯´æ˜ï¼Œå…¶ä»–ä¸€äº›MDæ–‡ä»¶ä¸»è¦æ˜¯æ–‡å­—è¯´æ˜ï¼š\nâ”œâ”€â”€ BRANDING.md â”œâ”€â”€ BUILD.md //å¦‚ä½•åœ¨æœ¬åœ°ç¼–è¯‘å’Œè¿è¡Œ â”œâ”€â”€ CHANGELOG.md â”œâ”€â”€ CONTRIBUTING.md //å¦‚ä½•å‚ä¸è´¡çŒ®æ¬¡é¡¹ç›® â”œâ”€â”€ CREATE-NEW-SCALER.md â”œâ”€â”€ Dockerfile â”œâ”€â”€ Dockerfile.adapter â”œâ”€â”€ GOVERNANCE.md â”œâ”€â”€ LICENSE â”œâ”€â”€ MAINTAINERS.md â”œâ”€â”€ Makefile // æ„å»ºç¼–è¯‘ç›¸å…³å‘½ä»¤ â”œâ”€â”€ PROJECT â”œâ”€â”€ README.md â”œâ”€â”€ RELEASE-PROCESS.MD â”œâ”€â”€ adapter // keda-metrics-apiserver ç»„ä»¶å…¥å£ â”œâ”€â”€ api // è‡ªå®šä¹‰èµ„æºå®šä¹‰ï¼Œä¾‹å¦‚ScaledObjectçš„å®šä¹‰ â”œâ”€â”€ bin â”œâ”€â”€ config //ç»„ä»¶yamlèµ„æºï¼Œé€šè¿‡kustomizationå·¥å…·ç”Ÿæˆ â”œâ”€â”€ controllers //kubebuilder ä¸­controller ä»£ç æ§åˆ¶crdèµ„æº â”œâ”€â”€ go.mod â”œâ”€â”€ go.sum â”œâ”€â”€ hack â”œâ”€â”€ images â”œâ”€â”€ main.go //keda-operator controllerå…¥å£ â”œâ”€â”€ pkg //åŒ…å«ç»„ä»¶æ ¸å¿ƒä»£ç å®ç° â”œâ”€â”€ tests //e2eæµ‹è¯• â”œâ”€â”€ tools â”œâ”€â”€ vendor â””â”€â”€ version kedaä¸­ä¸»è¦æ˜¯ä¸¤ä¸ªç»„ä»¶keda-operatorä»¥åŠkeda-metrics-apiserverã€‚\nkeda-operator ï¼š è´Ÿè´£åˆ›å»º/æ›´æ–°HPAä»¥åŠé€šè¿‡Loopæ§åˆ¶åº”ç”¨å‰¯æœ¬æ•° keda-metrics-apiserverï¼šå®ç°external-metricsæ¥å£ï¼Œä»¥å¯¹æ¥ç»™HPAçš„externalç±»å‹çš„æŒ‡æ ‡æŸ¥è¯¢ï¼ˆæ¯”å¦‚å„ç§prometheusæŒ‡æ ‡ï¼Œmysqlç­‰ï¼‰ ","å®ç°ä¸€ä¸ªscaler#å®ç°ä¸€ä¸ªScaler":"å…¶å®æœ‰ä¸¤ç§Scalerï¼Œå³ä¸Šé¢å°†çš„ä¸€ä¸ªpullï¼Œä¸€ä¸ªpushçš„æ¨¡å‹ï¼ŒPushScalerå¤šäº†ä¸€ä¸ªRunæ–¹æ³•ï¼š\nå®ç°ä¸€ä¸ªScalerï¼Œä¸»è¦å®ç°ä»¥ä¸‹æ¥å£ï¼š\n// Scaler interface type Scaler interface { // è¿”å›external_metrics.ExternalMetricValueå¯¹è±¡ï¼Œå…¶å®å°±æ˜¯ç”¨äº keda-metrics-apiserverä¸­è·å–åˆ°scalerçš„æŒ‡æ ‡ GetMetrics(ctx context.Context, metricName string, metricSelector labels.Selector) ([]external_metrics.ExternalMetricValue, error) // è¿”å›v2beta2.MetricSpec ç»“æ„ï¼Œä¸»è¦ç”¨äºScalerObjectæè¿°åˆ›å»ºHPAçš„ç±»å‹å’ŒTargetæŒ‡æ ‡ç­‰ GetMetricSpecForScaling() []v2beta2.MetricSpec // è¿”å›è¯¥Scaleræ˜¯å¦Activeï¼Œå¯èƒ½ä¼šå½±å“Loopä¸­ç›´æ¥ä¿®æ”¹å‰¯æœ¬æ•° IsActive(ctx context.Context) (bool, error) //è°ƒç”¨å®Œä¸€æ¬¡ä¸Šé¢çš„æ–¹æ³•å°±ä¼šè°ƒç”¨ä¸€æ¬¡Close Close() error } // PushScaler interface type PushScaler interface { Scaler // é€šè¿‡scalerå®ç°Runæ–¹æ³•ï¼Œå¾€active channelä¸­ï¼Œå†™å…¥å€¼ï¼Œè€Œéä¸Šé¢çš„ç›´æ¥è°ƒç”¨IsActiveæ”¾å› Run(ctx context.Context, active chan\u003c- bool) } ","æ€»ç»“#æ€»ç»“":"å›è¿‡å¤´æ¥æˆ‘ä»¬è§£ç­”ä¸‹åœ¨å¼€å¤´ç•™ä¸‹çš„é—®é¢˜ï¼š\nKEDAæ˜¯å¦‚ä½•è·å–åˆ°å¤šç§äº‹ä»¶çš„æŒ‡æ ‡ï¼Œä»¥åŠå¦‚ä½•åˆ¤æ–­æ‰©ç¼©å®¹çš„ï¼Ÿ\nç­”ï¼škeda controlerä¸­ç”Ÿæˆäº†external ç±»å‹çš„hpaï¼Œå¹¶ä¸”å®ç°äº†external metrics çš„api\nKEDAæ˜¯å¦‚ä½•åšåˆ°å°†åº”ç”¨çš„å‰¯æœ¬æ•°ç¼©å®¹0ï¼Œä¾æ®æ˜¯ä»€ä¹ˆï¼Ÿ\nç­”ï¼š keda å†…éƒ¨æœ‰ä¸ªloopï¼Œä¸æ–­çš„check isActiveçŠ¶æ€ï¼Œä¼šä¸»åŠ¨çš„ä¿®æ”¹åº”ç”¨å‰¯æœ¬"},"title":"æºç å‰–æï¼šKEDAæ˜¯å¦‚ä½•å·¥ä½œçš„?"},"/blog/202110/enforce-limit-emptydir-size/":{"data":{"":"emptyDiræ”¯æŒä¸‰ç§ç±»å‹çš„ï¼Œé€šè¿‡è®¾ç½® medium å­—æ®µ ï¼š\næ–‡ä»¶ï¼šé»˜è®¤æƒ…å†µ Memoryï¼šå ç”¨å†…å­˜èµ„æº HugePages ","sizelimité»˜è®¤è¡Œä¸º#sizeLimité»˜è®¤è¡Œä¸º":"åŒæ—¶æ”¯æŒé€šè¿‡sizeLimitè®¾ç½®é™åˆ¶çš„å¤§å°ï¼Œä½†æ˜¯è¿™ä¸ªå¤§å°é»˜è®¤æƒ…å†µä¸‹(LocalStorageCapacityIsolation ç‰¹æ€§é»˜è®¤å¼€å¯)å¹¶ä¸æ˜¯å¼ºåˆ¶é™åˆ¶çš„ï¼Œè€Œæ˜¯ç”±eviction manager æ‰«æåˆ°è¶…è¿‡è®¾å®šçš„å¤§å°ä¹‹åï¼Œå†å°†podè¿›è¡Œé©±é€ï¼Œæ‰€ä»¥å­˜åœ¨ä¸€ç§æƒ…å†µå°±æ˜¯æ–‡ä»¶å…¶å®å·²ç»è¶…è¿‡äº†é™å®šçš„å¤§å°(å¯èƒ½å·²ç»å½±å“åˆ°äº†ç³»ç»Ÿä¸Šå…¶ä»–æœåŠ¡)ï¼Œè€Œé©±é€æ˜¯å®šæ—¶è§¦å‘çš„ï¼Œæœ‰ä¸€å®šçš„æ—¶é—´é—´éš”ã€‚\næˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿè¾¾åˆ°å¼ºåˆ¶çš„æ•ˆæœçš„è¯ï¼Œå°±éœ€è¦åšä¸€äº›hackã€‚","é€šè¿‡xfs-quota-é™åˆ¶#é€šè¿‡xfs quota é™åˆ¶":" kubelet root-dir ä½¿ç”¨xfsæ–‡ä»¶ç³»ç»Ÿï¼Œå¹¶é™„ä¸Š project quota å±æ€§ï¼Œä¾‹å¦‚ï¼š /dev/vdb /data xfs noatime,prjquota 1 2 nodeä¸Š xfs_quota å·¥å…·ä½¿ç”¨è¾ƒæ–°ç‰ˆæœ¬ï¼Œéœ€è¦æ”¯æŒ -f å‚æ•° å…¶å®åœ¨ k8s 1.15å¢åŠ äº†ä¸€ä¸ªç‰¹æ€§ LocalStorageCapacityIsolationFSQuotaMonitoring (PRï¼šhttps://github.com/kubernetes/kubernetes/pull/66928) ï¼Œè¿™ä¸ªç‰¹æ€§å°±æ˜¯é€šè¿‡XFS quotasæ¥ç»™kubeletç›®å½•è®¾ç½®é…é¢ï¼Œä½†æ˜¯è¿™é‡Œä»…ä»…åªæ˜¯ç›‘æ§æ¶ˆè€—ï¼Œå¹¶æ²¡æœ‰å¼ºåˆ¶é™åˆ¶ï¼Œå¯ä»¥çœ‹ä¸‹è¿™æ®µä»£ç ï¼š\nhttps://github.com/kubernetes/kubernetes/blob/master/pkg/volume/util/fsquota/quota_linux.go#L342-L343\nfunc AssignQuota(m mount.Interface, path string, poduid types.UID, bytes *resource.Quantity) error { ..... //è¿™é‡Œå¼ºåˆ¶è®¾ç½®æˆäº†-1 è¡¨ç¤ºæ— é™åˆ¶ if ibytes \u003e 0 { ibytes = -1 } if err = setQuotaOnDir(path, id, ibytes); err == nil { quotaPodMap[id] = poduid quotaSizeMap[id] = ibytes podQuotaMap[poduid] = id dirQuotaMap[path] = id dirPodMap[path] = poduid podDirCountMap[poduid]++ klog.V(4).Infof(\"Assigning quota ID %d (%d) to %s\", id, ibytes, path) return nil } removeProjectID(path, id) } return fmt.Errorf(\"assign quota FAILED %v\", err) } hack å°†å…¶ä¸­ ibytes \u003e 0 åˆ¤æ–­æ”¹ä¸º ibytes â‰¤ 0 å³ï¼ŒsetQuotaçš„æ—¶å€™å°†sizeLimitè®¾ç½®è¿›å»ï¼Œå°±å¯ä»¥è¾¾åˆ°å¼ºåˆ¶é™åˆ¶çš„æ•ˆæœã€‚\næµ‹è¯•ä¸€ä¸‹ï¼š\npod.yaml\napiVersion: v1 kind: Pod metadata: labels: app: nginx name: pod-test namespace: default spec: containers: - args: - \"100000\" command: - sleep image: nginx imagePullPolicy: IfNotPresent name: nginx volumeMounts: - name: data-test mountPath: /data/test/ volumes: - name: data-test emptyDir: sizeLimit: \"50Mi\" è¿›å…¥podä¸­å†™å…¥æ–‡ä»¶æµ‹è¯•ï¼š\nroot@pod-test:/data/test# dd if=/dev/zero of=./bigfile bs=1M count=2000 dd: error writing './bigfile': No space left on device 51+0 records in 50+0 records out 52428800 bytes (52 MB, 50 MiB) copied, 0.0573529 s, 914 MB/s è¾¾åˆ°æˆ‘ä»¬çš„é¢„æœŸã€‚\nå‚è€ƒ https://kubernetes.io/zh/docs/concepts/storage/volumes/#emptydir"},"title":"emptyDir é€šè¿‡xfs_quota å¼ºåˆ¶é™åˆ¶å¤§å°"},"/blog/202204/xfsquota-golang/":{"data":{"":"æºç åœ°å€ï¼šhttps://github.com/silenceper/xfsquota","ä¸»è¦åŠŸèƒ½#ä¸»è¦åŠŸèƒ½":" support set quota\nsupport get quota\nclean quota\nUsage\nxfsquota is a tool for managing XFS quotas Usage: xfsquota [command] Available Commands: clean clean quota information completion Generate the autocompletion script for the specified shell get Get quota information help Help about any command set Set quota information version get version Flags: -h, --help help for xfsquota Use \"xfsquota [command] --help\" for more information about a command. Set Quota set quota size 1MiB ,inodes 20 for path /data/test/quota\n\u003e xfsquota set /data/test/quota -s 1MiB -i 20 set quota success, path: /data/test/quota, size:1MiB, inodes:20 Get Quota get quota for path /data/test/quota\n\u003e xfsquota get /data/test/quota quota Size(bytes): 1048576 quota Inodes: 20 diskUsage Size(bytes): 0 diskUsage Inodes: 1 Clean Quota xfsquota clean /data/test/quota ","åŠ¨æœº#åŠ¨æœº":"åœ¨Linuxæœ‰ä¸€ä¸ªxfs_quotaï¼ˆåœ¨xfsprogså·¥å…·åŒ…ä¸‹ï¼‰å‘½ä»¤è¡Œå·¥å…·ï¼Œä¸ºä»€ä¹ˆè¿˜ç”¨golangå®ç°äº†ï¼Ÿ\nä¸»è¦æ˜¯è¦å› ä¸ºæœ€è¿‘è¦å®ç°ç£ç›˜quotaçš„æ§åˆ¶ï¼ŒåŒæ—¶è§‰å¾—çœ‹äº†dockerå†…çš„æºç ï¼Œéƒ½æ˜¯åˆ©ç”¨cgoçš„æ–¹å¼æ¥å®ç°çš„ï¼Œå¦‚æœç›´æ¥ç”¨xfs_quotaçš„æ–¹å¼æŸ¥çœ‹é…é¢ï¼Œæ— æ³•ç›´è§‚çš„çœ‹åˆ°æŸä¸€ä¸ªç›®å½•ä¸‹çš„é…é¢ï¼Œåªèƒ½åˆ—å‡ºæ‰€æœ‰ï¼Œå¹¶ä¸”æ²¡æœ‰å…·ä½“ç›®å½•ï¼Œç±»ä¼¼å¦‚ä¸‹ç»“æœï¼Œåœ¨è®¾ç½®äº†docker å®¹å™¨çš„quotaä¹‹åæŸ¥çœ‹æ¯ä¸ªå®¹å™¨çš„é…é¢ï¼Œåªæœ‰Project IDæ— æ³•åˆ¤åˆ«åˆ°å…·ä½“æŸä¸ªç›®å½•ï¼š\n# xfs_quota -x -c \"report\" /data Project quota on /data (/dev/vdb) Blocks Project ID Used Soft Hard Warn/Grace ---------- -------------------------------------------------- #0 7394256 0 0 00 [--------] #2 8 52428800 52428800 00 [--------] #3 8 52428800 52428800 00 [--------] #4 8 52428800 52428800 00 [--------] #5 2360 52428800 52428800 00 [--------] #6 8 52428800 52428800 00 [--------] #7 8 52428800 52428800 00 [--------] #8 8 52428800 52428800 00 [--------] #9 10568 52428800 52428800 00 [--------] #10 0 52428800 52428800 00 [--------] #11 0 52428800 52428800 00 [--------] #12 0 52428800 52428800 00 [--------] #13 0 52428800 52428800 00 [--------] #14 0 52428800 52428800 00 [--------] #15 0 52428800 52428800 00 [--------] #16 0 52428800 52428800 00 [--------] #17 0 52428800 52428800 00 [--------] #18 0 52428800 52428800 00 [--------] #19 0 52428800 52428800 00 [--------] æ‰€æœ‰ç”¨cgoçš„æ–¹å¼ï¼Œå¯ä»¥å®ç°å¯¹æŸä¸ªç›®å½•çš„quotaæŸ¥çœ‹ã€‚"},"title":"xfsquotaï¼šä¸€ä¸ªä¾¿æ·çš„ç®¡ç†xfsç£ç›˜é…é¢çš„å‘½ä»¤è¡Œå·¥å…·"},"/blog/2025-04-19-how-to-write-mcp-in-golang/":{"data":{"mcp-go-sdkæ¦‚è¿°#mcp-go SDKæ¦‚è¿°":"mcp-goæ˜¯ä¸€ä¸ªç”¨Golangå®ç°çš„MCPåè®®SDKï¼Œå®ƒæä¾›äº†æ„å»ºMCPæœåŠ¡å™¨æ‰€éœ€çš„æ ¸å¿ƒç»„ä»¶ï¼š\nå·¥å…·æ³¨å†Œå’Œç®¡ç† åè®®æ¶ˆæ¯å¤„ç† å¤šç§ä¼ è¾“æ–¹å¼æ”¯æŒï¼ˆstdioã€HTTP SSEç­‰ï¼‰ ä½¿ç”¨mcp-goï¼Œæˆ‘ä»¬å¯ä»¥å¿«é€Ÿæ„å»ºè‡ªå·±çš„MCPæœåŠ¡å™¨ï¼Œè€Œæ— éœ€å…³å¿ƒåº•å±‚åè®®ç»†èŠ‚ã€‚","mcp-k8s-ä¸€ä¸ªå®Œæ•´çš„å®è·µæ¡ˆä¾‹#mcp-k8s: ä¸€ä¸ªå®Œæ•´çš„å®è·µæ¡ˆä¾‹":"mcp-k8sæ˜¯ä¸€ä¸ªä½¿ç”¨mcp-goå¼€å‘çš„ã€ç”¨äºä¸Kubernetesé›†ç¾¤äº¤äº’çš„MCPæœåŠ¡å™¨ã€‚å®ƒæä¾›äº†ä»¥ä¸‹å·¥å…·ï¼š\nèµ„æºç±»å‹æŸ¥è¯¢å·¥å…·\nget_api_resources: è·å–é›†ç¾¤ä¸­æ‰€æœ‰æ”¯æŒçš„APIèµ„æºç±»å‹ èµ„æºæ“ä½œå·¥å…·\nget_resource: è·å–ç‰¹å®šèµ„æºçš„è¯¦ç»†ä¿¡æ¯ list_resources: åˆ—å‡ºæŸç§èµ„æºç±»å‹çš„æ‰€æœ‰å®ä¾‹ create_resource: åˆ›å»ºæ–°èµ„æºï¼ˆå¯é…ç½®ç¦ç”¨ï¼‰ update_resource: æ›´æ–°ç°æœ‰èµ„æºï¼ˆå¯é…ç½®ç¦ç”¨ï¼‰ delete_resource: åˆ é™¤èµ„æºï¼ˆå¯é…ç½®ç¦ç”¨ï¼‰ ä»¥ä¸‹æ˜¯mcp-k8sçš„æ ¸å¿ƒå®ç°ï¼š\nç›®å½•ç»“æ„ mcp-k8s/ â”œâ”€â”€ cmd/ â”‚ â””â”€â”€ server/ â”‚ â””â”€â”€ main.go # ä¸»ç¨‹åºå…¥å£ â”œâ”€â”€ internal/ â”‚ â”œâ”€â”€ config/ # é…ç½®å¤„ç† â”‚ â”œâ”€â”€ k8s/ # Kuberneteså®¢æˆ·ç«¯ â”‚ â””â”€â”€ tools/ # MCPå·¥å…·å®ç° â”œâ”€â”€ go.mod â””â”€â”€ go.sum ä¸»ç¨‹åºå…¥å£ // cmd/server/main.go func main() { // è§£æå‘½ä»¤è¡Œå‚æ•° kubeconfig := flag.String(\"kubeconfig\", \"\", \"Kubernetesé…ç½®æ–‡ä»¶è·¯å¾„\") enableCreate := flag.Bool(\"enable-create\", false, \"å¯ç”¨èµ„æºåˆ›å»ºæ“ä½œ\") enableUpdate := flag.Bool(\"enable-update\", false, \"å¯ç”¨èµ„æºæ›´æ–°æ“ä½œ\") enableDelete := flag.Bool(\"enable-delete\", false, \"å¯ç”¨èµ„æºåˆ é™¤æ“ä½œ\") transport := flag.String(\"transport\", \"stdio\", \"ä¼ è¾“æ–¹å¼: stdioæˆ–sse\") host := flag.String(\"host\", \"localhost\", \"SSEæ¨¡å¼çš„ä¸»æœºå\") port := flag.Int(\"port\", 8080, \"SSEæ¨¡å¼çš„ç«¯å£\") flag.Parse() // åˆå§‹åŒ–Kuberneteså®¢æˆ·ç«¯ if err := k8s.InitClient(*kubeconfig); err != nil { log.Fatalf(\"åˆå§‹åŒ–K8så®¢æˆ·ç«¯å¤±è´¥: %v\", err) } // åˆ›å»ºMCPæœåŠ¡å™¨ serverOpts := []server.Option{ server.WithLogger(log.Default()), } // é…ç½®ä¼ è¾“æ–¹å¼ if *transport == \"sse\" { serverOpts = append(serverOpts, server.WithTransport(server.TransportSSE), server.WithHost(*host), server.WithPort(*port), ) } else { serverOpts = append(serverOpts, server.WithTransport(server.TransportStdio)) } s, err := server.NewServer(serverOpts...) if err != nil { log.Fatalf(\"åˆ›å»ºæœåŠ¡å™¨å¤±è´¥: %v\", err) } // æ³¨å†Œå·¥å…· tools.RegisterTools(s, \u0026tools.Options{ EnableCreate: *enableCreate, EnableUpdate: *enableUpdate, EnableDelete: *enableDelete, }) // å¯åŠ¨æœåŠ¡å™¨ if err := s.Start(); err != nil { log.Fatalf(\"å¯åŠ¨æœåŠ¡å™¨å¤±è´¥: %v\", err) } } å·¥å…·å®ç°ç¤ºä¾‹ ä»¥get_resourceå·¥å…·ä¸ºä¾‹ï¼š\n// internal/tools/get_resource.go var GetResourceTool = server.Tool{ Name: \"get_resource\", Description: \"è·å–ç‰¹å®šèµ„æºçš„è¯¦ç»†ä¿¡æ¯\", Parameters: []server.Parameter{ { Name: \"apiVersion\", Description: \"èµ„æºçš„APIç‰ˆæœ¬\", Type: \"string\", Required: true, }, { Name: \"kind\", Description: \"èµ„æºç±»å‹\", Type: \"string\", Required: true, }, { Name: \"name\", Description: \"èµ„æºåç§°\", Type: \"string\", Required: true, }, { Name: \"namespace\", Description: \"èµ„æºæ‰€åœ¨çš„å‘½åç©ºé—´ï¼ˆå¦‚é€‚ç”¨ï¼‰\", Type: \"string\", Required: false, }, }, Handler: handleGetResource, } type GetResourceParams struct { APIVersion string `json:\"apiVersion\"` Kind string `json:\"kind\"` Name string `json:\"name\"` Namespace string `json:\"namespace\"` } func handleGetResource(ctx context.Context, rawParams json.RawMessage) (interface{}, error) { var params GetResourceParams if err := json.Unmarshal(rawParams, \u0026params); err != nil { return nil, fmt.Errorf(\"è§£æå‚æ•°å¤±è´¥: %w\", err) } // è·å–åŠ¨æ€å®¢æˆ·ç«¯ dynamicClient, err := k8s.GetDynamicClient() if err != nil { return nil, err } // è·å–èµ„æºGVR (Group Version Resource) gvr, namespaced, err := k8s.GetGVR(params.APIVersion, params.Kind) if err != nil { return nil, err } // ç¡®å®šæ˜¯å‘½åç©ºé—´çº§åˆ«è¿˜æ˜¯é›†ç¾¤çº§åˆ«çš„èµ„æº var object *unstructured.Unstructured if namespaced { // å¦‚æœæ˜¯å‘½åç©ºé—´çº§åˆ«èµ„æºä½†æœªæä¾›å‘½åç©ºé—´ï¼Œä½¿ç”¨é»˜è®¤å‘½åç©ºé—´ namespace := params.Namespace if namespace == \"\" { namespace = \"default\" } object, err = dynamicClient.Resource(gvr).Namespace(namespace).Get(ctx, params.Name, metav1.GetOptions{}) } else { object, err = dynamicClient.Resource(gvr).Get(ctx, params.Name, metav1.GetOptions{}) } if err != nil { return nil, fmt.Errorf(\"è·å–èµ„æºå¤±è´¥: %w\", err) } return object.Object, nil } æ³¨å†Œæ‰€æœ‰å·¥å…· // internal/tools/tools.go type Options struct { EnableCreate bool EnableUpdate bool EnableDelete bool } func RegisterTools(s *server.Server, opts *Options) { // æ³¨å†ŒæŸ¥è¯¢å·¥å…·ï¼ˆå§‹ç»ˆå¯ç”¨ï¼‰ s.RegisterTool(GetAPIResourcesTool) s.RegisterTool(GetResourceTool) s.RegisterTool(ListResourcesTool) // æ ¹æ®é…ç½®æ³¨å†Œå†™æ“ä½œå·¥å…· if opts.EnableCreate { s.RegisterTool(CreateResourceTool) } if opts.EnableUpdate { s.RegisterTool(UpdateResourceTool) } if opts.EnableDelete { s.RegisterTool(DeleteResourceTool) } } ","mcpåè®®ç®€ä»‹#MCPåè®®ç®€ä»‹":"MCP (Model Control Protocol)æ˜¯ä¸€ç§åè®®ï¼Œå…è®¸LLMä¸å¤–éƒ¨å·¥å…·è¿›è¡Œç»“æ„åŒ–äº¤äº’ã€‚é€šè¿‡MCPï¼ŒLLMå¯ä»¥ï¼š\nè·å–å¯ç”¨å·¥å…·åŠå…¶å‚æ•°åˆ—è¡¨ è°ƒç”¨è¿™äº›å·¥å…·æ‰§è¡Œæ“ä½œ è·å–æ“ä½œç»“æœå¹¶åŸºäºç»“æœç»§ç»­äº¤äº’ è¿™ä½¿å¾—LLMèƒ½å¤Ÿ\"æ§åˆ¶\"å¤–éƒ¨ç³»ç»Ÿï¼Œæ‰§è¡Œä»æŸ¥è¯¢æ•°æ®åº“åˆ°æ“ä½œKubernetesèµ„æºç­‰å„ç§ä»»åŠ¡ã€‚","mcpæœåŠ¡å¼€å‘çš„æœ€ä½³å®è·µ#MCPæœåŠ¡å¼€å‘çš„æœ€ä½³å®è·µ":"åŸºäºå¼€å‘mcp-k8sçš„ç»éªŒï¼Œæˆ‘æ€»ç»“äº†ä»¥ä¸‹å¼€å‘MCPæœåŠ¡çš„æœ€ä½³å®è·µï¼š\nå·¥å…·å‘½åä¸åˆ†ç±»ï¼šä½¿ç”¨æ¸…æ™°ã€ä¸€è‡´çš„å‘½åæ–¹å¼ï¼ŒæŒ‰åŠŸèƒ½åˆ†ç±»å·¥å…· å‚æ•°è®¾è®¡ï¼šå‚æ•°åç§°è¦ç›´è§‚ï¼Œæä¾›æ¸…æ™°çš„æè¿°ï¼Œæ˜ç¡®æ ‡è®°å¿…é€‰å‚æ•° å®‰å…¨æ§åˆ¶ï¼šå¯¹å†™æ“ä½œæä¾›ç‹¬ç«‹çš„å¼€å…³æ§åˆ¶ï¼Œé¿å…ä¸å¿…è¦çš„æƒé™é£é™© é”™è¯¯å¤„ç†ï¼šè¿”å›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼Œå¸®åŠ©LLMç†è§£å¤±è´¥åŸå›  çŠ¶æ€ç®¡ç†ï¼šMCPæœåŠ¡åº”ä¿æŒæ— çŠ¶æ€ï¼Œæ‰€æœ‰å¿…è¦ä¿¡æ¯é€šè¿‡å‚æ•°ä¼ é€’ æ–‡æ¡£å®Œå–„ï¼šè¯¦ç»†è®°å½•æ¯ä¸ªå·¥å…·çš„åŠŸèƒ½ã€å‚æ•°å’Œä½¿ç”¨ç¤ºä¾‹ ","ä½¿ç”¨æ–¹æ³•#ä½¿ç”¨æ–¹æ³•":"mcp-k8sæ”¯æŒä¸¤ç§é€šä¿¡æ¨¡å¼ï¼š\n1. Stdioæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ åœ¨stdioæ¨¡å¼ä¸‹ï¼Œmcp-k8sé€šè¿‡æ ‡å‡†è¾“å…¥/è¾“å‡ºæµä¸å®¢æˆ·ç«¯é€šä¿¡ã€‚\n// MCPå®¢æˆ·ç«¯é…ç½® { \"mcpServers\": { \"mcp-k8s\": { \"command\": \"/path/to/mcp-k8s\", \"args\": [ \"-kubeconfig\", \"/path/to/kubeconfig\", \"-enable-create\", \"-enable-delete\", \"-enable-update\" ] } } } 2. SSEæ¨¡å¼ åœ¨SSEæ¨¡å¼ä¸‹ï¼Œmcp-k8sæš´éœ²HTTPç«¯ç‚¹ä¾›MCPå®¢æˆ·ç«¯è¿æ¥ã€‚\n# è¿è¡ŒSSEæ¨¡å¼æœåŠ¡ ./bin/mcp-k8s -kubeconfig=/path/to/kubeconfig -transport=sse -port=8080 -host=localhost -enable-create -enable-delete -enable-update // MCPå®¢æˆ·ç«¯é…ç½® { \"mcpServers\": { \"mcp-k8s\": { \"url\": \"http://localhost:8080/sse\", \"args\": [] } } } ","å‚è€ƒèµ„æ–™#å‚è€ƒèµ„æ–™":" MCPåè®®è§„èŒƒ mcp-go SDK mcp-k8sé¡¹ç›® Kubernetes client-goæ–‡æ¡£ ","å¦‚ä½•ä½¿ç”¨golangå¼€å‘mcpæœåŠ¡å™¨ä»mcp-goåˆ°mcp-k8så®è·µ#å¦‚ä½•ä½¿ç”¨Golangå¼€å‘MCPæœåŠ¡å™¨ï¼šä»mcp-goåˆ°mcp-k8så®è·µ":"å¦‚ä½•ä½¿ç”¨Golangå¼€å‘MCPæœåŠ¡å™¨ï¼šä»mcp-goåˆ°mcp-k8så®è·µéšç€å¤§è¯­è¨€æ¨¡å‹(LLM)ä¸å¼€å‘å·¥å…·çš„æ·±åº¦èåˆï¼ŒModel Control Protocol (MCP)åè®®æ­£åœ¨æˆä¸ºAIä¸è½¯ä»¶å·¥å…·äº¤äº’çš„é‡è¦æ¡¥æ¢ã€‚MCPå…è®¸LLMä»¥ç»“æ„åŒ–çš„æ–¹å¼è°ƒç”¨å·¥å…·ï¼Œä½¿AIèƒ½å¤Ÿæ‰§è¡Œå…·ä½“çš„æ“ä½œè€Œä¸ä»…ä»…æ˜¯ç”Ÿæˆæ–‡æœ¬ã€‚\næœ¬æ–‡å°†è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨Golangå’Œmcp-goè¿™ä¸ªSDKæ¥å¼€å‘MCPæœåŠ¡å™¨ï¼Œå¹¶ä»¥æˆ‘çš„å¼€æºé¡¹ç›®mcp-k8sä¸ºå…·ä½“æ¡ˆä¾‹ï¼Œè®²è§£å¦‚ä½•æ„å»ºä¸€ä¸ªä¸Kubernetesé›†ç¾¤äº¤äº’çš„MCPæœåŠ¡å™¨ã€‚","å¼€å‘mcpæœåŠ¡å™¨çš„åŸºæœ¬æ­¥éª¤#å¼€å‘MCPæœåŠ¡å™¨çš„åŸºæœ¬æ­¥éª¤":"ä½¿ç”¨mcp-goå¼€å‘MCPæœåŠ¡å™¨é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š\nè®¾è®¡å¹¶å®šä¹‰å·¥å…·ï¼ˆToolsï¼‰ å®ç°å·¥å…·çš„å…·ä½“åŠŸèƒ½ åˆ›å»ºæœåŠ¡å™¨å¹¶æ³¨å†Œå·¥å…· é…ç½®å¹¶å¯åŠ¨æœåŠ¡å™¨ ä¸‹é¢æˆ‘ä»¬å°†è¯¦ç»†ä»‹ç»æ¯ä¸€æ­¥ã€‚\n1. è®¾è®¡å¹¶å®šä¹‰å·¥å…· åœ¨MCPä¸­ï¼Œå·¥å…·ï¼ˆToolï¼‰æ˜¯LLMå¯ä»¥è°ƒç”¨çš„åŠŸèƒ½å•å…ƒã€‚æ¯ä¸ªå·¥å…·éœ€è¦å®šä¹‰ï¼š\nåç§°ï¼ˆNameï¼‰ï¼šå·¥å…·çš„æ ‡è¯†ç¬¦ æè¿°ï¼ˆDescriptionï¼‰ï¼šå·¥å…·çš„åŠŸèƒ½æè¿° å‚æ•°ï¼ˆParametersï¼‰ï¼šå·¥å…·æ¥å—çš„å‚æ•°åŠå…¶ç±»å‹ å¤„ç†å‡½æ•°ï¼ˆHandlerï¼‰ï¼šå®ç°å·¥å…·åŠŸèƒ½çš„å‡½æ•° ä»¥mcp-k8sä¸­çš„get_api_resourceså·¥å…·ä¸ºä¾‹ï¼š\n// å®šä¹‰å·¥å…· var getAPIResourcesTool = server.Tool{ Name: \"get_api_resources\", Description: \"è·å–é›†ç¾¤ä¸­æ‰€æœ‰æ”¯æŒçš„APIèµ„æºç±»å‹\", Parameters: nil, // æ­¤å·¥å…·ä¸éœ€è¦å‚æ•° Handler: handleGetAPIResources, } // å®ç°å¤„ç†å‡½æ•° func handleGetAPIResources(ctx context.Context, rawParams json.RawMessage) (interface{}, error) { // å…·ä½“å®ç°... } 2. å®ç°å·¥å…·çš„å…·ä½“åŠŸèƒ½ å·¥å…·çš„Handlerå‡½æ•°å®ç°å…·ä½“çš„ä¸šåŠ¡é€»è¾‘ã€‚åœ¨mcp-k8sä¸­ï¼Œè¿™äº›å‡½æ•°ä¸»è¦ä¸Kubernetes APIäº¤äº’ã€‚\nä¾‹å¦‚ï¼Œè·å–APIèµ„æºåˆ—è¡¨çš„å®ç°ï¼š\nfunc handleGetAPIResources(ctx context.Context, rawParams json.RawMessage) (interface{}, error) { // åˆ›å»ºk8s discoveryå®¢æˆ·ç«¯ discoveryClient, err := discovery.NewDiscoveryClientForConfig(kubeConfig) if err != nil { return nil, fmt.Errorf(\"åˆ›å»ºdiscoveryå®¢æˆ·ç«¯å¤±è´¥: %w\", err) } // è·å–æœåŠ¡å™¨ä¸Šæ‰€æœ‰APIç»„ apiGroups, err := discoveryClient.ServerGroups() if err != nil { return nil, fmt.Errorf(\"è·å–APIç»„å¤±è´¥: %w\", err) } // å¤„ç†ç»“æœå¹¶è¿”å› result := processAPIGroups(apiGroups) return result, nil } 3. åˆ›å»ºæœåŠ¡å™¨å¹¶æ³¨å†Œå·¥å…· ä½¿ç”¨mcp-goåˆ›å»ºMCPæœåŠ¡å™¨å¹¶æ³¨å†Œå·¥å…·ï¼š\nfunc main() { // åˆ›å»ºMCPæœåŠ¡å™¨ s, err := server.NewServer( server.WithLogger(log.Default()), ) if err != nil { log.Fatalf(\"åˆ›å»ºæœåŠ¡å™¨å¤±è´¥: %v\", err) } // æ³¨å†Œå·¥å…· s.RegisterTool(getAPIResourcesTool) s.RegisterTool(getResourceTool) s.RegisterTool(listResourcesTool) // ... æ³¨å†Œæ›´å¤šå·¥å…· // å¯åŠ¨æœåŠ¡å™¨ if err := s.Start(); err != nil { log.Fatalf(\"å¯åŠ¨æœåŠ¡å™¨å¤±è´¥: %v\", err) } } 4. é…ç½®å¹¶å¯åŠ¨æœåŠ¡å™¨ mcp-goæ”¯æŒå¤šç§ä¼ è¾“æ–¹å¼ï¼Œæœ€å¸¸ç”¨çš„æ˜¯stdioï¼ˆæ ‡å‡†è¾“å…¥/è¾“å‡ºï¼‰å’ŒSSEï¼ˆServer-Sent Eventsï¼‰ã€‚\n// stdioæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ s, err := server.NewServer( server.WithLogger(log.Default()), server.WithTransport(server.TransportStdio), ) // SSEæ¨¡å¼ s, err := server.NewServer( server.WithLogger(log.Default()), server.WithTransport(server.TransportSSE), server.WithHost(\"localhost\"), server.WithPort(8080), ) ","ç»“è®º#ç»“è®º":"ä½¿ç”¨Golangå’Œmcp-go SDKå¼€å‘MCPæœåŠ¡å™¨æ˜¯ä¸€ä¸ªç›¸å¯¹ç®€å•çš„è¿‡ç¨‹ã€‚é€šè¿‡å®šä¹‰å’Œå®ç°å·¥å…·ï¼Œæˆ‘ä»¬å¯ä»¥è®©LLMå…·å¤‡ä¸å„ç§ç³»ç»Ÿäº¤äº’çš„èƒ½åŠ›ï¼Œä»è€Œå¤§å¤§æ‰©å±•å…¶åº”ç”¨åœºæ™¯ã€‚\nmcp-k8sé¡¹ç›®å±•ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„MCPæœåŠ¡å™¨ï¼Œè®©LLMèƒ½å¤ŸæŸ¥è¯¢ã€åˆ›å»ºã€æ›´æ–°å’Œåˆ é™¤Kubernetesèµ„æºï¼Œä¸ºé›†ç¾¤ç®¡ç†æä¾›äº†æ–°çš„äº¤äº’æ–¹å¼ã€‚\nå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ ç†è§£MCPåè®®å’Œä½¿ç”¨Golangå¼€å‘MCPæœåŠ¡å™¨çš„åŸºæœ¬æ–¹æ³•ã€‚æ›´å¤šè¯¦æƒ…ï¼Œæ¬¢è¿è®¿é—®mcp-k8sé¡¹ç›®ï¼Œæˆ–æŸ¥çœ‹mark3labs/mcp-goçš„æ–‡æ¡£ã€‚"},"title":"å¦‚ä½•ä½¿ç”¨Golangå¼€å‘MCPæœåŠ¡å™¨ï¼šä»mcp-goåˆ°mcp-k8så®è·µ"},"/blog/202504/mcp-k8s/":{"data":{"":"è¿˜è®°å¾—åˆšå¼€å§‹æ¥è§¦Kubernetesæ—¶çš„æ„Ÿå—å—ï¼Ÿå¤æ‚çš„æ¶æ„ã€ç¹å¤šçš„æ¦‚å¿µã€ä»¥åŠé‚£äº›éœ€è¦è®°å¿†çš„kubectlå‘½ä»¤â€¦ï¼Œç°åœ¨æœ‰äº†MCPå¯ä»¥è®©è¿™ç§äº¤äº’å˜å¾—æ›´åŠ ç®€å•ï¼Œå°è¯•é€šè¿‡AIè‡ªç„¶è¯­è¨€å¯¹è¯æ¥å®Œæˆå¯¹k8sé›†ç¾¤å„ç§èµ„æºçš„æ“ä½œä¹ƒè‡³äºå®šäºé›†ç¾¤çš„é—®é¢˜ã€‚","ä¸ªäººæƒ³æ³•#ä¸ªäººæƒ³æ³•":"è¿™é‡Œä¸å¾—ä¸å¤¸ä¸€ä¸‹Claudeæ¨¡å‹ï¼Œæ„Ÿè§‰å®ƒç‰¹åˆ«èƒ½å¤Ÿç†è§£mcpçš„toolï¼Œæ¯æ¬¡éƒ½èƒ½å¤Ÿç²¾å‡†çš„çŸ¥é“åº”è¯¥ä¼ å…¥é‚£ç§å‚æ•°ã€‚è™½ç„¶åœ¨toolå®šä¹‰ä¸­éƒ½æœ‰æè¿°ï¼Œä½†æ˜¯å¯¹æ¯”äº†å…¶ä»–çš„ä¸€äº›æ¨¡å‹å’Œmcp serverçš„äº¤äº’ï¼Œæ€»æ˜¯ä¸å°½äººæ„ï¼Œè¦ä¸å°±æ˜¯ç»™çš„å‚æ•°jsonæ ¼å¼é”™è¯¯ï¼Œè¦ä¸å°±æ˜¯ç†è§£é”™äº†å‚æ•°éœ€è¦ä¼ å…¥çš„ä¿¡æ¯ã€‚","å†™åœ¨æœ€å#å†™åœ¨æœ€å":"åšè¿™ä¸ªé¡¹ç›®çš„è¿‡ç¨‹ä¸­ï¼Œæœ€å¤§çš„æ„Ÿå—å°±æ˜¯ï¼šæŠ€æœ¯å‘å±•çœŸçš„å¤ªå¿«äº†ï¼ŒAIç»™æˆ‘ä»¬å¸¦æ¥äº†å¤ªå¤šå¯èƒ½æ€§ã€‚è™½ç„¶ç°åœ¨è¿˜æœ‰å¾ˆå¤šå¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼Œä½†æˆ‘ç›¸ä¿¡è¿™åªæ˜¯å¼€å§‹ã€‚æœŸå¾…çœ‹åˆ°æ›´å¤šäººåŠ å…¥è¿›æ¥ï¼Œä¸€èµ·æŠŠKubernetesè¿ç»´å˜å¾—æ›´ç®€å•ã€æ›´æ™ºèƒ½ã€‚\nå¦‚æœä½ ä¹Ÿå¯¹è¿™ä¸ªé¡¹ç›®æ„Ÿå…´è¶£ï¼Œæ¬¢è¿æ¥GitHubçœ‹çœ‹ï¼Œä¸€èµ·è®¨è®ºï¼Œä¸€èµ·æ”¹è¿›ã€‚","å®ƒæ˜¯æ€ä¹ˆå·¥ä½œçš„#å®ƒæ˜¯æ€ä¹ˆå·¥ä½œçš„ï¼Ÿ":"è¯´èµ·æ¥å¾ˆç®€å•ï¼ŒMCP-K8så°±åƒæ˜¯åœ¨Kuberneteså’ŒAIä¹‹é—´æ­äº†ä¸€åº§æ¡¥ã€‚é€šè¿‡MCPï¼ˆModel Control Protocolï¼‰åè®®ï¼Œå®ƒèƒ½è®©AIç†è§£ä½ çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå¹¶è½¬æ¢æˆå¯¹åº”çš„Kubernetesæ“ä½œã€‚\nè¦ç”¨èµ·æ¥ä¹Ÿè¶…çº§ç®€å•ï¼Œåªéœ€è¦åœ¨Cursorä¸­é…ç½®ä¸€ä¸‹ï¼š\n{ \"mcpServers\": { \"mcp-k8s\": { \"command\": \"/path/to/mcp-k8s\", \"args\": [ \"-kubeconfig\", \"/path/to/kubeconfig\", \"-enable-create\", \"-enable-delete\", \"-enable-update\" ] } } } ","å®æˆ˜ä½“éªŒ#å®æˆ˜ä½“éªŒ":"æ¥çœ‹çœ‹å®é™…ç”¨èµ·æ¥æ˜¯ä»€ä¹ˆæ„Ÿè§‰ï¼š\næŸ¥è¯¢é›†ç¾¤ä¿¡æ¯ æ¯”å¦‚æˆ‘æƒ³çœ‹çœ‹é›†ç¾¤èŠ‚ç‚¹æƒ…å†µï¼Œç›´æ¥é—®å°±å¥½äº†ï¼š\næŸ¥è¯¢k8sç‰ˆæœ¬ åˆ›å»ºèµ„æº éœ€è¦åˆ›å»ºæ–°èµ„æºï¼Ÿå°±åƒè·ŸåŒäº‹è¯´è¯ä¸€æ ·æè¿°ä½ çš„éœ€æ±‚ï¼š\nAIä¼šå¸®ä½ å¤„ç†å¥½æ‰€æœ‰ç»†èŠ‚ï¼š\næœ€ç»ˆæ•ˆæœå¦‚ä¸‹ï¼š\næ¨¡æ‹Ÿæ’éšœ è¿™ä¸ªæ˜¯æˆ‘æœ€å–œæ¬¢çš„éƒ¨åˆ†ã€‚æœ‰ä¸€æ¬¡æˆ‘æ•…æ„æäº†ä¸ªé—®é¢˜ï¼Œæœ‰ä¸€ä¸ªpodæ²¡æœ‰runningï¼š\nåªéœ€è¦ç®€å•è¯´æ˜æƒ…å†µï¼š\nmcp-demo å‘½åç©ºé—´ä¸‹æœ‰ä¸ªnginx çš„podæ²¡æœ‰runningï¼Œçœ‹ä¸‹æ˜¯ä»€ä¹ˆåŸå› å¹¶è§£å†³ åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­AIä¼šè‡ªåŠ¨è°ƒç”¨mcp å·¥å…·ï¼Œå¹¶å°†æŸ¥è¯¢åˆ°çš„ç»“æœæäº¤ç»™å¤§æ¨¡å‹è¿›è¡Œåˆ†æï¼Œåˆ†æä¹‹å è¿›è¡Œå®šä½å¹¶è§£å†³","æŠ€æœ¯ç‚¹åˆ†äº«#æŠ€æœ¯ç‚¹åˆ†äº«":"è¯´å®è¯ï¼Œèƒ½æŠŠè¿™ä¸ªé¡¹ç›®åšå‡ºæ¥ï¼Œä¸»è¦å½’åŠŸäºï¼š\nAIç†è§£èƒ½åŠ›: ç‰¹åˆ«æ˜¯Claudeè¿™æ ·çš„æ¨¡å‹ï¼Œå¯¹ä¸Šä¸‹æ–‡çš„ç†è§£çœŸçš„å¾ˆåˆ°ä½ å‚æ•°å¤„ç†: AIèƒ½è‡ªåŠ¨æ¨æ–­å‡ºæ­£ç¡®çš„å‚æ•°ï¼Œè¿™ä¸ªå¤ªçœå¿ƒäº† é—®é¢˜è¯Šæ–­: å®ƒä¸æ˜¯ç®€å•åœ°æ‰§è¡Œå‘½ä»¤ï¼Œè€Œæ˜¯çœŸçš„èƒ½ç†è§£é—®é¢˜å¹¶ç»™å‡ºè§£å†³æ–¹æ¡ˆ ","æœªæ¥ç•…æƒ³#æœªæ¥ç•…æƒ³":"è¯´å®è¯ï¼Œç°åœ¨çš„åŠŸèƒ½è¿˜åªæ˜¯å†°å±±ä¸€è§’ã€‚æˆ‘è§‰å¾—æœªæ¥å¯ä»¥åšçš„äº‹æƒ…è¿˜æœ‰å¾ˆå¤šï¼š\næ™ºèƒ½è¿ç»´: è®©AIä¸åªæ˜¯æ‰§è¡Œå‘½ä»¤ï¼Œè¿˜èƒ½ä¸»åŠ¨å‘ç°å’Œé¢„é˜²é—®é¢˜ è¿ç»´è‡ªåŠ¨åŒ–: é€šè¿‡ç®€å•çš„å¯¹è¯å®Œæˆå¤æ‚çš„è¿ç»´æµç¨‹ ç»éªŒæ²‰æ·€: æŠŠæ¯æ¬¡æ’éšœçš„ç»éªŒéƒ½å˜æˆAIçš„çŸ¥è¯†ï¼Œè¶Šç”¨è¶Šæ™ºèƒ½ "},"title":"MCP-K8sï¼šå½“AIæˆä¸ºæˆ‘çš„Kuberneteså°åŠ©æ‰‹"},"/kubernetes-book/csi/":{"data":{"":"å®¹å™¨å­˜å‚¨æ¥å£ï¼ˆCSIï¼‰æ˜¯ç”¨äºå°†ä»»æ„å—å’Œæ–‡ä»¶å­˜å‚¨ç³»ç»Ÿæš´éœ²ç»™è¯¸å¦‚Kubernetesä¹‹ç±»çš„å®¹å™¨ç¼–æ’ç³»ç»Ÿï¼ˆCOï¼‰ä¸Šçš„å®¹å™¨åŒ–å·¥ä½œè´Ÿè½½çš„æ ‡å‡†ã€‚ ä½¿ç”¨CSIçš„ç¬¬ä¸‰æ–¹å­˜å‚¨æä¾›å•†å¯ä»¥ç¼–å†™å’Œéƒ¨ç½²åœ¨Kubernetesä¸­å…¬å¼€æ–°å­˜å‚¨ç³»ç»Ÿçš„æ’ä»¶ï¼Œè€Œæ— éœ€æ¥è§¦æ ¸å¿ƒçš„Kubernetesä»£ç ã€‚\nå…·ä½“æ¥è¯´ï¼ŒKubernetesé’ˆå¯¹CSIè§„å®šäº†ä»¥ä¸‹å†…å®¹ï¼š\nKubeletåˆ°CSIé©±åŠ¨ç¨‹åºçš„é€šä¿¡ Kubeleté€šè¿‡UnixåŸŸå¥—æ¥å­—ç›´æ¥å‘CSIé©±åŠ¨ç¨‹åºå‘èµ·CSIè°ƒç”¨ï¼ˆä¾‹å¦‚NodeStageVolumeï¼ŒNodePublishVolumeç­‰ï¼‰ï¼Œä»¥æŒ‚è½½å’Œå¸è½½å·ã€‚ Kubeleté€šè¿‡kubeletæ’ä»¶æ³¨å†Œæœºåˆ¶å‘ç°CSIé©±åŠ¨ç¨‹åºï¼ˆä»¥åŠç”¨äºä¸CSIé©±åŠ¨ç¨‹åºè¿›è¡Œäº¤äº’çš„UnixåŸŸå¥—æ¥å­—ï¼‰ã€‚ å› æ­¤ï¼Œéƒ¨ç½²åœ¨Kubernetesä¸Šçš„æ‰€æœ‰CSIé©±åŠ¨ç¨‹åºå¿…é¡»åœ¨æ¯ä¸ªå—æ”¯æŒçš„èŠ‚ç‚¹ä¸Šä½¿ç”¨kubeletæ’ä»¶æ³¨å†Œæœºåˆ¶è¿›è¡Œæ³¨å†Œã€‚ Masteråˆ°CSIé©±åŠ¨ç¨‹åºçš„é€šä¿¡ Kubernetes masterç»„ä»¶ä¸ä¼šç›´æ¥ï¼ˆé€šè¿‡UnixåŸŸå¥—æ¥å­—æˆ–å…¶ä»–æ–¹å¼ï¼‰ä¸CSIé©±åŠ¨ç¨‹åºé€šä¿¡ã€‚ Kubernetes masterç»„ä»¶ä»…ä¸Kubernetes APIäº¤äº’ã€‚ å› æ­¤ï¼Œéœ€è¦ä¾èµ–äºKubernetes APIçš„æ“ä½œçš„CSIé©±åŠ¨ç¨‹åºï¼ˆä¾‹å¦‚å·åˆ›å»ºï¼Œå·attachï¼Œå·å¿«ç…§ç­‰ï¼‰å¿…é¡»ç›‘å¬Kubernetes APIå¹¶é’ˆå¯¹å®ƒè§¦å‘é€‚å½“çš„CSIæ“ä½œï¼ˆä¾‹å¦‚ä¸‹é¢çš„ä¸€ç³»åˆ—çš„externalç»„ä»¶ï¼‰ã€‚ ","å‚è€ƒ#å‚è€ƒ":" kubernetes-csi-introduction\nè¯¦è§£ Kubernetes Volume çš„å®ç°åŸç†\nCSIå­˜å‚¨æ¥å£è§£é‡Š","ç»„ä»¶#ç»„ä»¶":"\nCSIå®ç°ä¸­çš„ç»„ä»¶åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š\nç”±k8så®˜æ–¹ç»´æŠ¤çš„ä¸€ç³»åˆ—externalç»„ä»¶è´Ÿè´£æ³¨å†ŒCSI driver æˆ–ç›‘å¬k8så¯¹è±¡èµ„æºï¼Œä»è€Œå‘èµ·csi driverè°ƒç”¨ï¼Œæ¯”å¦‚ï¼ˆnode-driver-registrarï¼Œexternal-attacherï¼Œexternal-provisionerï¼Œexternal-resizerï¼Œexternal-snapshotterï¼Œlivenessprobeï¼‰ å„äº‘å‚å•†orå¼€å‘è€…è‡ªè¡Œå¼€å‘çš„ç»„ä»¶ï¼ˆéœ€è¦å®ç°CSI Identityï¼ŒCSI Controllerï¼ŒCSI Node æ¥å£ï¼‰ RPCæ¥å£(å¼€å‘å•†å®ç°) Identity Service\nservice Identity { //è¿”å›driverçš„ä¿¡æ¯ï¼Œæ¯”å¦‚åå­—ï¼Œç‰ˆæœ¬ rpc GetPluginInfo(GetPluginInfoRequest) returns (GetPluginInfoResponse) {} //è¿”å›driveræä¾›çš„èƒ½åŠ›ï¼Œæ¯”å¦‚æ˜¯å¦æä¾›Controller Service,volume è®¿é—®èƒ½èƒ½åŠ› rpc GetPluginCapabilities(GetPluginCapabilitiesRequest) returns (GetPluginCapabilitiesResponse) {} //æ¢é’ˆ rpc Probe (ProbeRequest) returns (ProbeResponse) {} } Controller service\nservice Controller { //åˆ›å»ºå· rpc CreateVolume (CreateVolumeRequest) returns (CreateVolumeResponse) {} //åˆ é™¤å· rpc DeleteVolume (DeleteVolumeRequest) returns (DeleteVolumeResponse) {} //attach å· rpc ControllerPublishVolume (ControllerPublishVolumeRequest) returns (ControllerPublishVolumeResponse) {} //unattachå· rpc ControllerUnpublishVolume (ControllerUnpublishVolumeRequest) returns (ControllerUnpublishVolumeResponse) {} //è¿”å›å­˜å‚¨å·çš„åŠŸèƒ½ç‚¹ï¼Œå¦‚æ˜¯å¦æ”¯æŒæŒ‚è½½åˆ°å¤šä¸ªèŠ‚ç‚¹ä¸Šï¼Œæ˜¯å¦æ”¯æŒå¤šä¸ªèŠ‚ç‚¹åŒæ—¶è¯»å†™ rpc ValidateVolumeCapabilities (ValidateVolumeCapabilitiesRequest) returns (ValidateVolumeCapabilitiesResponse) {} //åˆ—å‡ºæ‰€æœ‰å· rpc ListVolumes (ListVolumesRequest) returns (ListVolumesResponse) {} //è¿”å›å­˜å‚¨èµ„æºæ± çš„å¯ç”¨ç©ºé—´å¤§å° rpc GetCapacity (GetCapacityRequest) returns (GetCapacityResponse) {} //è¿”å›controlleræ’ä»¶çš„åŠŸèƒ½ç‚¹ï¼Œå¦‚æ˜¯å¦æ”¯æŒGetCapacityæ¥å£ï¼Œæ˜¯å¦æ”¯æŒsnapshotåŠŸèƒ½ç­‰ rpc ControllerGetCapabilities (ControllerGetCapabilitiesRequest) returns (ControllerGetCapabilitiesResponse) {} //åˆ›å»ºå¿«ç…§ rpc CreateSnapshot (CreateSnapshotRequest) returns (CreateSnapshotResponse) {} //åˆ é™¤å¿«ç…§ rpc DeleteSnapshot (DeleteSnapshotRequest) returns (DeleteSnapshotResponse) {} //åˆ—å‡ºå¿«ç…§ rpc ListSnapshots (ListSnapshotsRequest) returns (ListSnapshotsResponse) {} //æ‰©å®¹ rpc ControllerExpandVolume (ControllerExpandVolumeRequest) returns (ControllerExpandVolumeResponse) {} //è·å¾—å· rpc ControllerGetVolume (ControllerGetVolumeRequest) returns (ControllerGetVolumeResponse) { option (alpha_method) = true; } } Node Service\nservice Node { //å¦‚æœå­˜å‚¨å·æ²¡æœ‰æ ¼å¼åŒ–ï¼Œé¦–å…ˆè¦æ ¼å¼åŒ–ã€‚ç„¶åæŠŠå­˜å‚¨å·mountåˆ°ä¸€ä¸ªä¸´æ—¶çš„ç›®å½•ï¼ˆè¿™ä¸ªç›®å½•é€šå¸¸æ˜¯èŠ‚ç‚¹ä¸Šçš„ä¸€ä¸ªå…¨å±€ç›®å½•ï¼‰ã€‚å†é€šè¿‡NodePublishVolumeå°†å­˜å‚¨å·mountåˆ°podçš„ç›®å½•ä¸­ã€‚mountè¿‡ç¨‹åˆ†ä¸º2æ­¥ï¼ŒåŸå› æ˜¯ä¸ºäº†æ”¯æŒå¤šä¸ªpodå…±äº«åŒä¸€ä¸ªvolumeï¼ˆå¦‚NFSï¼‰ã€‚ rpc NodeStageVolume (NodeStageVolumeRequest) returns (NodeStageVolumeResponse) {} //NodeStageVolumeçš„é€†æ“ä½œï¼Œå°†ä¸€ä¸ªå­˜å‚¨å·ä»ä¸´æ—¶ç›®å½•umountæ‰ rpc NodeUnstageVolume (NodeUnstageVolumeRequest) returns (NodeUnstageVolumeResponse) {} //å°†å­˜å‚¨å·ä»ä¸´æ—¶ç›®å½•mountåˆ°ç›®æ ‡ç›®å½•ï¼ˆpodç›®å½•ï¼‰ rpc NodePublishVolume (NodePublishVolumeRequest) returns (NodePublishVolumeResponse) {} //å°†å­˜å‚¨å·ä»podç›®å½•umountæ‰ rpc NodeUnpublishVolume (NodeUnpublishVolumeRequest) returns (NodeUnpublishVolumeResponse) {} //è¿”å›å¯ç”¨äºè¯¥å·çš„å·å®¹é‡ç»Ÿè®¡ä¿¡æ¯ã€‚ rpc NodeGetVolumeStats (NodeGetVolumeStatsRequest) returns (NodeGetVolumeStatsResponse) {} //noeä¸Šæ‰§è¡Œå·æ‰©å®¹ rpc NodeExpandVolume(NodeExpandVolumeRequest) returns (NodeExpandVolumeResponse) {} //è¿”å›Nodeæ’ä»¶çš„åŠŸèƒ½ç‚¹ï¼Œå¦‚æ˜¯å¦æ”¯æŒstage/unstageåŠŸèƒ½ rpc NodeGetCapabilities (NodeGetCapabilitiesRequest) returns (NodeGetCapabilitiesResponse) {} //è¿”å›èŠ‚ç‚¹ä¿¡æ¯ rpc NodeGetInfo (NodeGetInfoRequest) returns (NodeGetInfoResponse) {} } ###External ç»„ä»¶ï¼ˆk8s Teamï¼‰\nè¿™éƒ¨åˆ†ç»„ä»¶æ˜¯ç”±k8så®˜æ–¹æä¾›çš„ï¼Œä½œä¸ºk8s apiè·Ÿcsi driverçš„æ¡¥æ¢ï¼š\nnode-driver-registrar\nCSI node-driver-registraræ˜¯ä¸€ä¸ªsidecarå®¹å™¨ï¼Œå¯ä»CSI driverè·å–é©±åŠ¨ç¨‹åºä¿¡æ¯ï¼ˆä½¿ç”¨NodeGetInfoï¼‰ï¼Œå¹¶ä½¿ç”¨kubeletæ’ä»¶æ³¨å†Œæœºåˆ¶åœ¨è¯¥èŠ‚ç‚¹ä¸Šçš„kubeletä¸­å¯¹å…¶è¿›è¡Œæ³¨å†Œã€‚\nexternal-attacher\nå®ƒæ˜¯ä¸€ä¸ªsidecarå®¹å™¨ï¼Œç”¨äºç›‘è§†Kubernetes VolumeAttachmentå¯¹è±¡å¹¶é’ˆå¯¹é©±åŠ¨ç¨‹åºç«¯ç‚¹è§¦å‘CSI ControllerPublishå’ŒControllerUnpublishæ“ä½œ\nexternal-provisioner\nå®ƒæ˜¯ä¸€ä¸ªsidecarå®¹å™¨ï¼Œç”¨äºç›‘è§†Kubernetes PersistentVolumeClaimå¯¹è±¡å¹¶é’ˆå¯¹é©±åŠ¨ç¨‹åºç«¯ç‚¹è§¦å‘CSI CreateVolumeå’ŒDeleteVolumeæ“ä½œã€‚ external-attacherè¿˜æ”¯æŒå¿«ç…§æ•°æ®æºã€‚ å¦‚æœå°†å¿«ç…§CRDèµ„æºæŒ‡å®šä¸ºPVCå¯¹è±¡ä¸Šçš„æ•°æ®æºï¼Œåˆ™æ­¤sidecarå®¹å™¨é€šè¿‡è·å–SnapshotContentå¯¹è±¡è·å–æœ‰å…³å¿«ç…§çš„ä¿¡æ¯ï¼Œå¹¶å¡«å……æ•°æ®æºå­—æ®µï¼Œè¯¥å­—æ®µå‘å­˜å‚¨ç³»ç»ŸæŒ‡ç¤ºåº”ä½¿ç”¨æŒ‡å®šçš„å¿«ç…§å¡«å……æ–°å· ã€‚\nexternal-resizer\nå®ƒæ˜¯ä¸€ä¸ªsidecarå®¹å™¨ï¼Œç”¨äºç›‘è§†Kubernetes APIæœåŠ¡å™¨ä¸Šçš„PersistentVolumeClaimå¯¹è±¡çš„æ”¹åŠ¨ï¼Œå¦‚æœç”¨æˆ·è¯·æ±‚åœ¨PersistentVolumeClaimå¯¹è±¡ä¸Šè¯·æ±‚æ›´å¤šå­˜å‚¨ï¼Œåˆ™ä¼šé’ˆå¯¹CSIç«¯ç‚¹è§¦å‘ControllerExpandVolumeæ“ä½œã€‚\nexternal-snapshotter\nå®ƒæ˜¯ä¸€ä¸ªsidecarå®¹å™¨ï¼Œç”¨äºç›‘è§†Kubernetes APIæœåŠ¡å™¨ä¸Šçš„VolumeSnapshotå’ŒVolumeSnapshotContent CRDå¯¹è±¡ã€‚åˆ›å»ºæ–°çš„VolumeSnapshotå¯¹è±¡ï¼ˆå¼•ç”¨ä¸æ­¤é©±åŠ¨ç¨‹åºå¯¹åº”çš„SnapshotClass CRDå¯¹è±¡ï¼‰å°†å¯¼è‡´sidecarå®¹å™¨æä¾›æ–°çš„å¿«ç…§ã€‚ è¯¥Sidecarä¾¦å¬æŒ‡ç¤ºæˆåŠŸåˆ›å»ºVolumeSnapshotçš„æœåŠ¡ï¼Œå¹¶ç«‹å³åˆ›å»ºVolumeSnapshotContentèµ„æºã€‚\nlivenessprobe\nå®ƒæ˜¯ä¸€ä¸ªsidecarå®¹å™¨ï¼Œç”¨äºç›‘è§†CSIé©±åŠ¨ç¨‹åºçš„è¿è¡ŒçŠ¶å†µï¼Œå¹¶é€šè¿‡Liveness Probeæœºåˆ¶å°†å…¶æŠ¥å‘Šç»™Kubernetesã€‚ è¿™ä½¿Kubernetesèƒ½å¤Ÿè‡ªåŠ¨æ£€æµ‹é©±åŠ¨ç¨‹åºé—®é¢˜å¹¶é‡æ–°å¯åŠ¨Podä»¥å°è¯•è§£å†³é—®é¢˜ã€‚"},"title":"CSI - å®¹å™¨å­˜å‚¨æ¥å£"},"/kubernetes-book/csi/csi-driver-host-path.html":{"data":{"":" é›†ç¾¤ v1.19.0","å‚è€ƒ#å‚è€ƒ":" https://github.com/kubernetes-csi/csi-driver-host-path/blob/master/docs/deploy-1.17-and-later.md https://arslan.io/2018/06/21/how-to-write-a-container-storage-interface-csi-plugin/ ","å®‰è£…#å®‰è£…":"https://github.com/kubernetes-csi/csi-driver-host-path/blob/master/docs/deploy-1.17-and-later.md\nVolumeSnapshot CRDs and snapshot controller installation # Apply VolumeSnapshot CRDs version:v2.0.1 kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/v2.0.1/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/v2.0.1/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/v2.0.1/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml # Create snapshot controller kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/v2.0.1/deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/v2.0.1/deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml Deployment ä»£ç åœ°å€ï¼šhttps://github.com/kubernetes-csi/csi-driver-host-path\nsh deploy/kubernetes-latest/deploy.sh å®‰è£…æˆåŠŸï¼š\nâœ ~ kubectl get pod|grep csi csi-hostpath-attacher-0 1/1 Running 0 76m csi-hostpath-provisioner-0 1/1 Running 0 76m csi-hostpath-resizer-0 1/1 Running 1 76m csi-hostpath-snapshotter-0 1/1 Running 0 76m csi-hostpath-socat-0 1/1 Running 0 76m csi-hostpathplugin-0 3/3 Running 1 76m my-csi-app 1/1 Running 0 46m å› ä¸ºéªŒè¯è€Œå·²ï¼Œè¿™é‡Œcsi-hostpathpluginç»„ä»¶åªéƒ¨ç½²äº†ä¸€ä¸ªï¼Œprovisionerå’Œattacherç»„ä»¶éƒ½ä¼šè°ƒç”¨è¿™ä¸ªç»„ä»¶ä¸Šæ¥\néªŒè¯ éƒ¨ç½²æµ‹è¯•åº”ç”¨ï¼ŒstorageClass,pvc,app:\n$ for i in ./examples/csi-storageclass.yaml ./examples/csi-pvc.yaml ./examples/csi-app.yaml; do kubectl apply -f $i; done storageclass.storage.k8s.io/csi-hostpath-sc created persistentvolumeclaim/csi-pvc created pod/my-csi-app created æŸ¥çœ‹pvå·²è‡ªåŠ¨åˆ›å»ºå‡ºæ¥äº†\n$ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e 1Gi RWO Delete Bound default/csi-pvc csi-hostpath-sc 50m $ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE csi-pvc Bound pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e 1Gi RWO csi-hostpath-sc 50m åœ¨èŠ‚ç‚¹ä¸Šçš„/var/lib/csi-hostpath-data/ç›®å½•ä¸‹å·²ç»æœ‰ç›®å½•åˆ›å»ºå‡ºæ¥äº†\nå¯ä»¥é€šè¿‡æŸ¥çœ‹å®¹å™¨csi-hostpathplugin-0 çš„logæ¥çœ‹æ•´ä¸ªpvçš„åˆ›å»ºä»¥åŠattachè¿‡ç¨‹ï¼š\nI1116 06:54:50.518286 1 server.go:117] GRPC call: /csi.v1.Controller/CreateVolume I1116 06:54:50.518384 1 server.go:118] GRPC request: {\"accessibility_requirements\":{\"preferred\":[{\"segments\":{\"topology.hostpath.csi/node\":\"minikube\"}}],\"requisite\":[{\"segments\":{\"topology.hostpath.csi/node\":\"minikube\"}}]},\"capacity_range\":{\"required_bytes\":1073741824},\"name\":\"pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e\",\"volume_capabilities\":[{\"AccessType\":{\"Mount\":{}},\"access_mode\":{\"mode\":1}}]} I1116 06:54:50.581056 1 controllerserver.go:165] created volume 9f684dbc-27d8-11eb-884a-0242ac120016 at path /csi-data-dir/9f684dbc-27d8-11eb-884a-0242ac120016 I1116 06:54:50.581129 1 server.go:123] GRPC response: {\"volume\":{\"accessible_topology\":[{\"segments\":{\"topology.hostpath.csi/node\":\"minikube\"}}],\"capacity_bytes\":1073741824,\"volume_id\":\"9f684dbc-27d8-11eb-884a-0242ac120016\"}} I1116 06:54:52.020457 1 server.go:117] GRPC call: /csi.v1.Identity/Probe I1116 06:54:56.879104 1 server.go:117] GRPC call: /csi.v1.Node/NodeGetCapabilities I1116 06:54:56.879169 1 server.go:118] GRPC request: {} I1116 06:54:56.879866 1 server.go:123] GRPC response: {\"capabilities\":[{\"Type\":{\"Rpc\":{\"type\":1}}},{\"Type\":{\"Rpc\":{\"type\":3}}}]} I1116 06:54:57.020014 1 server.go:117] GRPC call: /csi.v1.Node/NodeStageVolume I1116 06:54:57.020087 1 server.go:118] GRPC request: {\"staging_target_path\":\"/var/lib/kubelet/plugins/kubernetes.io/csi/pv/pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e/globalmount\",\"volume_capability\":{\"AccessType\":{\"Mount\":{}},\"access_mode\":{\"mode\":1}},\"volume_context\":{\"storage.kubernetes.io/csiProvisionerIdentity\":\"1605508257344-8081-hostpath.csi.k8s.io\"},\"volume_id\":\"9f684dbc-27d8-11eb-884a-0242ac120016\"} I1116 06:54:57.022399 1 server.go:123] GRPC response: {} I1116 06:54:57.041971 1 server.go:117] GRPC call: /csi.v1.Node/NodeGetCapabilities I1116 06:54:57.042036 1 server.go:118] GRPC request: {} I1116 06:54:57.043319 1 server.go:123] GRPC response: {\"capabilities\":[{\"Type\":{\"Rpc\":{\"type\":1}}},{\"Type\":{\"Rpc\":{\"type\":3}}}]} I1116 06:54:57.068101 1 server.go:117] GRPC call: /csi.v1.Node/NodePublishVolume I1116 06:54:57.068159 1 server.go:118] GRPC request: {\"staging_target_path\":\"/var/lib/kubelet/plugins/kubernetes.io/csi/pv/pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e/globalmount\",\"target_path\":\"/var/lib/kubelet/pods/9c5aa371-e5a7-4b67-8795-ec7013811363/volumes/kubernetes.io~csi/pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e/mount\",\"volume_capability\":{\"AccessType\":{\"Mount\":{}},\"access_mode\":{\"mode\":1}},\"volume_context\":{\"csi.storage.k8s.io/ephemeral\":\"false\",\"csi.storage.k8s.io/pod.name\":\"my-csi-app\",\"csi.storage.k8s.io/pod.namespace\":\"default\",\"csi.storage.k8s.io/pod.uid\":\"9c5aa371-e5a7-4b67-8795-ec7013811363\",\"csi.storage.k8s.io/serviceAccount.name\":\"default\",\"storage.kubernetes.io/csiProvisionerIdentity\":\"1605508257344-8081-hostpath.csi.k8s.io\"},\"volume_id\":\"9f684dbc-27d8-11eb-884a-0242ac120016\"} I1116 06:54:57.104975 1 mount_linux.go:164] Detected OS without systemd I1116 06:54:57.146159 1 nodeserver.go:166] target /var/lib/kubelet/pods/9c5aa371-e5a7-4b67-8795-ec7013811363/volumes/kubernetes.io~csi/pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e/mount fstype device readonly false volumeId 9f684dbc-27d8-11eb-884a-0242ac120016 attributes map[csi.storage.k8s.io/ephemeral:false csi.storage.k8s.io/pod.name:my-csi-app csi.storage.k8s.io/pod.namespace:default csi.storage.k8s.io/pod.uid:9c5aa371-e5a7-4b67-8795-ec7013811363 csi.storage.k8s.io/serviceAccount.name:default storage.kubernetes.io/csiProvisionerIdentity:1605508257344-8081-hostpath.csi.k8s.io] mountflags [] I1116 06:54:57.146375 1 mount_linux.go:164] Detected OS without systemd I1116 06:54:57.146449 1 mount_linux.go:146] Mounting cmd (mount) with arguments ([-o bind /csi-data-dir/9f684dbc-27d8-11eb-884a-0242ac120016 /var/lib/kubelet/pods/9c5aa371-e5a7-4b67-8795-ec7013811363/volumes/kubernetes.io~csi/pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e/mount]) I1116 06:54:57.448129 1 mount_linux.go:146] Mounting cmd (mount) with arguments ([-o bind,remount /csi-data-dir/9f684dbc-27d8-11eb-884a-0242ac120016 /var/lib/kubelet/pods/9c5aa371-e5a7-4b67-8795-ec7013811363/volumes/kubernetes.io~csi/pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e/mount]) å…ˆè¿›è¡Œcreate volumeï¼Œåœ¨è¿›è¡ŒNodePublishVolume\nNodeStageVolumeçš„ä½œç”¨ å¯¹äºå—å­˜å‚¨æ¥è¯´ï¼Œè®¾å¤‡åªèƒ½mountåˆ°ä¸€ä¸ªç›®å½•ä¸Šï¼Œæ‰€ä»¥NodeStageVolumeå°±æ˜¯å…ˆmountåˆ°ä¸€ä¸ªglobalmountç›®å½•(ç±»ä¼¼:/var/lib/kubelet/plugins/kubernetes.io/csi/pv/pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e/globalmount)ï¼Œç„¶åå†bindåˆ°podçš„ç›®å½•ï¼ˆ/var/lib/kubelet/pods/9c5aa371-e5a7-4b67-8795-ec7013811363/volumes/kubernetes.io~csi/pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e/mount/hello-worldï¼‰ï¼Œè¿™æ ·å°±å¯ä»¥pvæŒ‚è½½åœ¨å¤šä¸ªpodä¸­(NodePublishVolume)ã€‚åœ¨è¿™ä¸€æ­¥å¯ä»¥è¿›è¡Œæ ¼å¼åŒ–"},"title":"csi-driver-host-pathå®‰è£…"},"/kubernetes-book/csi/how-to-write-csi-driver.html":{"data":{"":" è¿™é‡Œä»¥csi-driver-host-pathä½œä¸ºä¾‹å­ï¼Œæ¥çœ‹çœ‹æ˜¯å¦‚ä½•å®ç°ä¸€ä¸ªcsiæ’ä»¶çš„ï¼Ÿ\nç›®æ ‡ï¼š\næ”¯æŒPVåŠ¨æ€åˆ›å»ºï¼Œå¹¶ä¸”èƒ½å¤ŸæŒ‚è½½åœ¨PODä¸­ volumeæ¥è‡ªæœ¬åœ°ç›®å½•ï¼Œä¸»è¦æ˜¯æ¨¡æ‹Ÿvolumeäº§ç”Ÿçš„è¿‡ç¨‹ï¼Œè¿™æ ·å°±ä¸ä¾èµ–äºæŸä¸ªç‰¹å®šçš„å­˜å‚¨æœåŠ¡ ","ä»£ç å®ç°#ä»£ç å®ç°":"æˆ‘ä»¬å¹¶ä¸ä¸€å®šè¦å®ç°æ‰€æœ‰çš„æ¥å£ï¼Œè¿™ä¸ªå¯ä»¥é€šè¿‡CSIä¸­Capabilitiesèƒ½åŠ›æ ‡è¯†å‡ºæ¥ï¼Œæˆ‘ä»¬ç»„ä»¶æä¾›çš„èƒ½åŠ›ï¼Œæ¯”å¦‚\nIdentityServerä¸­çš„GetPluginCapabilitiesæ–¹æ³•\nControllerServerä¸­çš„ControllerGetCapabilitiesæ–¹æ³•\nNodeServerä¸­çš„NodeGetCapabilities\nè¿™äº›æ–¹æ³•éƒ½æ˜¯åœ¨å‘Šè¯‰è°ƒç”¨æ–¹ï¼Œæˆ‘ä»¬çš„ç»„ä»¶å®ç°äº†å“ªäº›èƒ½åŠ›ï¼Œæœªå®ç°çš„æ–¹æ³•å°±ä¸ä¼šè°ƒç”¨äº†ã€‚\nIdentityServer IdentityServeråŒ…å«äº†ä¸‰ä¸ªæ¥å£ï¼Œè¿™é‡Œæˆ‘ä»¬ä¸»è¦å®ç°\n// IdentityServer is the server API for Identity service. type IdentityServer interface { GetPluginInfo(context.Context, *GetPluginInfoRequest) (*GetPluginInfoResponse, error) GetPluginCapabilities(context.Context, *GetPluginCapabilitiesRequest) (*GetPluginCapabilitiesResponse, error) Probe(context.Context, *ProbeRequest) (*ProbeResponse, error) } ä¸»è¦çœ‹ä¸‹GetPluginCapabilitiesè¿™ä¸ªæ–¹æ³•ï¼š\nidentityserver.go#L60:\nfunc (ids *identityServer) GetPluginCapabilities(ctx context.Context, req *csi.GetPluginCapabilitiesRequest) (*csi.GetPluginCapabilitiesResponse, error) { return \u0026csi.GetPluginCapabilitiesResponse{ Capabilities: []*csi.PluginCapability{ { Type: \u0026csi.PluginCapability_Service_{ Service: \u0026csi.PluginCapability_Service{ Type: csi.PluginCapability_Service_CONTROLLER_SERVICE, }, }, }, { Type: \u0026csi.PluginCapability_Service_{ Service: \u0026csi.PluginCapability_Service{ Type: csi.PluginCapability_Service_VOLUME_ACCESSIBILITY_CONSTRAINTS, }, }, }, }, }, nil } ä»¥ä¸Šå°±å‘Šè¯‰è°ƒç”¨è€…æˆ‘ä»¬æä¾›äº†ControllerServiceçš„èƒ½åŠ›ï¼Œä»¥åŠvolumeè®¿é—®é™åˆ¶çš„èƒ½åŠ›ï¼ˆCSI å¤„ç†æ—¶éœ€è¦æ ¹æ®é›†ç¾¤æ‹“æ‰‘ä½œè°ƒæ•´ï¼‰\nPSï¼šå…¶å®åœ¨k8sè¿˜æä¾›äº†ä¸€ä¸ªåŒ…ï¼šgithub.com/kubernetes-csi/drivers/pkg/csi-commonï¼Œé‡Œé¢æä¾›äº†æ¯”å¦‚DefaultIdentityServerï¼ŒDefaultControllerServer,DefaultNodeServerçš„structï¼Œåªè¦åœ¨æˆ‘ä»¬è‡ªå·±çš„XXXServer structä¸­ç»§æ‰¿è¿™äº›structï¼Œæˆ‘ä»¬çš„ä»£ç ä¸­å°±åªè¦åŒ…å«è‡ªå·±å®ç°çš„æ–¹æ³•å°±è¡Œäº†ï¼Œå¯ä»¥å‚è€ƒalibaba-cloud-csi-driverä¸­çš„ã€‚\n###ControllerServer\nControllerServeræˆ‘ä»¬ä¸»è¦å…³æ³¨CreateVolume,DeleteVolumeï¼Œå› ä¸ºæ˜¯hostpath volumeï¼Œæ‰€ä»¥å°±æ²¡æœ‰attachçš„è¿™ä¸ªè¿‡ç¨‹äº†ï¼Œæˆ‘ä»¬æ”¾åœ¨NodeServerä¸­å®ç°ï¼š\nCreateVolume controllerserver.go#L73\nfunc (cs *controllerServer) CreateVolume(ctx context.Context, req *csi.CreateVolumeRequest) (*csi.CreateVolumeResponse, error) { //æ ¡éªŒå‚æ•°æ˜¯å¦æœ‰CreateVolumeçš„èƒ½åŠ› if err := cs.validateControllerServiceRequest(csi.ControllerServiceCapability_RPC_CREATE_DELETE_VOLUME); err != nil { glog.V(3).Infof(\"invalid create volume req: %v\", req) return nil, err } //.....è¿™é‡Œçœç•¥çš„æ ¡éªŒå‚æ•°çš„è¿‡ç¨‹ //è¿™é‡Œæ ¹æ®volume nameåˆ¤æ–­æ˜¯å¦å·²ç»å­˜åœ¨äº†ï¼Œå­˜åœ¨äº†å°±è¿”å›å°±è¡Œäº† if exVol, err := getVolumeByName(req.GetName()); err == nil { // volumeå·²ç»å­˜åœ¨ï¼Œä½†æ˜¯å¤§å°ä¸ç¬¦åˆ if exVol.VolSize \u003c capacity { return nil, status.Errorf(codes.AlreadyExists, \"Volume with the same name: %s but with different size already exist\", req.GetName()) } //è¿™é‡Œåˆ¤æ–­æ˜¯å¦è®¾ç½®äº†pvc.dataSourceï¼Œå°±è¡¨ç¤ºæ˜¯ä¸€ä¸ªrestoreè¿‡ç¨‹ if req.GetVolumeContentSource() != nil { volumeSource := req.VolumeContentSource switch volumeSource.Type.(type) { //æ ¡éªŒï¼šä»å¿«ç…§ä¸­æ¢å¤ case *csi.VolumeContentSource_Snapshot: if volumeSource.GetSnapshot() != nil \u0026\u0026 exVol.ParentSnapID != \"\" \u0026\u0026 exVol.ParentSnapID != volumeSource.GetSnapshot().GetSnapshotId() { return nil, status.Error(codes.AlreadyExists, \"existing volume source snapshot id not matching\") } //æ ¡éªŒï¼šcloneè¿‡ç¨‹ case *csi.VolumeContentSource_Volume: if volumeSource.GetVolume() != nil \u0026\u0026 exVol.ParentVolID != volumeSource.GetVolume().GetVolumeId() { return nil, status.Error(codes.AlreadyExists, \"existing volume source volume id not matching\") } default: return nil, status.Errorf(codes.InvalidArgument, \"%v not a proper volume source\", volumeSource) } } // TODO (sbezverk) Do I need to make sure that volume still exists? return \u0026csi.CreateVolumeResponse{ Volume: \u0026csi.Volume{ VolumeId: exVol.VolID, CapacityBytes: int64(exVol.VolSize), VolumeContext: req.GetParameters(), ContentSource: req.GetVolumeContentSource(), }, }, nil } //åˆ›å»ºvolume volumeID := uuid.NewUUID().String() //åˆ›å»ºhostpathçš„volume vol, err := createHostpathVolume(volumeID, req.GetName(), capacity, requestedAccessType, false /* ephemeral */) if err != nil { return nil, status.Errorf(codes.Internal, \"failed to create volume %v: %v\", volumeID, err) } glog.V(4).Infof(\"created volume %s at path %s\", vol.VolID, vol.VolPath) //åˆ¤æ–­æ˜¯ä»å¿«ç…§æ¢å¤ï¼Œè¿˜æ˜¯clone if req.GetVolumeContentSource() != nil { path := getVolumePath(volumeID) volumeSource := req.VolumeContentSource switch volumeSource.Type.(type) { //ä»å¿«ç…§æ¢å¤ case *csi.VolumeContentSource_Snapshot: if snapshot := volumeSource.GetSnapshot(); snapshot != nil { err = loadFromSnapshot(capacity, snapshot.GetSnapshotId(), path, requestedAccessType) vol.ParentSnapID = snapshot.GetSnapshotId() } //clone case *csi.VolumeContentSource_Volume: if srcVolume := volumeSource.GetVolume(); srcVolume != nil { err = loadFromVolume(capacity, srcVolume.GetVolumeId(), path, requestedAccessType) vol.ParentVolID = srcVolume.GetVolumeId() } default: err = status.Errorf(codes.InvalidArgument, \"%v not a proper volume source\", volumeSource) } if err != nil { if delErr := deleteHostpathVolume(volumeID); delErr != nil { glog.V(2).Infof(\"deleting hostpath volume %v failed: %v\", volumeID, delErr) } return nil, err } glog.V(4).Infof(\"successfully populated volume %s\", vol.VolID) } //Topologyè¡¨ç¤ºvolumeèƒ½å¤Ÿéƒ¨ç½²åœ¨å“ªäº›èŠ‚ç‚¹ï¼ˆç”Ÿäº§æƒ…å†µå¯èƒ½å°±å¯¹åº”å¯ç”¨åŒºï¼‰ topologies := []*csi.Topology{\u0026csi.Topology{ Segments: map[string]string{TopologyKeyNode: cs.nodeID}, }} return \u0026csi.CreateVolumeResponse{ Volume: \u0026csi.Volume{ VolumeId: volumeID, CapacityBytes: req.GetCapacityRange().GetRequiredBytes(), VolumeContext: req.GetParameters(), ContentSource: req.GetVolumeContentSource(), AccessibleTopology: topologies, }, }, nil } createHostpathVolume\nå†æ¥çœ‹ä¸‹createHostpathVolumeæ–¹æ³•ï¼Œè¿™é‡ŒaccessTypeæœ‰ä¸¤ä¸ªé€‰é¡¹ï¼Œæ˜¯åˆ›å»ºæ–‡ä»¶ç³»ç»Ÿï¼Œè¿˜æ˜¯åˆ›å»ºå—ï¼Œå…¶å®å°±æ˜¯å¯¹åº”pvcä¸­volumeModeå­—æ®µï¼š\npkg/hostpath/hostpath.go#L208\n// createVolume create the directory for the hostpath volume. // It returns the volume path or err if one occurs. func createHostpathVolume(volID, name string, cap int64, volAccessType accessType, ephemeral bool) (*hostPathVolume, error) { path := getVolumePath(volID) switch volAccessType { case mountAccess: //åˆ›å»ºæ–‡ä»¶ err := os.MkdirAll(path, 0777) if err != nil { return nil, err } case blockAccess: //åˆ›å»ºå— executor := utilexec.New() size := fmt.Sprintf(\"%dM\", cap/mib) // Create a block file. _, err := os.Stat(path) if err != nil { if os.IsNotExist(err) { out, err := executor.Command(\"fallocate\", \"-l\", size, path).CombinedOutput() if err != nil { return nil, fmt.Errorf(\"failed to create block device: %v, %v\", err, string(out)) } } else { return nil, fmt.Errorf(\"failed to stat block device: %v, %v\", path, err) } } // é€šè¿‡losetupå°†æ–‡ä»¶è™šæ‹Ÿæˆå—è®¾å¤‡ // Associate block file with the loop device. volPathHandler := volumepathhandler.VolumePathHandler{} _, err = volPathHandler.AttachFileDevice(path) if err != nil { // Remove the block file because it'll no longer be used again. if err2 := os.Remove(path); err2 != nil { glog.Errorf(\"failed to cleanup block file %s: %v\", path, err2) } return nil, fmt.Errorf(\"failed to attach device %v: %v\", path, err) } default: return nil, fmt.Errorf(\"unsupported access type %v\", volAccessType) } hostpathVol := hostPathVolume{ VolID: volID, VolName: name, VolSize: cap, VolPath: path, VolAccessType: volAccessType, Ephemeral: ephemeral, } hostPathVolumes[volID] = hostpathVol return \u0026hostpathVol, nil } DeleteVolume åœ¨DeleteVolumeè¿™é‡Œä¸»è¦æ˜¯åˆ é™¤volumeï¼š\npkg/hostpath/controllerserver.go#L2\nfunc (cs *controllerServer) DeleteVolume(ctx context.Context, req *csi.DeleteVolumeRequest) (*csi.DeleteVolumeResponse, error) { // Check arguments if len(req.GetVolumeId()) == 0 { return nil, status.Error(codes.InvalidArgument, \"Volume ID missing in request\") } if err := cs.validateControllerServiceRequest(csi.ControllerServiceCapability_RPC_CREATE_DELETE_VOLUME); err != nil { glog.V(3).Infof(\"invalid delete volume req: %v\", req) return nil, err } volId := req.GetVolumeId() if err := deleteHostpathVolume(volId); err != nil { return nil, status.Errorf(codes.Internal, \"failed to delete volume %v: %v\", volId, err) } glog.V(4).Infof(\"volume %v successfully deleted\", volId) return \u0026csi.DeleteVolumeResponse{}, nil } åœ¨ControllerServiceä¸­è¿˜æœ‰ä¸€äº›å…¶ä»–æ¥å£ï¼Œæ¯”å¦‚CreateSnapshotåˆ›å»ºå¿«ç…§ï¼ŒDeleteSnapshotåˆ é™¤å¿«ç…§ï¼Œæ‰©å®¹ç­‰ï¼Œå…¶å®éƒ½ä¼šä¾èµ–äºæˆ‘ä»¬å­˜å‚¨æœåŠ¡ç«¯çš„æä¾›çš„èƒ½åŠ›ï¼Œè°ƒç”¨ç›¸åº”çš„æ¥å£å°±è¡Œäº†ã€‚\nNodeServer åœ¨nodeServerä¸­å°±æ˜¯å®ç°æˆ‘ä»¬çš„mount,unmountè¿‡ç¨‹äº†ï¼Œåˆ†åˆ«å¯¹åº”NodePublishVolumeå’ŒNodeUnpublishVolume\nNodePublishVolume pkg/hostpath/nodeserver.go#L5\nfunc (ns *nodeServer) NodePublishVolume(ctx context.Context, req *csi.NodePublishVolumeRequest) (*csi.NodePublishVolumeResponse, error) { //......è¿™é‡Œçœç•¥æ ¡éªŒå‚æ•°ä»£ç  vol, err := getVolumeByID(req.GetVolumeId()) if err != nil { return nil, status.Error(codes.NotFound, err.Error()) } //å¯¹åº”pvc.volumeBindå­—æ®µæ˜¯blockçš„æƒ…å†µ if req.GetVolumeCapability().GetBlock() != nil { if vol.VolAccessType != blockAccess { return nil, status.Error(codes.InvalidArgument, \"cannot publish a non-block volume as block volume\") } volPathHandler := volumepathhandler.VolumePathHandler{} //è·å–deviceåœ°å€ï¼ˆé€šè¿‡loopset -lå‘½ä»¤ï¼Œå› ä¸ºæ˜¯é€šè¿‡æ–‡ä»¶è™šæ‹Ÿå‡ºæ¥çš„å—è®¾å¤‡ï¼‰ // Get loop device from the volume path. loopDevice, err := volPathHandler.GetLoopDevice(vol.VolPath) if err != nil { return nil, status.Error(codes.Internal, fmt.Sprintf(\"failed to get the loop device: %v\", err)) } mounter := mount.New(\"\") // Check if the target path exists. Create if not present. _, err = os.Lstat(targetPath) if os.IsNotExist(err) { if err = mounter.MakeFile(targetPath); err != nil { return nil, status.Error(codes.Internal, fmt.Sprintf(\"failed to create target path: %s: %v\", targetPath, err)) } } if err != nil { return nil, status.Errorf(codes.Internal, \"failed to check if the target block file exists: %v\", err) } // Check if the target path is already mounted. Prevent remounting. notMount, err := mounter.IsNotMountPoint(targetPath) if err != nil { if !os.IsNotExist(err) { return nil, status.Errorf(codes.Internal, \"error checking path %s for mount: %s\", targetPath, err) } notMount = true } if !notMount { // It's already mounted. glog.V(5).Infof(\"Skipping bind-mounting subpath %s: already mounted\", targetPath) return \u0026csi.NodePublishVolumeResponse{}, nil } //è¿›è¡Œç»‘å®šæŒ‚è½½ï¼ˆmount bindï¼‰ï¼Œå°†å—è®¾å¤‡ç»‘å®šåˆ°å®¹å™¨ç›®å½•(targetpathç±»ä¼¼è¿™ç§ï¼š/var/lib/kubelet/pods/9c5aa371-e5a7-4b67-8795-ec7013811363/volumes/kubernetes.io~csi/pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e/mount) options := []string{\"bind\"} if err := mount.New(\"\").Mount(loopDevice, targetPath, \"\", options); err != nil { return nil, status.Error(codes.Internal, fmt.Sprintf(\"failed to mount block device: %s at %s: %v\", loopDevice, targetPath, err)) } //å¯¹åº”pvc.volumeBindå­—æ®µæ˜¯filesystemçš„æƒ…å†µ } else if req.GetVolumeCapability().GetMount() != nil { //....è¿™é‡Œçœç•¥ï¼Œå› ä¸ºè·Ÿä¸Šé¢ç±»ä¼¼ä¹Ÿæ˜¯mount bindè¿‡ç¨‹ } return \u0026csi.NodePublishVolumeResponse{}, nil } ####NodeUnpublishVolume\nNodeUnpublishVolumeè¿‡ç¨‹å°±æ˜¯unmountè¿‡ç¨‹ï¼Œå¦‚ä¸‹ï¼š\npkg/hostpath/nodeserver.go#L191\nfunc (ns *nodeServer) NodeUnpublishVolume(ctx context.Context, req *csi.NodeUnpublishVolumeRequest) (*csi.NodeUnpublishVolumeResponse, error) { // Check arguments if len(req.GetVolumeId()) == 0 { return nil, status.Error(codes.InvalidArgument, \"Volume ID missing in request\") } if len(req.GetTargetPath()) == 0 { return nil, status.Error(codes.InvalidArgument, \"Target path missing in request\") } targetPath := req.GetTargetPath() volumeID := req.GetVolumeId() vol, err := getVolumeByID(volumeID) if err != nil { return nil, status.Error(codes.NotFound, err.Error()) } // Unmount only if the target path is really a mount point. if notMnt, err := mount.IsNotMountPoint(mount.New(\"\"), targetPath); err != nil { if !os.IsNotExist(err) { return nil, status.Error(codes.Internal, err.Error()) } } else if !notMnt { // Unmounting the image or filesystem. err = mount.New(\"\").Unmount(targetPath) if err != nil { return nil, status.Error(codes.Internal, err.Error()) } } // Delete the mount point. // Does not return error for non-existent path, repeated calls OK for idempotency. if err = os.RemoveAll(targetPath); err != nil { return nil, status.Error(codes.Internal, err.Error()) } glog.V(4).Infof(\"hostpath: volume %s has been unpublished.\", targetPath) if vol.Ephemeral { glog.V(4).Infof(\"deleting volume %s\", volumeID) if err := deleteHostpathVolume(volumeID); err != nil \u0026\u0026 !os.IsNotExist(err) { return nil, status.Error(codes.Internal, fmt.Sprintf(\"failed to delete volume: %s\", err)) } } return \u0026csi.NodeUnpublishVolumeResponse{}, nil } å¯åŠ¨grpc server pkg/hostpath/hostpath.go#L164\nfunc (hp *hostPath) Run() { // Create GRPC servers hp.ids = NewIdentityServer(hp.name, hp.version) hp.ns = NewNodeServer(hp.nodeID, hp.ephemeral, hp.maxVolumesPerNode) hp.cs = NewControllerServer(hp.ephemeral, hp.nodeID) s := NewNonBlockingGRPCServer() s.Start(hp.endpoint, hp.ids, hp.cs, hp.ns) s.Wait() } ##æµ‹è¯•\næˆ‘ä»¬å¯ä»¥é€šè¿‡cscå·¥å…·æ¥è¿›è¡Œgrpcæ¥å£çš„æµ‹è¯•ï¼š\n$ GO111MODULE=off go get -u github.com/rexray/gocsi/csc Get plugin info\n$ csc identity plugin-info --endpoint tcp://127.0.0.1:10000 \"csi-hostpath\" \"0.1.0\" Create a volume\n$ csc controller new --endpoint tcp://127.0.0.1:10000 --cap 1,block CSIVolumeName CSIVolumeID Delete a volume\n$ csc controller del --endpoint tcp://127.0.0.1:10000 CSIVolumeID CSIVolumeID Validate volume capabilities\n$ csc controller validate-volume-capabilities --endpoint tcp://127.0.0.1:10000 --cap 1,block CSIVolumeID CSIVolumeID true NodePublish a volume\n$ csc node publish --endpoint tcp://127.0.0.1:10000 --cap 1,block --target-path /mnt/hostpath CSIVolumeID CSIVolumeID NodeUnpublish a volume\n$ csc node unpublish --endpoint tcp://127.0.0.1:10000 --target-path /mnt/hostpath CSIVolumeID CSIVolumeID Get Nodeinfo\n$ csc node get-info --endpoint tcp://127.0.0.1:10000 CSINode ","å‚è€ƒ#å‚è€ƒ":" https://medium.com/velotio-perspectives/kubernetes-csi-in-action-explained-with-features-and-use-cases-4f966b910774\nhttps://kubernetes-csi.github.io/docs/developing.html","æ€»ç»“#æ€»ç»“":"å›é¡¾ä¸‹æ•´ä¸ªç»„ä»¶æ˜¯æ€ä¹ˆåè°ƒå·¥ä½œçš„ï¼š\ncsi-provisionerç»„ä»¶ç›‘å¬pvcçš„åˆ›å»ºï¼Œä»è€Œé€šè¿‡ CSI socket åˆ›å»º CreateVolumeRequest è¯·æ±‚è‡³CreateVolumeæ–¹æ³• csi-provisioneråˆ›å»º PV ä»¥åŠæ›´æ–° PVCçŠ¶æ€è‡³ bound ï¼Œä»è€Œç”± controller-manageråˆ›å»ºVolumeAttachmentå¯¹è±¡ csi-attacher ç›‘å¬VolumeAttachments å¯¹è±¡åˆ›å»ºï¼Œä»è€Œè°ƒç”¨ ControllerPublishVolume æ–¹æ³•ã€‚ kubeletä¸€ç›´éƒ½åœ¨ç­‰å¾…volume attachï¼Œ ä»è€Œè°ƒç”¨ NodeStageVolume (ä¸»è¦åšæ ¼å¼åŒ–ä»¥åŠmountåˆ°èŠ‚ç‚¹ä¸Šä¸€ä¸ªå…¨å±€ç›®å½•) æ–¹æ³• - è¿™ä¸€æ­¥å¯é€‰ CSI Driveråœ¨ åœ¨ NodeStageVolume æ–¹æ³•ä¸­å°†volumemountåˆ° /var/lib/kubelet/plugins/kubernetes.io/csi/pv/\u003cpv-name\u003e/globalmountè¿™ä¸ªç›®å½•å¹¶è¿”å›ç»™kubelet - è¿™ä¸€æ­¥å¯é€‰ kubeletè°ƒç”¨NodePublishVolume (æŒ‚è½½åˆ°podç›®å½•é€šè¿‡mount bind) CSI Driverç›¸åº” NodePublishVolume è¯·æ±‚ï¼Œå°†volumeæŒ‚è½½åˆ°podç›®å½• /var/lib/kubelet/pods/\u003cpod-uuid\u003e/volumes/[kubernetes.io](http://kubernetes.io/)~csi/\u003cpvc-name\u003e/mount æœ€åï¼Œkubeletå¯åŠ¨å®¹å™¨ ","éƒ¨ç½²#éƒ¨ç½²":"ä»ä¸Šä¸€ç¯‡æ–‡ç« ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒCSIçœŸæ­£è¿è¡Œèµ·æ¥ï¼Œå…¶å®è¿˜éœ€è¦ä¸€äº›å®˜æ–¹æä¾›çš„ç»„ä»¶è¿›è¡Œé…åˆï¼Œæ¯”å¦‚node-driver-registrarï¼Œcsi-provisionï¼Œcsi-attacherï¼Œæˆ‘ä»¬å°†è¿™äº›containerä½œä¸ºæˆ‘ä»¬çš„sidecarå®¹å™¨ï¼Œé€šè¿‡volumeå…±äº«socketè¿æ¥ï¼Œæ–¹ä¾¿è°ƒç”¨ï¼Œéƒ¨ç½²åœ¨ä¸€èµ·ã€‚\næˆ‘ä»¬æŠŠæœåŠ¡åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š\ncontroller ï¼šä»¥Deploymentæˆ–è€…Statefulsetæ–¹å¼éƒ¨ç½²ï¼Œé€šè¿‡leader selectorï¼Œæ§åˆ¶åªæœ‰ä¸€ä¸ªåœ¨å·¥ä½œã€‚ nodeï¼šä»¥DaemonSetæ–¹å¼éƒ¨ç½²ï¼Œåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šéƒ½è°ƒåº¦ hostpathå› ä¸ºåªæœ‰åœ¨å•ä¸ªèŠ‚ç‚¹ä¸Šæµ‹è¯•ç”¨ï¼Œæ‰€ä»¥å®ƒçš„éƒ½ä½¿ç”¨äº†Statefulsetï¼Œå› ä¸ºåªæ˜¯æµ‹è¯•ã€‚\nåœ¨ç”Ÿäº§éƒ¨ç½²çš„è¯å¯ä»¥å‚è€ƒcsi-driver-nfs æœåŠ¡çš„éƒ¨ç½²ï¼Œè¿™ä¸ªæœåŠ¡æ¯”è¾ƒå®Œæ•´ã€‚\nhttps://github.com/kubernetes-csi/csi-driver-nfs/blob/master/deploy/csi-nfs-node.yaml https://github.com/kubernetes-csi/csi-driver-nfs/blob/master/deploy/csi-nfs-controller.yaml å½“ç„¶è¿˜æœ‰ä¸€äº›rbacï¼ŒCSIDriverçš„åˆ›å»ºï¼Œè¿™é‡Œå°±ä¸è´´å‡ºæ¥äº†ã€‚","é¢„å¤‡çŸ¥è¯†#é¢„å¤‡çŸ¥è¯†":"åœ¨ä¸Šä¸€ç¯‡æ–‡ç« ä¸­ï¼Œå·²ç»å¯¹CSIæ¦‚å¿µæœ‰ä¸ªäº†è§£ï¼Œå¹¶ä¸”æå‡ºäº†CSIç»„ä»¶éœ€è¦å®ç°çš„RPCæ¥å£ï¼Œé‚£æˆ‘ä»¬ä¸ºä»€ä¹ˆéœ€è¦è¿™äº›æ¥å£ï¼Œè¿™éœ€è¦ä»volumeè¦è¢«ä½¿ç”¨ç»è¿‡äº†ä»¥ä¸‹æµç¨‹ï¼š\nvolumeåˆ›å»º volume attachåˆ°èŠ‚ç‚¹(æ¯”å¦‚åƒEBSç¡¬ç›˜ï¼ŒNFSå¯èƒ½å°±ç›´æ¥ä¸‹ä¸€æ­¥mountäº†) volume è¢«mountåˆ°æŒ‡å®šç›®å½•(è¿™ä¸ªç›®å½•å…¶å®å°±è¢«æ˜ å°„åˆ°å®¹å™¨ä¸­ï¼Œç”±kubelet ä¸­çš„VolumeManager è°ƒç”¨) è€Œå½“å¸è½½æ—¶æ­£å¥½æ˜¯ç›¸åçš„ï¼šunmount,detach,delete volume\næ­£å¥½å¯¹åº”å¦‚ä¸‹å›¾ï¼š\nCreateVolume +------------+ DeleteVolume +-------------\u003e| CREATED +--------------+ | +---+----^---+ | | Controller | | Controller v +++ Publish | | Unpublish +++ |X| Volume | | Volume | | +-+ +---v----+---+ +-+ | NODE_READY | +---+----^---+ Node | | Node Stage | | Unstage Volume | | Volume +---v----+---+ | VOL_READY | +---+----^---+ Node | | Node Publish | | Unpublish Volume | | Volume +---v----+---+ | PUBLISHED | +------------+ è€Œä¸ºä»€ä¹ˆå¤šä¸ªNodeStageVolumeçš„è¿‡ç¨‹æ˜¯å› ä¸ºï¼š\nå¯¹äºå—å­˜å‚¨æ¥è¯´ï¼Œè®¾å¤‡åªèƒ½mountåˆ°ä¸€ä¸ªç›®å½•ä¸Šï¼Œæ‰€ä»¥NodeStageVolumeå°±æ˜¯å…ˆmountåˆ°ä¸€ä¸ªglobalmountç›®å½•(ç±»ä¼¼:/var/lib/kubelet/plugins/kubernetes.io/csi/pv/pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e/globalmount)ï¼Œç„¶åå†NodePublishVolumeè¿™ä¸€æ­¥ä¸­é€šè¿‡mount bindåˆ°podçš„ç›®å½•ï¼ˆ/var/lib/kubelet/pods/9c5aa371-e5a7-4b67-8795-ec7013811363/volumes/kubernetes.io~csi/pvc-bcfe33ed-e822-4b0e-954a-0f5c0468525e/mount/hello-worldï¼‰ï¼Œè¿™æ ·å°±å¯ä»¥å®ç°ä¸€ä¸ªpvæŒ‚è½½åœ¨å¤šä¸ªpodä¸­ä½¿ç”¨ã€‚"},"title":"å¦‚ä½•ç¼–å†™ä¸€ä¸ªCSIæ’ä»¶"},"/kubernetes-book/keda/":{"data":{"":"kedaæ˜¯ä¸€ä¸ªåŸºäºäº‹ä»¶é©±åŠ¨çš„ä¼¸ç¼©æ§åˆ¶å™¨ï¼Œå¯ä»¥å®ç°åº”ç”¨ç¼©å®¹è‡³0ï¼Œä»¥åŠä»0å¼€å§‹æ‰©å®¹ã€‚ç›®å‰å·²æ”¯æŒåƒCPU/Memroyã€Mysqlã€Prometheusã€Redisç­‰20å¤šç§äº‹ä»¶æ¥æº(Scaler)ã€‚\nç›®å‰ä¹Ÿæ˜¯CNCFä¸‹çš„sandboxé¡¹ç›®ï¼Œæœ€åˆä¸»è¦ç”±å¾®è½¯ã€redhatä»¥åŠç¤¾åŒºçš„äººå‘˜å‚ä¸è´¡çŒ®ã€‚\nç½‘ç«™ï¼šhttps://keda.sh/\né¡¹ç›®åœ°å€ï¼šhttps://github.com/kedacore/keda\nKEDAæ¶æ„å›¾ï¼š","åŸºæœ¬ä½¿ç”¨#åŸºæœ¬ä½¿ç”¨":"KEDA 2.0æœ‰ä¸¤ç§æ§åˆ¶å¯¹è±¡ï¼š\nScaledObjectï¼šåŸºäºHPAï¼Œæ ¹æ®äº‹ä»¶è§¦å‘å™¨(scaler)æ§åˆ¶åº”ç”¨(Deployments, StatefulSets \u0026 Custom Resources)çš„æ°´å¹³ä¼¸ç¼© ScaledJobï¼šæ ¹æ®äº‹ä»¶è§¦å‘å™¨(scaler)ï¼Œç”Ÿæˆjob ###ScaledObjecté…ç½®\napiVersion: keda.sh/v1alpha1 kind: ScaledObject metadata: name: {scaled-object-name} spec: scaleTargetRef: apiVersion: {api-version-of-target-resource} # Optional. Default: apps/v1 kind: {kind-of-target-resource} # Optional. Default: Deployment name: {name-of-target-resource} # Mandatory. Must be in the same namespace as the ScaledObject envSourceContainerName: {container-name} # Optional. Default: .spec.template.spec.containers[0] pollingInterval: 30 # Optional. Default: 30 seconds cooldownPeriod: 300 # Optional. Default: 300 seconds minReplicaCount: 0 # Optional. Default: 0 maxReplicaCount: 100 # Optional. Default: 100 advanced: # Optional. Section to specify advanced options restoreToOriginalReplicaCount: true/false # Optional. Default: false horizontalPodAutoscalerConfig: # Optional. Section to specify HPA related options behavior: # Optional. Use to modify HPA's scaling behavior scaleDown: stabilizationWindowSeconds: 300 policies: - type: Percent value: 100 periodSeconds: 15 triggers: # {list of triggers to activate scaling of the target resource} å‚æ•°è¯´æ˜ï¼š\nå‚æ•° è¯´æ˜ spec.scaleTargetRef éœ€è¦æ‰©ç¼©å®¹çš„å¯¹è±¡èµ„æº spec.pollingInterval å®šæ—¶è·å–è§¦å‘å™¨(scaler)çš„æ—¶é—´é—´éš”ï¼Œé»˜è®¤30s spec.cooldownPeriod ä¸Šæ¬¡activeè‡³ç¼©å®¹ä¸º0éœ€è¦ç­‰å¾…çš„æ—¶é—´ï¼Œé»˜è®¤300s spec.minReplicaCount åº”ç”¨æœ€å°å€¼ spec.maxReplicaCount åº”ç”¨æœ€å¤§å€¼ spec.advanced.restoreToOriginalReplicaCount åœ¨åˆ é™¤ScaledObjectä¹‹åï¼Œæ˜¯å¦å°†åº”ç”¨æ¢å¤ä¸ºåŸå€¼ spec.advanced.horizontalPodAutoscalerConfig HPAå¯¹åº”çš„é…ç½® spec.triggers scaleråˆ—è¡¨ æ¯”å¦‚åˆ›å»ºä¸€ä¸ªåŸºäºprometheusçš„æ•°æ®ä½œä¸ºè§¦å‘å™¨çš„scaledobject:\napiVersion: keda.k8s.io/v1alpha1 kind: ScaledObject metadata: name: prometheus-scaledobject namespace: default spec: scaleTargetRef: deploymentName: http-demo minReplicaCount: 1 triggers: - type: prometheus metadata: serverAddress: http://192.168.99.100:31046/ metricName: gin_requests_total threshold: '2' query: sum(rate(gin_requests_total{app=\"http-demo\",code=\"200\"}[2m])) ###Scaling Jobsé…ç½®\napiVersion: keda.sh/v1alpha1 kind: ScaledJob metadata: name: {scaled-job-name} spec: jobTargetRef: parallelism: 1 # [max number of desired pods](https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/#controlling-parallelism) completions: 1 # [desired number of successfully finished pods](https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/#controlling-parallelism) activeDeadlineSeconds: 600 # Specifies the duration in seconds relative to the startTime that the job may be active before the system tries to terminate it; value must be positive integer backoffLimit: 6 # Specifies the number of retries before marking this job failed. Defaults to 6 template: # describes the [job template](https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/) pollingInterval: 30 # Optional. Default: 30 seconds successfulJobsHistoryLimit: 5 # Optional. Default: 100. How many completed jobs should be kept. failedJobsHistoryLimit: 5 # Optional. Default: 100. How many failed jobs should be kept. envSourceContainerName: {container-name} # Optional. Default: .spec.JobTargetRef.template.spec.containers[0] maxReplicaCount: 100 # Optional. Default: 100 scalingStrategy: strategy: \"custom\" # Optional. Default: default. Which Scaling Strategy to use. customScalingQueueLengthDeduction: 1 # Optional. A parameter to optimize custom ScalingStrategy. customScalingRunningJobPercentage: \"0.5\" # Optional. A parameter to optimize custom ScalingStrategy. triggers: # {list of triggers to create jobs} å‚æ•°è¯´æ˜ï¼š\nå‚æ•° è¯´æ˜ spec.jobTargetRef ç”Ÿæˆçš„jobæè¿°ï¼Œ spec.pollingInterval å®šæ—¶è·å–è§¦å‘å™¨(scaler)çš„æ—¶é—´é—´éš”ï¼Œé»˜è®¤30s spec.successfulJobsHistoryLimit ä¿ç•™çš„success jobæ•°é‡ spec.failedJobsHistoryLimit ä¿ç•™çš„failed jobæ•°é‡ spec.envSourceContainerName é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®å‚æ•°çš„å®¹å™¨ï¼Œæ¯”å¦‚â€œiam.amazonaws.com/roleâ€å‚æ•°ç­‰ spec.maxReplicaCount jobæœ€å¤§æ•°é‡ spec.scalingStrategy jobç”Ÿæˆç­–ç•¥ spec.triggers scaleråˆ—è¡¨ Scaler æ”¯æŒçš„Scalerå¦‚ä¸‹ï¼š\nActiveMQ Artemis Apache Kafka AWS CloudWatch AWS Kinesis Stream AWS SQS Queue Azure Blob Storage Azure Event Hubs Azure Log Analytics Azure Monitor Azure Service Bus Azure Storage Queue CPU Cron External External Push Google Cloud Platformâ€ Pub/Sub Huawei Cloudeye IBM MQ Liiklus Topic Memory Metrics API MySQL NATS Streaming PostgreSQL Prometheus RabbitMQ Queue Redis Lists Redis Streams ","å®‰è£…#å®‰è£…":" keda 2.0ç‰ˆæœ¬è¦æ±‚k8sé›†ç¾¤\u003e=1.16\næ”¯æŒå¤šç§å®‰è£…æ–¹å¼ï¼Œå¯ä»¥æŸ¥çœ‹kedaæ–‡æ¡£ï¼šhttps://keda.sh/docs/2.0/deploy/#install\næ¯”å¦‚ç›´æ¥ä½¿ç”¨YAMLæ–‡ä»¶å®‰è£…ï¼š\nkubectl apply -f https://github.com/kedacore/keda/releases/download/v2.0.0/keda-2.0.0.yaml æ£€æŸ¥é›†ç¾¤ä¸­æ˜¯å¦å®‰è£…æˆåŠŸï¼š\n\u003ekubectl get pod -n keda NAME READY STATUS RESTARTS AGE keda-metrics-apiserver-5bffbfbd68-s7pbn 1/1 Running 10 2d23h keda-operator-7b98595dc7-tvgr9 1/1 Running 19 2d23h "},"title":"KEDA - ä¸€ä¸ªåŸºäºäº‹ä»¶é©±åŠ¨çš„ä¼¸ç¼©æ§åˆ¶å™¨"},"/kubernetes-book/keda/source.html":{"data":{"":" æ–‡ç« ä¸­æºç æ˜¯åŸºäºKEDA 2.0( 50bec80)æ¥è¿›è¡Œåˆ†æ\nkeda 2.0 è¦æ±‚k8sé›†ç¾¤ç‰ˆæœ¬ \u003e=1.16\nKEDA åœ¨2020å¹´11æœˆ4å·releaseäº†2.0ç‰ˆæœ¬ï¼ŒåŒ…å«äº†ä¸€äº›æ–°çš„æ¯”è¾ƒæœ‰ç”¨çš„ç‰¹æ€§ï¼Œæ¯”å¦‚ScaledObject/ScaledJobä¸­æ”¯æŒå¤šè§¦å‘å™¨ã€æ”¯æŒHPAåŸå§‹çš„CPUã€Memory scalerç­‰ã€‚\nå…·ä½“çš„å®‰è£…ä½¿ç”¨è¯·å‚è€ƒä¸Šä¸€ç¯‡æ–‡ç« ä½¿ç”¨kedaå®ŒæˆåŸºäºäº‹ä»¶çš„å¼¹æ€§ä¼¸ç¼©ï¼Œè¿™ç¯‡æ–‡ç« ä¸»è¦æ·±å…¥çš„çœ‹ä¸‹KEDAå†…éƒ¨æœºåˆ¶ä»¥åŠæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚\næˆ‘ä»¬å…ˆæå‡ºå‡ ä¸ªé—®é¢˜ï¼Œå¸¦ç€é—®é¢˜å»çœ‹ä»£ç ï¼Œæ–¹ä¾¿æˆ‘ä»¬ç†è§£æ•´ä¸ªæœºåˆ¶ï¼š\nKEDAæ˜¯å¦‚ä½•è·å–åˆ°å¤šç§äº‹ä»¶çš„æŒ‡æ ‡ï¼Œä»¥åŠå¦‚ä½•åˆ¤æ–­æ‰©ç¼©å®¹çš„ï¼Ÿ KEDAæ˜¯å¦‚ä½•åšåˆ°å°†åº”ç”¨çš„å‰¯æœ¬æ•°ç¼©å®¹0ï¼Œä¾æ®æ˜¯ä»€ä¹ˆï¼Ÿ ","keda-metrics-apiserver#keda-metrics-apiserver":"keda-metrics-apiserverå®ç°äº†ExternalMetricsProvideræ¥å£ï¼š\ntype ExternalMetricsProvider interface { GetExternalMetric(namespace string, metricSelector labels.Selector, info ExternalMetricInfo) (*external_metrics.ExternalMetricValueList, error) ListAllExternalMetrics() []ExternalMetricInfo } GetExternalMetric ç”¨äºè¿”å›Scalerçš„æŒ‡æ ‡ï¼Œè°ƒç”¨scaler.GetMetricsæ–¹æ³• ListAllExternalMetrics è¿”å›æ‰€æœ‰æ”¯æŒçš„external metricsï¼Œä¾‹å¦‚prometheusï¼Œmysqlç­‰ å½“ä»£ç å†™å¥½ä¹‹åï¼Œå†é€šè¿‡apiserviceæ³¨å†Œåˆ°apiservierä¸Š(å½“ç„¶è¿˜æ¶‰åŠåˆ°é‰´æƒï¼Œè¿™é‡Œä¸å•°å—¦äº†)ï¼š\napiVersion: apiregistration.k8s.io/v1 kind: APIService metadata: labels: app.kubernetes.io/name: v1beta1.external.metrics.k8s.io app.kubernetes.io/version: latest app.kubernetes.io/part-of: keda-operator name: v1beta1.external.metrics.k8s.io spec: service: name: keda-metrics-apiserver namespace: keda group: external.metrics.k8s.io version: v1beta1 insecureSkipTLSVerify: true groupPriorityMinimum: 100 versionPriority: 100 ","keda-operator#keda-operator":"é¡¹ç›®ä¸­ç”¨åˆ°äº†kubebuilder SDKï¼Œç”¨æ¥å®Œæˆè¿™ä¸ªOperatorçš„ç¼–å†™ã€‚\nå¯¹äºk8sä¸­çš„è‡ªå®šä¹‰controllerä¸äº†è§£çš„å¯ä»¥çœ‹çœ‹è¿™è¾¹æ–‡ç« ï¼šå¦‚ä½•åœ¨Kubernetesä¸­åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰Controller?ã€‚\nkeda controllerçš„ä¸»è¦æµç¨‹ï¼Œç”»äº†å¹…å›¾ï¼š ç»„ä»¶å¯åŠ¨å…¥å£åœ¨äºmain.goæ–‡ä»¶ä¸­ï¼š\né€šè¿‡controller-runtimeç»„ä»¶å¯åŠ¨ä¸¤ä¸ªè‡ªå®šä¹‰controllerï¼šScaledObjectReconciler,ScaledJobReconciler:\nmgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options{ Scheme: scheme, MetricsBindAddress: metricsAddr, HealthProbeBindAddress: \":8081\", Port: 9443, LeaderElection: enableLeaderElection, LeaderElectionID: \"operator.keda.sh\", }) ... // Add readiness probe err = mgr.AddReadyzCheck(\"ready-ping\", healthz.Ping) ... // Add liveness probe err = mgr.AddHealthzCheck(\"health-ping\", healthz.Ping) .... //æ³¨å†Œ ScaledObject å¤„ç†çš„controller if err = (\u0026controllers.ScaledObjectReconciler{ Client: mgr.GetClient(), Log: ctrl.Log.WithName(\"controllers\").WithName(\"ScaledObject\"), Scheme: mgr.GetScheme(), }).SetupWithManager(mgr); err != nil { setupLog.Error(err, \"unable to create controller\", \"controller\", \"ScaledObject\") os.Exit(1) } ////æ³¨å†Œ ScaledJob å¤„ç†çš„controller if err = (\u0026controllers.ScaledJobReconciler{ Client: mgr.GetClient(), Log: ctrl.Log.WithName(\"controllers\").WithName(\"ScaledJob\"), Scheme: mgr.GetScheme(), }).SetupWithManager(mgr); err != nil { setupLog.Error(err, \"unable to create controller\", \"controller\", \"ScaledJob\") os.Exit(1) } if err := mgr.Start(ctrl.SetupSignalHandler()); err != nil { setupLog.Error(err, \"problem running manager\") os.Exit(1) } ScaledObjectReconciler å¤„ç† æˆ‘ä»¬ä¸»è¦å…³æ³¨Reconcileæ–¹æ³•ï¼Œå½“ScaledObjectå‘ç”Ÿå˜åŒ–æ—¶å°†ä¼šè§¦å‘è¯¥æ–¹æ³•ï¼š æ–¹æ³•å†…éƒ¨ä¸»è¦åŠŸèƒ½å®ç°ï¼š\n... // å¤„ç†åˆ é™¤ScaledObjectçš„æƒ…å†µ if scaledObject.GetDeletionTimestamp() != nil { //è¿›å…¥åƒåœ¾å›æ”¶ï¼ˆæ¯”å¦‚åœæ­¢goroutineä¸­Loopï¼Œæ¢å¤åŸæœ‰å‰¯æœ¬æ•°ï¼‰ return ctrl.Result{}, r.finalizeScaledObject(reqLogger, scaledObject) } // ç»™ScaledObjectèµ„æºåŠ ä¸ŠFinalizerï¼šfinalizer.keda.sh if err := r.ensureFinalizer(reqLogger, scaledObject); err != nil { return ctrl.Result{}, err } ... // çœŸæ­£å¤„ç†ScaledObjectèµ„æº msg, err := r.reconcileScaledObject(reqLogger, scaledObject) // è®¾ç½®Statuså­—æ®µè¯´æ˜ conditions := scaledObject.Status.Conditions.DeepCopy() if err != nil { reqLogger.Error(err, msg) conditions.SetReadyCondition(metav1.ConditionFalse, \"ScaledObjectCheckFailed\", msg) conditions.SetActiveCondition(metav1.ConditionUnknown, \"UnkownState\", \"ScaledObject check failed\") } else { reqLogger.V(1).Info(msg) conditions.SetReadyCondition(metav1.ConditionTrue, \"ScaledObjectReady\", msg) } kedacontrollerutil.SetStatusConditions(r.Client, reqLogger, scaledObject, \u0026conditions) return ctrl.Result{}, err r.reconcileScaledObjectæ–¹æ³•ï¼š\nè¿™ä¸ªæ–¹æ³•ä¸­ä¸»è¦ä¸¤ä¸ªåŠ¨ä½œï¼š\nensureHPAForScaledObjectExistsåˆ›å»ºHPAèµ„æº è¿›å…¥requestScaleLoopï¼ˆä¸æ–­çš„æ£€æµ‹scaler æ˜¯å¦activeï¼Œè¿›è¡Œå‰¯æœ¬æ•°çš„ä¿®æ”¹ï¼‰ ensureHPAForScaledObjectExists é€šè¿‡è·Ÿè¸ªè¿›å…¥åˆ°newHPAForScaledObjectæ–¹æ³•:\nscaledObjectMetricSpecs, err := r.getScaledObjectMetricSpecs(logger, scaledObject) ...çœç•¥ä»£ç  hpa := \u0026autoscalingv2beta2.HorizontalPodAutoscaler{ Spec: autoscalingv2beta2.HorizontalPodAutoscalerSpec{ MinReplicas: getHPAMinReplicas(scaledObject), MaxReplicas: getHPAMaxReplicas(scaledObject), Metrics: scaledObjectMetricSpecs, Behavior: behavior, ScaleTargetRef: autoscalingv2beta2.CrossVersionObjectReference{ Name: scaledObject.Spec.ScaleTargetRef.Name, Kind: gvkr.Kind, APIVersion: gvkr.GroupVersion().String(), }}, ObjectMeta: metav1.ObjectMeta{ Name: getHPAName(scaledObject), Namespace: scaledObject.Namespace, Labels: labels, }, TypeMeta: metav1.TypeMeta{ APIVersion: \"v2beta2\", }, } å¯ä»¥çœ‹åˆ°åˆ›å»ºScalerObjectå…¶å®æœ€ç»ˆä¹Ÿæ˜¯åˆ›å»ºäº†HPAï¼Œå…¶å®è¿˜æ˜¯é€šè¿‡HPAæœ¬èº«çš„ç‰¹æ€§æ¥æ§åˆ¶åº”ç”¨çš„å¼¹æ€§ä¼¸ç¼©ã€‚\nå…¶ä¸­getScaledObjectMetricSpecsæ–¹æ³•ä¸­å°±æ˜¯è·å–åˆ°triggersä¸­çš„metricsæŒ‡æ ‡ã€‚\nè¿™é‡Œæœ‰åŒºåˆ†ä¸€ä¸‹Externalçš„metricså’Œresource metricsï¼Œå› ä¸ºCPU/Memory scaleræ˜¯é€šè¿‡resource metrics æ¥è·å–çš„ã€‚\nrequestScaleLoop requestScaleLoopæ–¹æ³•ä¸­ç”¨æ¥å¾ªç¯check Scalerä¸­çš„IsActiveçŠ¶æ€å¹¶ä½œå‡ºå¯¹åº”çš„å¤„ç†ï¼Œæ¯”å¦‚ä¿®æ”¹å‰¯æœ¬æ•°ï¼Œç›´æ¥æ¥çœ‹æœ€ç»ˆçš„å¤„ç†å§ï¼š è¿™é‡Œæœ‰ä¸¤ç§æ¨¡å‹æ¥è§¦å‘RequestScaleï¼š\nPullæ¨¡å‹ï¼šå³ä¸»åŠ¨çš„è°ƒç”¨scaler ä¸­çš„IsActiveæ–¹æ³• Pushæ¨¡å‹ï¼šç”±Scaleræ¥è§¦å‘ï¼ŒPushScalerå¤šäº†ä¸€ä¸ªRunæ–¹æ³•ï¼Œé€šè¿‡channelä¼ å…¥activeçŠ¶æ€ã€‚ IsActiveæ˜¯ç”±Scalerå®ç°çš„ï¼Œæ¯”å¦‚å¯¹äºprometheusæ¥è¯´ï¼Œå¯èƒ½æŒ‡æ ‡ä¸º0åˆ™ä¸ºfalse\nè¿™ä¸ªå…·ä½“çš„scalerå®ç°åç»­å†è®²ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹RequestScaleåšäº†ä»€ä¹ˆäº‹ï¼š\n//å½“å‰å‰¯æœ¬æ•°ä¸º0ï¼Œå¹¶æ˜¯æ‰€æœ‰scalerå±äºactiveçŠ¶æ€ï¼Œåˆ™ä¿®æ”¹å‰¯æœ¬æ•°ä¸ºMinReplicaCount æˆ– 1 if currentScale.Spec.Replicas == 0 \u0026\u0026 isActive { e.scaleFromZero(ctx, logger, scaledObject, currentScale) } else if !isActive \u0026\u0026 currentScale.Spec.Replicas \u003e 0 \u0026\u0026 (scaledObject.Spec.MinReplicaCount == nil || *scaledObject.Spec.MinReplicaCount == 0) { // æ‰€æœ‰scaleréƒ½å¤„ç†not activeçŠ¶æ€ï¼Œå¹¶ä¸”å½“å‰å‰¯æœ¬æ•°å¤§äº0ï¼Œä¸”MinReplicaCountè®¾å®šä¸º0 // åˆ™ç¼©å®¹å‰¯æœ¬æ•°ä¸º0 e.scaleToZero(ctx, logger, scaledObject, currentScale) } else if !isActive \u0026\u0026 scaledObject.Spec.MinReplicaCount != nil \u0026\u0026 currentScale.Spec.Replicas \u003c *scaledObject.Spec.MinReplicaCount { // æ‰€æœ‰scaleréƒ½å¤„ç†not activeçŠ¶æ€ï¼Œå¹¶ä¸”å½“å‰å‰¯æœ¬æ•°å°äºMinReplicaCountï¼Œåˆ™ä¿®æ”¹ä¸ºMinReplicaCount currentScale.Spec.Replicas = *scaledObject.Spec.MinReplicaCount err := e.updateScaleOnScaleTarget(ctx, scaledObject, currentScale) .... } else if isActive { // å¤„ç†activeçŠ¶æ€ï¼Œå¹¶ä¸”å‰¯æœ¬æ•°å¤§äº0ï¼Œåˆ™æ›´æ–°LastActiveTime e.updateLastActiveTime(ctx, logger, scaledObject) } else { // ä¸å¤„ç† logger.V(1).Info(\"ScaleTarget no change\") } ScaledJobReconciler å¤„ç† ScaledJobReconcilerç›¸æ¯”ScalerObjectå°‘äº†åˆ›å»ºHPAçš„æ­¥éª¤ï¼Œå…¶ä½™çš„æ­¥éª¤ä¸»è¦æ˜¯é€šè¿‡checkScaledJobScalersï¼ŒRequestJobScaleä¸¤ä¸ªæ–¹æ³•æ¥åˆ¤æ–­Jobåˆ›å»ºï¼š\ncheckScaledJobScalers æ–¹æ³•ï¼Œç”¨äºè®¡ç®—isActiveï¼ŒmaxValueçš„å€¼ RequestJobScale æ–¹æ³•ï¼Œç”¨äºè´Ÿè´£åˆ›å»ºJobï¼Œé‡Œé¢è¿˜æ¶‰åŠåˆ°ä¸‰ç§æ‰©å®¹ç­–ç•¥ è¿™é‡Œç›´æ¥çœ‹ä»£ç å§ï¼Œä¸è´´ä»£ç äº†ã€‚\nå¦‚ä½•åœæ­¢Loop\nè¿™é‡Œæœ‰ä¸ªé—®é¢˜å°±æ˜¯startPushScalerså’ŒstartScaleLoopéƒ½æ˜¯åœ¨Goroutineä¸­å¤„ç†çš„ï¼Œæ‰€ä»¥å½“ScaleObject/ScalerJobè¢«åˆ é™¤çš„æ—¶å€™ï¼Œè¿™é‡Œéœ€è¦èƒ½å¤Ÿè¢«åˆ é™¤ï¼Œè¿™é‡Œå°±ç”¨åˆ°äº†context.Cancelæ–¹æ³•ï¼Œåœ¨Goroutineå¯åŠ¨çš„æ—¶å€™å°±å°†ï¼Œcontextä¿å­˜åœ¨scaleLoopContexts *sync.Mapä¸­(å¦‚æœå·²ç»æœ‰äº†ï¼Œå°±å…ˆCancelä¸€æ¬¡)ï¼Œåœ¨åˆ é™¤èµ„æºçš„æ—¶å€™ï¼Œè¿›è¡Œåˆ é™¤:\nfunc (h *scaleHandler) DeleteScalableObject(scalableObject interface{}) error { withTriggers, err := asDuckWithTriggers(scalableObject) if err != nil { h.logger.Error(err, \"error duck typing object into withTrigger\") return err } key := generateKey(withTriggers) result, ok := h.scaleLoopContexts.Load(key) if ok { cancel, ok := result.(context.CancelFunc) if ok { cancel() } h.scaleLoopContexts.Delete(key) } else { h.logger.V(1).Info(\"ScaleObject was not found in controller cache\", \"key\", key) } return nil } ps: è¿™é‡Œçš„å¦™å•Šï¼Œå­¦åˆ°äº†","ä»£ç ç»“æ„#ä»£ç ç»“æ„":"å¯¹ä¸€äº›ä¸»è¦ç›®å½•è¯´æ˜ï¼Œå…¶ä»–ä¸€äº›MDæ–‡ä»¶ä¸»è¦æ˜¯æ–‡å­—è¯´æ˜ï¼š\nâ”œâ”€â”€ BRANDING.md â”œâ”€â”€ BUILD.md //å¦‚ä½•åœ¨æœ¬åœ°ç¼–è¯‘å’Œè¿è¡Œ â”œâ”€â”€ CHANGELOG.md â”œâ”€â”€ CONTRIBUTING.md //å¦‚ä½•å‚ä¸è´¡çŒ®æ¬¡é¡¹ç›® â”œâ”€â”€ CREATE-NEW-SCALER.md â”œâ”€â”€ Dockerfile â”œâ”€â”€ Dockerfile.adapter â”œâ”€â”€ GOVERNANCE.md â”œâ”€â”€ LICENSE â”œâ”€â”€ MAINTAINERS.md â”œâ”€â”€ Makefile // æ„å»ºç¼–è¯‘ç›¸å…³å‘½ä»¤ â”œâ”€â”€ PROJECT â”œâ”€â”€ README.md â”œâ”€â”€ RELEASE-PROCESS.MD â”œâ”€â”€ adapter // keda-metrics-apiserver ç»„ä»¶å…¥å£ â”œâ”€â”€ api // è‡ªå®šä¹‰èµ„æºå®šä¹‰ï¼Œä¾‹å¦‚ScaledObjectçš„å®šä¹‰ â”œâ”€â”€ bin â”œâ”€â”€ config //ç»„ä»¶yamlèµ„æºï¼Œé€šè¿‡kustomizationå·¥å…·ç”Ÿæˆ â”œâ”€â”€ controllers //kubebuilder ä¸­controller ä»£ç æ§åˆ¶crdèµ„æº â”œâ”€â”€ go.mod â”œâ”€â”€ go.sum â”œâ”€â”€ hack â”œâ”€â”€ images â”œâ”€â”€ main.go //keda-operator controllerå…¥å£ â”œâ”€â”€ pkg //åŒ…å«ç»„ä»¶æ ¸å¿ƒä»£ç å®ç° â”œâ”€â”€ tests //e2eæµ‹è¯• â”œâ”€â”€ tools â”œâ”€â”€ vendor â””â”€â”€ version kedaä¸­ä¸»è¦æ˜¯ä¸¤ä¸ªç»„ä»¶keda-operatorä»¥åŠkeda-metrics-apiserverã€‚\nkeda-operator ï¼š è´Ÿè´£åˆ›å»º/æ›´æ–°HPAä»¥åŠé€šè¿‡Loopæ§åˆ¶åº”ç”¨å‰¯æœ¬æ•° keda-metrics-apiserverï¼šå®ç°external-metricsæ¥å£ï¼Œä»¥å¯¹æ¥ç»™HPAçš„externalç±»å‹çš„æŒ‡æ ‡æŸ¥è¯¢ï¼ˆæ¯”å¦‚å„ç§prometheusæŒ‡æ ‡ï¼Œmysqlç­‰ï¼‰ ","å®ç°ä¸€ä¸ªscaler#å®ç°ä¸€ä¸ªScaler":"å…¶å®æœ‰ä¸¤ç§Scalerï¼Œå³ä¸Šé¢å°†çš„ä¸€ä¸ªpullï¼Œä¸€ä¸ªpushçš„æ¨¡å‹ï¼ŒPushScalerå¤šäº†ä¸€ä¸ªRunæ–¹æ³•ï¼š\nå®ç°ä¸€ä¸ªScalerï¼Œä¸»è¦å®ç°ä»¥ä¸‹æ¥å£ï¼š\n// Scaler interface type Scaler interface { // è¿”å›external_metrics.ExternalMetricValueå¯¹è±¡ï¼Œå…¶å®å°±æ˜¯ç”¨äº keda-metrics-apiserverä¸­è·å–åˆ°scalerçš„æŒ‡æ ‡ GetMetrics(ctx context.Context, metricName string, metricSelector labels.Selector) ([]external_metrics.ExternalMetricValue, error) // è¿”å›v2beta2.MetricSpec ç»“æ„ï¼Œä¸»è¦ç”¨äºScalerObjectæè¿°åˆ›å»ºHPAçš„ç±»å‹å’ŒTargetæŒ‡æ ‡ç­‰ GetMetricSpecForScaling() []v2beta2.MetricSpec // è¿”å›è¯¥Scaleræ˜¯å¦Activeï¼Œå¯èƒ½ä¼šå½±å“Loopä¸­ç›´æ¥ä¿®æ”¹å‰¯æœ¬æ•° IsActive(ctx context.Context) (bool, error) //è°ƒç”¨å®Œä¸€æ¬¡ä¸Šé¢çš„æ–¹æ³•å°±ä¼šè°ƒç”¨ä¸€æ¬¡Close Close() error } // PushScaler interface type PushScaler interface { Scaler // é€šè¿‡scalerå®ç°Runæ–¹æ³•ï¼Œå¾€active channelä¸­ï¼Œå†™å…¥å€¼ï¼Œè€Œéä¸Šé¢çš„ç›´æ¥è°ƒç”¨IsActiveæ”¾å› Run(ctx context.Context, active chan\u003c- bool) } ","æ€»ç»“#æ€»ç»“":"å›è¿‡å¤´æ¥æˆ‘ä»¬è§£ç­”ä¸‹åœ¨å¼€å¤´ç•™ä¸‹çš„é—®é¢˜ï¼š\nKEDAæ˜¯å¦‚ä½•è·å–åˆ°å¤šç§äº‹ä»¶çš„æŒ‡æ ‡ï¼Œä»¥åŠå¦‚ä½•åˆ¤æ–­æ‰©ç¼©å®¹çš„ï¼Ÿ\nç­”ï¼škeda controlerä¸­ç”Ÿæˆäº†external ç±»å‹çš„hpaï¼Œå¹¶ä¸”å®ç°äº†external metrics çš„api\nKEDAæ˜¯å¦‚ä½•åšåˆ°å°†åº”ç”¨çš„å‰¯æœ¬æ•°ç¼©å®¹0ï¼Œä¾æ®æ˜¯ä»€ä¹ˆï¼Ÿ\nç­”ï¼š keda å†…éƒ¨æœ‰ä¸ªloopï¼Œä¸æ–­çš„check isActiveçŠ¶æ€ï¼Œä¼šä¸»åŠ¨çš„ä¿®æ”¹åº”ç”¨å‰¯æœ¬"},"title":"æºç åˆ†æï¼šKEDAæ˜¯å¦‚ä½•å·¥ä½œçš„?"},"/wechat/":{"data":{"ä½¿ç”¨#ä½¿ç”¨":"æ ¹æ®åŠŸèƒ½ä¸åŒï¼Œè¿›å…¥å¯¹åº”çš„æ¨¡å—æ–‡æ¡£è¿›è¡ŒæŸ¥çœ‹\nä¾‹å­ ä»“åº“åœ°å€ï¼šhttps://github.com/gowechat/example","å…³æ³¨å…¬ä¼—å·#å…³æ³¨å…¬ä¼—å·":"","å®‰è£…#å®‰è£…":"æ¨èä½¿ç”¨go moduleè¿›è¡Œä¾èµ–ç®¡ç†\ngo get github.com/silenceper/wechat/v2 ","å¾®ä¿¡sdk-for-golang#å¾®ä¿¡SDK For Golang":"å¾®ä¿¡SDK For Golang WeChat SDK æ˜¯ä¸€ä¸ªGolangç‰ˆæœ¬å¾®ä¿¡SDKï¼Œç®€å•ã€æ˜“ç”¨ã€‚\nSDKæºç ï¼šhttps://github.com/silenceper/wechat\næ­¤æ–‡æ¡£ä½¿ç”¨sdk\u003e=2.0ç‰ˆæœ¬ï¼Œ1.xç³»åˆ—ç‰ˆæœ¬æ–‡æ¡£åœ¨ï¼šè¿™é‡Œ"},"title":"_index"},"/wechat/contributing.html":{"data":{"å‚ä¸è´¡çŒ®#å‚ä¸è´¡çŒ®":"å‚ä¸è´¡çŒ®ä¸»è¦åŒ…å«æºç å’Œæ–‡æ¡£çš„å…±äº«","æ–‡æ¡£#æ–‡æ¡£":"æ–‡æ¡£ä»“åº“åœ°å€ï¼šhttps://github.com/gowechat/docs","æºç #æºç ":" å…ˆè¿›å…¥ https://github.com/silenceper/wechat/issues æè¿°éœ€è¦è´¡çŒ®çš„å†…å®¹ å°†æºç forkè¿›å…¥è‡ªå·±çš„ä»“åº“ å¾…å®Œæˆä¹‹åæäº¤prå "},"title":"å‚ä¸è´¡çŒ®"},"/wechat/miniprogram/":{"data":{"":"","è·å–å°ç¨‹åºæ“ä½œå¯¹è±¡#è·å–å°ç¨‹åºæ“ä½œå¯¹è±¡":" wc := wechat.NewWechat() memory := cache.NewMemory() cfg := \u0026miniConfig.Config{ AppID: \"xxx\", AppSecret: \"xxx\", Cache: memory, } miniprogram := wc.GetMiniProgram(cfg) //TODO è°ƒç”¨å¯¹åº”æ¥å£ miniprogram.GetAnalysis().GetAnalysisDailyRetain() "},"title":"å°ç¨‹åº"},"/wechat/miniprogram/auth.html":{"data":{"":"","æ ¹æ®-jscode-è·å–ç”¨æˆ·-session-ä¿¡æ¯#æ ¹æ® jscode è·å–ç”¨æˆ· session ä¿¡æ¯":" Code2Session(jsCode string) (result ResCode2Session, err error) ","è·å–æ“ä½œå®ä¾‹#è·å–æ“ä½œå®ä¾‹":" mini := wc.GetMiniProgram(cfg) a:=mini.GetAuth() "},"title":"å¾®ä¿¡ç™»å½•"},"/wechat/miniprogram/decrypt.html":{"data":{"":"","è·å–æ“ä½œå®ä¾‹#è·å–æ“ä½œå®ä¾‹":" mini := wc.GetMiniProgram(cfg) a:=mini.GetEncryptor() ","è§£å¯†æ•°æ®#è§£å¯†æ•°æ®":" Decrypt(sessionKey, encryptedData, iv string) (*PlainData, error) å…¶ä¸­ç»“æœä¸ºï¼š\ntype PlainData struct { OpenID string `json:\"openId\"` UnionID string `json:\"unionId\"` NickName string `json:\"nickName\"` Gender int `json:\"gender\"` City string `json:\"city\"` Province string `json:\"province\"` Country string `json:\"country\"` AvatarURL string `json:\"avatarUrl\"` Language string `json:\"language\"` PhoneNumber string `json:\"phoneNumber\"` PurePhoneNumber string `json:\"purePhoneNumber\"` CountryCode string `json:\"countryCode\"` Watermark struct { Timestamp int64 `json:\"timestamp\"` AppID string `json:\"appid\"` } `json:\"watermark\"` } æ ¹æ®éœ€è¦å–ç”¨æˆ·ä¿¡æ¯è¿˜æ˜¯æ‰‹æœºå·ä¿¡æ¯"},"title":"æ¶ˆæ¯è§£å¯†"},"/wechat/miniprogram/qrcode.html":{"data":{"":"","è·å–å°ç¨‹åºäºŒç»´ç é€‚ç”¨äºéœ€è¦çš„ç æ•°é‡è¾ƒå°‘çš„ä¸šåŠ¡åœºæ™¯#è·å–å°ç¨‹åºäºŒç»´ç ï¼Œé€‚ç”¨äºéœ€è¦çš„ç æ•°é‡è¾ƒå°‘çš„ä¸šåŠ¡åœºæ™¯":" CreateWXAQRCode(coderParams QRCoder) (response []byte, err error) ","è·å–å°ç¨‹åºç é€‚ç”¨äºéœ€è¦çš„ç æ•°é‡æå¤šçš„ä¸šåŠ¡åœºæ™¯#è·å–å°ç¨‹åºç ï¼Œé€‚ç”¨äºéœ€è¦çš„ç æ•°é‡æå¤šçš„ä¸šåŠ¡åœºæ™¯":" GetWXACodeUnlimit(coderParams QRCoder) (response []byte, err error) ","è·å–å°ç¨‹åºç é€‚ç”¨äºéœ€è¦çš„ç æ•°é‡è¾ƒå°‘çš„ä¸šåŠ¡åœºæ™¯#è·å–å°ç¨‹åºç ï¼Œé€‚ç”¨äºéœ€è¦çš„ç æ•°é‡è¾ƒå°‘çš„ä¸šåŠ¡åœºæ™¯":" GetWXACode(coderParams QRCoder) (response []byte, err error) ","è·å–æ“ä½œå®ä¾‹#è·å–æ“ä½œå®ä¾‹":" mini := wc.GetMiniProgram(cfg) qr:=mini.GetQrcode() "},"title":"å°ç¨‹åºç "},"/wechat/miniprogram/subscribe.html":{"data":{"":"å¾®ä¿¡æ–‡æ¡£","å‘é€è®¢é˜…æ¶ˆæ¯#å‘é€è®¢é˜…æ¶ˆæ¯":" Send(msg *Message) (err error) å…¶ä¸­Messageå†…å®¹ä¸º,å…·ä½“è¯´æ˜è¯·å‚è€ƒå¾®ä¿¡æ–‡æ¡£ï¼šï¼š\n// Message è®¢é˜…æ¶ˆæ¯è¯·æ±‚å‚æ•° type Message struct { ToUser string `json:\"touser\"` //å¿…é€‰ï¼Œæ¥æ”¶è€…ï¼ˆç”¨æˆ·ï¼‰çš„ openid TemplateID string `json:\"template_id\"` //å¿…é€‰ï¼Œæ‰€éœ€ä¸‹å‘çš„è®¢é˜…æ¨¡æ¿id Page string `json:\"page\"` //å¯é€‰ï¼Œç‚¹å‡»æ¨¡æ¿å¡ç‰‡åçš„è·³è½¬é¡µé¢ï¼Œä»…é™æœ¬å°ç¨‹åºå†…çš„é¡µé¢ã€‚æ”¯æŒå¸¦å‚æ•°,ï¼ˆç¤ºä¾‹index?foo=barï¼‰ã€‚è¯¥å­—æ®µä¸å¡«åˆ™æ¨¡æ¿æ— è·³è½¬ã€‚ Data map[string]*DataItem `json:\"data\"` //å¿…é€‰, æ¨¡æ¿å†…å®¹ MiniprogramState string `json:\"miniprogram_state\"` //å¯é€‰ï¼Œè·³è½¬å°ç¨‹åºç±»å‹ï¼šdeveloperä¸ºå¼€å‘ç‰ˆï¼›trialä¸ºä½“éªŒç‰ˆï¼›formalä¸ºæ­£å¼ç‰ˆï¼›é»˜è®¤ä¸ºæ­£å¼ç‰ˆ Lang string `json:\"lang\"` //å…¥å°ç¨‹åºæŸ¥çœ‹\"çš„è¯­è¨€ç±»å‹ï¼Œæ”¯æŒzh_CN(ç®€ä½“ä¸­æ–‡)ã€en_US(è‹±æ–‡)ã€zh_HK(ç¹ä½“ä¸­æ–‡)ã€zh_TW(ç¹ä½“ä¸­æ–‡)ï¼Œé»˜è®¤ä¸ºzh_CN } ","è·å–æ“ä½œå®ä¾‹#è·å–æ“ä½œå®ä¾‹":" mini := wc.GetMiniProgram(cfg) sub:=mini.GetSubscribe() "},"title":"è®¢é˜…æ¶ˆæ¯"},"/wechat/miniprogram/tcb.html":{"data":{"":"Tencent Cloud Base æ–‡æ¡£","ä¸¾ä¾‹#ä¸¾ä¾‹":"è§¦å‘äº‘å‡½æ•° res, err := wcTcb.InvokeCloudFunction(\"test-xxxx\", \"add\", `{\"a\":1,\"b\":2}`) if err != nil { panic(err) } æ›´å¤šä½¿ç”¨æ–¹æ³•å‚è€ƒGODOC","ä½¿ç”¨è¯´æ˜#ä½¿ç”¨è¯´æ˜":"åˆå§‹åŒ–é…ç½®\nwc := wechat.NewWechat() //ä½¿ç”¨memcacheä¿å­˜access_tokenï¼Œä¹Ÿå¯é€‰æ‹©redisæˆ–è‡ªå®šä¹‰cache memCache:=cache.NewMemcache(\"127.0.0.1:11211\") //é…ç½®å°ç¨‹åºå‚æ•° config := \u0026wechat.Config{ AppID: \"your app id\", AppSecret: \"your app secret\", Cache: memCache, } miniprogram := wc.GetMiniProgram(cfg) wcTcb := miniprogram.GetTcb() "},"title":"äº‘å¼€å‘"},"/wechat/officialaccount/":{"data":{"":"å¼€å‘å‰å¿…è¯»ï¼šå¾®ä¿¡å…¬ä¼—å®˜æ–¹æ–‡æ¡£","è·å–å¾®ä¿¡å…¬ä¼—å·æ“ä½œå¯¹è±¡#è·å–å¾®ä¿¡å…¬ä¼—å·æ“ä½œå¯¹è±¡":" wc := wechat.NewWechat() //è®¾ç½®å…¨å±€cacheï¼Œä¹Ÿå¯ä»¥å•ç‹¬ä¸ºæ¯ä¸ªæ“ä½œå®ä¾‹è®¾ç½® redisOpts := \u0026cache.RedisOpts{ Host: \"127.0.0.1:6379\", } redisCache := cache.NewRedis(redisOpts) wc.SetCache(redisCache) cfg := \u0026offConfig.Config{ AppID: \"xxx\", AppSecret: \"xxx\", Token: \"xxx\", //EncodingAESKey: \"xxxx\", //Cache: redisCache, //ä¹Ÿå¯ä»¥å•ç‹¬è®¾ç½® } officialAccount := wc.GetOfficialAccount(cfg) //TODO ä½¿ç”¨ `officialAccount` æ“ä½œå…¬ä¼—å·ç›¸å…³æ¥å£ "},"title":"å…¬ä¼—å·"},"/wechat/officialaccount/basic.html":{"data":{"":"","æ¸…ç†æ¥å£è°ƒç”¨é¢‘æ¬¡#æ¸…ç†æ¥å£è°ƒç”¨é¢‘æ¬¡":" æ­¤æ¥å£å®˜æ–¹æœ‰æ¯æœˆè°ƒç”¨é™åˆ¶ï¼Œä¸å¯éšæ„è°ƒç”¨\nerr:=officialAccount.GetBasic().ClearQuota() ","è·å–access_token#è·å–\u003ccode\u003eaccess_token\u003c/code\u003e":"å¾®ä¿¡å…¬ä¼—å·æ“ä½œåŸºç¡€æ¥å£\nè·å–access_token åœ¨æ¯ä¸ªæ“ä½œå®ä¾‹å¯¹è±¡ä¸­ä¹Ÿæœ‰GetAccessTokenæ–¹æ³•\nak,err:=officialAccount.GetAccessToken() æ›¿æ¢è·å–access_tokençš„æ–¹æ³• é»˜è®¤åœ¨sdkå†…éƒ¨æ˜¯akè·å–ä¹‹åæ˜¯å­˜æ”¾åœ¨cacheä¸­ï¼Œå¦‚æœä½ æœ‰å…¶ä»–ç³»ç»Ÿä»¥åŠå­˜æ”¾äº†akçš„è¯ï¼Œåªéœ€è¦å®ç°å¦‚ä¸‹interfaceå°±å¯ä»¥äº†ï¼š\n//AccessTokenHandle AccessToken æ¥å£ type AccessTokenHandle interface { GetAccessToken() (accessToken string, err error) } ç„¶åé€šè¿‡wechatå¯¹è±¡ï¼Œè¿›è¡Œè®¾ç½®:\nofficialAccount.SetAccessTokenHandle=customAccessTokenHandle ","è·å–å¾®ä¿¡æœåŠ¡å™¨-ip-æˆ–ipæ®µ#è·å–å¾®ä¿¡æœåŠ¡å™¨ IP (æˆ–IPæ®µ)":"å¦‚æœå…¬ä¼—å·åŸºäºå®‰å…¨ç­‰è€ƒè™‘ï¼Œéœ€è¦è·çŸ¥å¾®ä¿¡æœåŠ¡å™¨çš„IPåœ°å€åˆ—è¡¨ï¼Œä»¥ä¾¿è¿›è¡Œç›¸å…³é™åˆ¶ï¼Œå¯ä»¥é€šè¿‡è¯¥æ¥å£è·å¾—å¾®ä¿¡æœåŠ¡å™¨IPåœ°å€åˆ—è¡¨æˆ–è€…IPç½‘æ®µä¿¡æ¯ã€‚\nè·å–å¾®ä¿¡callback IPåœ°å€ ipList, err:=officialAccount.GetBasic().GetCallbackIP() è·å–å¾®ä¿¡APIæ¥å£ IPåœ°å€ ipList, err:=officialAccount.GetBasic().GetAPIDomainIP() "},"title":"åŸºç¡€æ¥å£"},"/wechat/officialaccount/broadcast.html":{"data":{"":"","å‘é€å¯¹è±¡#å‘é€å¯¹è±¡":" å‘é€æ–¹æ³•çš„ç¬¬ä¸€ä¸ªå‚æ•°ä¸ºbroadcast.Userå¯¹è±¡ï¼Œä¸ºnilåˆ™è¡¨ç¤ºå‘é€ç»™æ‰€æœ‰äºº broadcast.User{TagID:1} : æ ¹æ®tagIDå‘é€ `broadcast.User{OpenID:[]string{â€œopenid-1â€,â€œopenid-2â€}}`` ï¼šæ ¹æ®openidå‘é€ ","ç¾¤å‘æ¶ˆæ¯ç±»å‹#ç¾¤å‘æ¶ˆæ¯ç±»å‹":"å‘é€æ–‡æœ¬æ¶ˆæ¯ bd.SendText(user *User, content string) å‘é€å›¾æ–‡ bd.SendNews(user *User, mediaID string,ignoreReprint bool) å‘é€å›¾ç‰‡ bd.SendImage(user *User, images *Image) å‘é€è¯­éŸ³ bd.SendVoice(user *User, mediaID string) å‘é€è§†é¢‘ bd.SendVideo(user *User, mediaID string,title,description string) ","è·å–ç¾¤å‘æ“ä½œå®ä¾‹#è·å–ç¾¤å‘æ“ä½œå®ä¾‹":" oa := wc.GetOfficialAccount(cfg) bd:=oa.GetBroadcast() //TODO bd.SendText "},"title":"æ¶ˆæ¯ç¾¤å‘"},"/wechat/officialaccount/configuration.html":{"data":{"":"é€šå¸¸é€šè¿‡å¦‚ä¸‹é…ç½®å°±å¯ä»¥è·å–åˆ°ä¸€ä¸ªofficialAccountçš„æ“ä½œå®ä¾‹äº†ã€‚\n//ä½¿ç”¨memcacheä¿å­˜access_tokenï¼Œä¹Ÿå¯é€‰æ‹©redisæˆ–è‡ªå®šä¹‰cache wc := wechat.NewWechat() redisOpts := \u0026cache.RedisOpts{ Host: \"127.0.0.1:6379\", Database: 0, MaxActive: 10, MaxIdle: 10, IdleTimeout: 60, //second } redisCache := cache.NewRedis(redisOpts) cfg := \u0026offConfig.Config{ AppID: \"xxx\", AppSecret: \"xxx\", Token: \"xxx\", //EncodingAESKey: \"xxxx\", Cache: redisCache, } officialAccount := wc.GetOfficialAccount(cfg) å¾®ä¿¡å…¬ä¼—å·æ”¯æŒçš„é…ç½®ï¼Œå¦‚ä¸‹ï¼š\n//Config config for å¾®ä¿¡å…¬ä¼—å· type Config struct { AppID string `json:\"app_id\"` //appid AppSecret string `json:\"app_secret\"` //appsecret Token string `json:\"token\"` //token EncodingAESKey string `json:\"encoding_aes_key\"` //EncodingAESKey Cache cache.Cache } é…ç½®è¯´æ˜ï¼š\nå‚æ•° æ˜¯å¦å¿…é¡» è¯´æ˜ AppID æ˜¯ å¾®ä¿¡å…¬ä¼—å·APP ID AppSecret æ˜¯ å¾®ä¿¡å…¬ä¼—å·App Secret EncodingAESKey å¦ å¦‚æœæŒ‡å®šåˆ™è¡¨ç¤ºå¼€å¯AESåŠ å¯†ï¼Œæ¶ˆæ¯å’Œç»“æœéƒ½ä¼šè¿›è¡Œè§£å¯†å’ŒåŠ å¯† Cache å¦ å•ç‹¬æŒ‡å®šå¾®ä¿¡å…¬ä¼—å·ç”¨åˆ°çš„AccessTokenä¿å­˜çš„ä½ç½®ï¼Œä¼šè¦†ç›–å…¨å±€é€šè¿‡wechat.SetCacheçš„è®¾ç½® å‚æ•°é…ç½®è¯·å‰å¾€å¾®ä¿¡å…¬ä¼—å·åå°è·å–","æ—¥å¿—#\bæ—¥å¿—":"sdkä¸­ä½¿ç”¨github.com/sirupsen/logrusæ¥è¿›è¡Œæ—¥å¿—çš„è¾“å‡ºã€‚ é»˜è®¤çš„æ—¥å¿—å‚æ•°ä¸ºï¼š\n// æ—¥å¿—è¾“å‡ºç±»å‹ï¼ŒTextæ–‡æœ¬ log.SetFormatter(\u0026log.TextFormatter{}) // å°†æ—¥å¿—ç›´æ¥è¾“å‡ºåˆ°stdout log.SetOutput(os.Stdout) // è¾“å‡ºæ—¥å¿—ä¸ºDebug æ¨¡å¼ log.SetLevel(log.DebugLevel) ä½ å¯ä»¥åœ¨è‡ªå·±çš„é¡¹ç›®ä¸­è‡ªå®šä¹‰logrusçš„è¾“å‡ºé…ç½®æ¥è¦†ç›–sdkä¸­é»˜è®¤çš„è¡Œä¸º å‚è€ƒ: logrusé…ç½®æ–‡æ¡£","ç¼“å­˜#ç¼“å­˜":"ä½œç”¨ï¼š ç¼“å­˜access_tokenï¼Œä¿å­˜åœ¨ç‹¬ç«‹æœåŠ¡ä¸Šå¯ä»¥ä¿è¯access_tokenåœ¨æœ‰æ•ˆæœŸå†…ï¼Œaccess_tokenæ˜¯å…¬ä¼—å·çš„å…¨å±€å”¯ä¸€æ¥å£è°ƒç”¨å‡­æ®ï¼Œå…¬ä¼—å·è°ƒç”¨å„æ¥å£æ—¶éƒ½éœ€ä½¿ç”¨access_tokenã€‚\næ¨èä½¿ç”¨redisæˆ–è€…memcache\nRedis å®ä¾‹åŒ–å¦‚ä¸‹ï¼š\nredisOpts := \u0026cache.RedisOpts{ Host: \"127.0.0.1:6379\", // redis host Password: \"\",//redis password Database: 0, // redis db MaxActive: 10, // è¿æ¥æ± æœ€å¤§æ´»è·ƒè¿æ¥æ•° MaxIdle: 10, //è¿æ¥æ± æœ€å¤§ç©ºé—²è¿æ¥æ•° IdleTimeout: 60, //ç©ºé—²è¿æ¥è¶…æ—¶æ—¶é—´ï¼Œå•ä½ï¼šsecond } redisCache := cache.NewRedis(redisOpts) Memcache å®ä¾‹åŒ–å¦‚ä¸‹ï¼š\nmemCache:=cache.NewMemcache(\"127.0.0.1:11211\") Memory è¿›ç¨‹å†…å†…å­˜\nä¸æ¨èä½¿ç”¨è¯¥æ¨¡å¼ç”¨äºç”Ÿäº§\nå®ä¾‹åŒ–å¦‚ä¸‹ï¼š\nmemoryCache:=cache.NewMemory() è‡ªå®šä¹‰Cache æ¥å£å¦‚ä¸‹ï¼š\n//Cache interface type Cache interface { Get(key string) interface{} Set(key string, val interface{}, timeout time.Duration) error IsExist(key string) bool Delete(key string) error } æ–‡ä»¶ä½ç½®ï¼š/cache/cache.go","è·³è¿‡æ¥å£éªŒè¯#è·³è¿‡æ¥å£éªŒè¯":"å¾®ä¿¡å…¬ä¼—å·åå°åœ¨å¡«å†™æ¥å£é…ç½®ä¿¡æ¯æ—¶ä¼šè¿›è¡Œæ¥å£çš„æ ¡éªŒä»¥ç¡®ä¿æ¥å£æ˜¯å¦å¯ä»¥æ­£å¸¸ç›¸åº”ã€‚ å¦‚æœæƒ³è¦åœ¨sdkä¸­å…³é—­è¯¥è®¾ç½®ï¼Œå¯ä»¥é€šè¿‡å¦‚ä¸‹æ–¹æ³•ï¼š\nofficialAccount := wc.GetOfficialAccount(cfg) // ä¼ å…¥requestå’ŒresponseWriter server := officialAccount.GetServer(req, rw) //å…³é—­æ¥å£éªŒè¯ï¼Œåˆ™validateç»“æœåˆ™ä¸€ç›´è¿”å›true server.SkipValidate(true) "},"title":"é…ç½®"},"/wechat/officialaccount/customer_service.html":{"data":{"æ–°ç‰ˆå®¢æœæ¶ˆæ¯#æ–°ç‰ˆå®¢æœæ¶ˆæ¯":"æ–°ç‰ˆå®¢æœæ¶ˆæ¯TODO"},"title":"æ–°ç‰ˆå®¢æœæ¶ˆæ¯"},"/wechat/officialaccount/js.html":{"data":{"":"","æ›¿æ¢js-ticketå–å€¼æ–¹å¼#æ›¿æ¢\u003ccode\u003ejs-ticket\u003c/code\u003eå–å€¼æ–¹å¼":"è·å–js-sdkæ“ä½œå®ä¾‹ oa := wc.GetOfficialAccount(cfg) j:=oa.GetJs() è·å–jsé…ç½® GetConfig(uri string) (config *Config, err error) å…¶ä¸­ Config ç»“æœä¸ºï¼š\n// Config è¿”å›ç»™ç”¨æˆ·jssdké…ç½®ä¿¡æ¯ type Config struct { AppID string `json:\"app_id\"` Timestamp int64 `json:\"timestamp\"` NonceStr string `json:\"nonce_str\"` Signature string `json:\"signature\"` } æ›¿æ¢js-ticketå–å€¼æ–¹å¼ é»˜è®¤js-ticketæ˜¯å­˜æ”¾åœ¨sdkè®¾ç½®çš„cacheï¼Œå¦‚æœéœ€è¦è‡ªå®šä¹‰å–å€¼ï¼Œå¯ä»¥å®ç°credential.JsTicketHandleæ¥å£ï¼š\n//JsTicketHandle js ticketè·å– type JsTicketHandle interface { //GetTicket è·å–ticket GetTicket(accessToken string) (ticket string, err error) } ç„¶åé€šè¿‡js.SetJsTicketHandle(ticketHandle credential.JsTicketHandle)è¿›è¡Œè®¾ç½®","è·å–js-sdkæ“ä½œå®ä¾‹#è·å–js-sdkæ“ä½œå®ä¾‹":"","è·å–jsé…ç½®#è·å–jsé…ç½®":""},"title":"JS-SDK"},"/wechat/officialaccount/material.html":{"data":{"":"","åˆ é™¤æ°¸ä¹…ç´ æ#åˆ é™¤æ°¸ä¹…ç´ æ":" DeleteMaterial(mediaID string) ","æ‰¹é‡è·å–æ°¸ä¹…ç´ æ#æ‰¹é‡è·å–æ°¸ä¹…ç´ æ":" BatchGetMaterial(permanentMaterialType PermanentMaterialType, offset, count int64) ","æ–°å¢å…¶ä»–ç±»å‹æ°¸ä¹…ç´ æé™¤è§†é¢‘#æ–°å¢å…¶ä»–ç±»å‹æ°¸ä¹…ç´ æ(é™¤è§†é¢‘)":" AddMaterial(mediaType MediaType, filename string) ","æ–°å¢æ°¸ä¹…å›¾æ–‡ç´ æ#æ–°å¢æ°¸ä¹…å›¾æ–‡ç´ æ":" AddNews(articles []*Article) ","æ–°å¢æ°¸ä¹…è§†é¢‘ç´ æ#æ–°å¢æ°¸ä¹…è§†é¢‘ç´ æ":" AddVideo(filename, title, introduction string) ","è·å–æ°¸ä¹…å›¾æ–‡ç´ æ#è·å–æ°¸ä¹…å›¾æ–‡ç´ æ":" GetNews(id string) ([]*Article, error) ","è·å–ç´ ææ“ä½œå®ä¾‹#è·å–ç´ ææ“ä½œå®ä¾‹":" oa := wc.GetOfficialAccount(cfg) m:=oa.GetMaterial() "},"title":"ç´ æç®¡ç†"},"/wechat/officialaccount/menu.html":{"data":{"":"","åˆ é™¤ä¸ªæ€§åŒ–èœå•#åˆ é™¤ä¸ªæ€§åŒ–èœå•":" DeleteConditional(menuID int64) error ","åˆ é™¤èœå•#åˆ é™¤èœå•":" DeleteMenu() error ","æµ‹è¯•ä¸ªæ€§åŒ–èœå•åŒ¹é…ç»“æœ#æµ‹è¯•ä¸ªæ€§åŒ–èœå•åŒ¹é…ç»“æœ":" MenuTryMatch(userID string) (buttons []Button, err error) ","æ·»åŠ ä¸ªæ€§åŒ–èœå•jsonæ–¹å¼#æ·»åŠ ä¸ªæ€§åŒ–èœå•ï¼ˆJSONæ–¹å¼ï¼‰":"ç›´æ¥ä¼ å…¥json\nAddConditionalByJSON(jsonInfo string) error ","æ·»åŠ ä¸ªæ€§åŒ–èœå•structæ–¹å¼#æ·»åŠ ä¸ªæ€§åŒ–èœå•ï¼ˆstructæ–¹å¼ï¼‰":" AddConditional(buttons []*Button, matchRule *MatchRule) error ","æ·»åŠ èœå•jsonæ–¹å¼#æ·»åŠ èœå•ï¼ˆJSONæ–¹å¼ï¼‰":"ç›´æ¥ä¼ å…¥json\nSetMenuByJSON(jsonInfo string) error ","æ·»åŠ èœå•structæ–¹å¼#æ·»åŠ èœå•ï¼ˆstructæ–¹å¼ï¼‰":" SetMenu(buttons []*Button) error ","è·å–å½“å‰èœå•è®¾ç½®#è·å–å½“å‰èœå•è®¾ç½®":" GetMenu() (resMenu ResMenu, err error) å…¶ä¸­ResMenuç»“æœä¸ºï¼š\n//ResMenu æŸ¥è¯¢èœå•çš„è¿”å›æ•°æ® type ResMenu struct { util.CommonError Menu struct { Button []Button `json:\"button\"` MenuID int64 `json:\"menuid\"` } `json:\"menu\"` Conditionalmenu []resConditionalMenu `json:\"conditionalmenu\"` } ","è·å–è‡ªå®šä¹‰èœå•é…ç½®æ¥å£#è·å–è‡ªå®šä¹‰èœå•é…ç½®æ¥å£":" GetCurrentSelfMenuInfo() (resSelfMenuInfo ResSelfMenuInfo, err error) å…¶ä¸­ResSelfMenuInfoç»“æœä¸ºï¼š\ntype ResSelfMenuInfo struct { util.CommonError IsMenuOpen int32 `json:\"is_menu_open\"` SelfMenuInfo struct { Button []SelfMenuButton `json:\"button\"` } `json:\"selfmenu_info\"` } ","è·å–èœå•æ“ä½œå®ä¾‹#è·å–èœå•æ“ä½œå®ä¾‹":" oa := wc.GetOfficialAccount(cfg) m:=oa.GetMenu() "},"title":"èœå•ç®¡ç†"},"/wechat/officialaccount/message.html":{"data":{"":" å½“æ™®é€šå¾®ä¿¡ç”¨æˆ·å‘å…¬ä¼—è´¦å·å‘æ¶ˆæ¯æ—¶ï¼Œå¾®ä¿¡æœåŠ¡å™¨å°†POSTæ¶ˆæ¯çš„XMLæ•°æ®åŒ…åˆ°å¼€å‘è€…å¡«å†™çš„URLä¸Šã€‚\nåœ¨å¿«é€Ÿå…¥é—¨ä¸€èŠ‚ä¸­å°±å·²ç»æ¼”ç¤ºäº†å¦‚æœæ”¶åˆ°æ¶ˆæ¯ä»¥åŠå¯¹æ¶ˆæ¯è¿›è¡Œå›å¤ åœ¨SDKä¸­é€šè¿‡SetMessageHandleræ–¹æ³•å¯¹æ¶ˆæ¯è¿›è¡Œæ¥æ”¶ä»¥åŠå¤„ç†\nserver.SetMessageHandler(func(msg message.MixMessage) *message.Reply { //TODO å¯¹æ¥æ”¶åˆ°çš„æ¶ˆæ¯ä»¥åŠå¤„ç† }) å…¶ä¸­MixMessageä¸­åŒ…å«äº†ä¸€ä¸ªMsgTypeå­—æ®µï¼Œä¸»è¦ä¼šæœ‰ä»¥ä¸‹å‡ ç§ç±»å‹ï¼š","æ¥æ”¶äº‹ä»¶æ¨é€#æ¥æ”¶äº‹ä»¶æ¨é€":"å¦‚æœmsg.MsgTypeå€¼ä¸ºMsgTypeEventåˆ™è¡¨ç¤ºæ¥æ”¶åˆ°çš„æ˜¯ä¸€ä¸ªäº‹ä»¶æ¨é€ï¼Œé€šè¿‡msg.EventTypeå¯ä»¥åˆ¤æ–­äº‹ä»¶ç±»å‹ï¼Œå¯ä»¥ä¸ºä»¥ä¸‹å‡ ç§ï¼š\nconst ( //EventSubscribe è®¢é˜… EventSubscribe EventType = \"subscribe\" //EventUnsubscribe å–æ¶ˆè®¢é˜… EventUnsubscribe = \"unsubscribe\" //EventScan ç”¨æˆ·å·²ç»å…³æ³¨å…¬ä¼—å·ï¼Œåˆ™å¾®ä¿¡ä¼šå°†å¸¦åœºæ™¯å€¼æ‰«æäº‹ä»¶æ¨é€ç»™å¼€å‘è€… EventScan = \"SCAN\" //EventLocation ä¸ŠæŠ¥åœ°ç†ä½ç½®äº‹ä»¶ EventLocation = \"LOCATION\" //EventClick ç‚¹å‡»èœå•æ‹‰å–æ¶ˆæ¯æ—¶çš„äº‹ä»¶æ¨é€ EventClick = \"CLICK\" //EventView ç‚¹å‡»èœå•è·³è½¬é“¾æ¥æ—¶çš„äº‹ä»¶æ¨é€ EventView = \"VIEW\" //EventScancodePush æ‰«ç æ¨äº‹ä»¶çš„äº‹ä»¶æ¨é€ EventScancodePush = \"scancode_push\" //EventScancodeWaitmsg æ‰«ç æ¨äº‹ä»¶ä¸”å¼¹å‡º\"æ¶ˆæ¯æ¥æ”¶ä¸­\"æç¤ºæ¡†çš„äº‹ä»¶æ¨é€ EventScancodeWaitmsg = \"scancode_waitmsg\" //EventPicSysphoto å¼¹å‡ºç³»ç»Ÿæ‹ç…§å‘å›¾çš„äº‹ä»¶æ¨é€ EventPicSysphoto = \"pic_sysphoto\" //EventPicPhotoOrAlbum å¼¹å‡ºæ‹ç…§æˆ–è€…ç›¸å†Œå‘å›¾çš„äº‹ä»¶æ¨é€ EventPicPhotoOrAlbum = \"pic_photo_or_album\" //EventPicWeixin å¼¹å‡ºå¾®ä¿¡ç›¸å†Œå‘å›¾å™¨çš„äº‹ä»¶æ¨é€ EventPicWeixin = \"pic_weixin\" //EventLocationSelect å¼¹å‡ºåœ°ç†ä½ç½®é€‰æ‹©å™¨çš„äº‹ä»¶æ¨é€ EventLocationSelect = \"location_select\" //EventTemplateSendJobFinish å‘é€æ¨¡æ¿æ¶ˆæ¯æ¨é€é€šçŸ¥ EventTemplateSendJobFinish = \"TEMPLATESENDJOBFINISH\" //EventWxaMediaCheck å¼‚æ­¥æ ¡éªŒå›¾ç‰‡/éŸ³é¢‘æ˜¯å¦å«æœ‰è¿æ³•è¿è§„å†…å®¹æ¨é€äº‹ä»¶ EventWxaMediaCheck = \"wxa_media_check\" ) ","æ¥æ”¶æ™®é€šæ¶ˆæ¯#æ¥æ”¶æ™®é€šæ¶ˆæ¯":" const ( //MsgTypeText è¡¨ç¤ºæ–‡æœ¬æ¶ˆæ¯ MsgTypeText MsgType = \"text\" //MsgTypeImage è¡¨ç¤ºå›¾ç‰‡æ¶ˆæ¯ MsgTypeImage = \"image\" //MsgTypeVoice è¡¨ç¤ºè¯­éŸ³æ¶ˆæ¯ MsgTypeVoice = \"voice\" //MsgTypeVideo è¡¨ç¤ºè§†é¢‘æ¶ˆæ¯ MsgTypeVideo = \"video\" //MsgTypeShortVideo è¡¨ç¤ºçŸ­è§†é¢‘æ¶ˆæ¯[é™æ¥æ”¶] MsgTypeShortVideo = \"shortvideo\" //MsgTypeLocation è¡¨ç¤ºåæ ‡æ¶ˆæ¯[é™æ¥æ”¶] MsgTypeLocation = \"location\" //MsgTypeLink è¡¨ç¤ºé“¾æ¥æ¶ˆæ¯[é™æ¥æ”¶] MsgTypeLink = \"link\" //MsgTypeMusic è¡¨ç¤ºéŸ³ä¹æ¶ˆæ¯[é™å›å¤] MsgTypeMusic = \"music\" //MsgTypeNews è¡¨ç¤ºå›¾æ–‡æ¶ˆæ¯[é™å›å¤] MsgTypeNews = \"news\" //MsgTypeTransfer è¡¨ç¤ºæ¶ˆæ¯æ¶ˆæ¯è½¬å‘åˆ°å®¢æœ MsgTypeTransfer = \"transfer_customer_service\" //MsgTypeEvent è¡¨ç¤ºäº‹ä»¶æ¨é€æ¶ˆæ¯ MsgTypeEvent = \"event\" ) ","è¢«åŠ¨å›å¤ç”¨æˆ·æ¶ˆæ¯#è¢«åŠ¨å›å¤ç”¨æˆ·æ¶ˆæ¯":"å½“æ”¶åˆ°ç”¨æˆ·å‘å…¬ä¼—å·å‘é€çš„æ¶ˆæ¯åå¯ä»¥å¯¹å‘è¿‡æ¥çš„è¿›è¡Œä¸€æ¬¡å›å¤ï¼š\nç°æ”¯æŒä¸€ä¸‹å‡ ç§å›å¤ï¼šæ–‡æœ¬ã€å›¾ç‰‡ã€å›¾æ–‡ã€è¯­éŸ³ã€è§†é¢‘ã€éŸ³ä¹\nå›å¤æ–‡æœ¬ server.SetMessageHandler(func(msg message.MixMessage) *message.Reply { //TODO æ¼”ç¤ºå›å¤æ–‡æœ¬ //å›å¤æ¶ˆæ¯ï¼šæ¼”ç¤ºå›å¤ç”¨æˆ·å‘é€çš„æ¶ˆæ¯ text := message.NewText(msg.Content) return \u0026message.Reply{MsgType: message.MsgTypeText, MsgData: text} }) å›å¤å›¾ç‰‡ image := message.NewImage(mediaID) return \u0026message.Reply{MsgType: message.MsgTypeImage, MsgData: image} å…¶ä¸­ mediaID ä¸ºåª’ä½“èµ„æº ID ,å¯ä»¥é€šè¿‡ç´ æç®¡ç†(Material)ä¸­çš„æ¥å£è¿›è¡Œä¸Šä¼ \nå›å¤å›¾æ–‡ article1 := message.NewArticle(\"æµ‹è¯•å›¾æ–‡1\", \"å›¾æ–‡æè¿°\", \"http://å›¾ç‰‡é“¾æ¥åœ°å€\", \"http://å›¾æ–‡é“¾æ¥åœ°å€\") articles := []*message.Article{article1} news := message.NewNews(articles) return \u0026message.Reply{MsgType: message.MsgTypeNews, MsgData: news} å›å¤è¯­éŸ³ voice := message.NewVoice(mediaID) return \u0026message.Reply{MsgType: message.MsgTypeVoice, MsgData: voice} å…¶ä¸­ mediaID ä¸ºåª’ä½“èµ„æº ID ,å¯ä»¥é€šè¿‡ç´ æç®¡ç†(Material)ä¸­çš„æ¥å£è¿›è¡Œä¸Šä¼ \nå›å¤è§†é¢‘ video := message.NewVideo(mediaID, \"æ ‡é¢˜\", \"æè¿°\") return \u0026message.Reply{MsgType: message.MsgTypeVideo, MsgData: video} å…¶ä¸­ mediaID ä¸ºåª’ä½“èµ„æº ID ,å¯ä»¥é€šè¿‡ç´ æç®¡ç†(Material)ä¸­çš„æ¥å£è¿›è¡Œä¸Šä¼ \nå›å¤éŸ³ä¹ music := message.NewMusic(\"æ ‡é¢˜\", \"æè¿°\", \"éŸ³ä¹é“¾æ¥\", \"é«˜è´¨é‡éŸ³ä¹é“¾æ¥\", \"ç¼©ç•¥å›¾çš„åª’ä½“id\") return \u0026message.Reply{MsgType: message.MsgTypeMusic, MsgData: music} NewMusicå‚æ•°è¯´æ˜ï¼š\nå‚æ•° æ˜¯å¦å¿…é¡» æè¿° Title å¦ éŸ³ä¹æ ‡é¢˜ Description å¦ éŸ³ä¹æè¿° MusicURL å¦ éŸ³ä¹é“¾æ¥ HQMusicUrl å¦ é«˜è´¨é‡éŸ³ä¹é“¾æ¥ï¼ŒWIFIç¯å¢ƒä¼˜å…ˆä½¿ç”¨è¯¥é“¾æ¥æ’­æ”¾éŸ³ä¹ ThumbMediaId å¦ ç¼©ç•¥å›¾çš„åª’ä½“idï¼Œé€šè¿‡ç´ æç®¡ç†ä¸­çš„æ¥å£ä¸Šä¼ å¤šåª’ä½“æ–‡ä»¶ï¼Œå¾—åˆ°çš„id å…¶ä¸­ä¸å¿…é¡»çš„å‚æ•°å¯ä»¥å¡«å†™ç©ºå­—ç¬¦ä¸²\"\"\nå¤šå®¢æœæ¶ˆæ¯è½¬å‘ è¯·å‚è€ƒ å¤šå®¢æœæ¶ˆæ¯è½¬å‘"},"title":"æ¶ˆæ¯ç®¡ç†"},"/wechat/officialaccount/message_transfer.html":{"data":{"":" transferCustomer := message.NewTransferCustomer(\"\") return \u0026message.Reply{MsgType: message.MsgTypeTransfer, MsgData: transferCustomer} å…¶ä¸­NewTransferCustomerå¦‚æœå‚æ•°å¯é€‰ï¼Œè¡¨ç¤ºæŒ‡å®šå®¢æœè´¦å·"},"title":"å¤šå®¢æœæ¶ˆæ¯è½¬å‘"},"/wechat/officialaccount/start.html":{"data":{"":"ä»¥ä¸‹ä¾‹å­å°±æ¼”ç¤ºäº†ä¸€ä¸ªå¯åŠ¨ä¸€ä¸ªserverï¼Œæ¥æ”¶åˆ°ç”¨æˆ·å‘å¾€å…¬ä¼—å·çš„æ¶ˆæ¯ç„¶ååšå¤„ç†ã€‚\næµ‹è¯•å…¬ä¼—å·å¯ä»¥ä½¿ç”¨å¾®ä¿¡å…¬ä¼—å¹³å°æ¥å£æµ‹è¯•å¹³å° æœ¬åœ°ç¯å¢ƒå¼€å‘çš„è¯ï¼Œå¯ä»¥ä½¿ç”¨ ngrokå·¥å…·æ˜ å°„å‡ºæ¥çš„å…¬ç½‘åœ°å€ï¼Œæ–¹ä¾¿è°ƒè¯•ã€‚ é€šè¿‡go modåˆå§‹åŒ–ä¸€ä¸ªé¡¹ç›®ï¼Œå¹¶å°†wechat sdkä¸‹è½½ä¸‹æ¥ï¼š\ngo mod init github.com/silenceper/wechat-example go get -v github.com/silenceper/wechat/v2 åŒ…å«ä¸€ä¸ªæ–‡ä»¶main.go\nä»£ç ä¸­çš„é…ç½®å‚æ•°è¯·æ›´æ”¹ä¸ºè‡ªå·±çš„ï¼\npackage main import ( \"fmt\" \"net/http\" wechat \"github.com/silenceper/wechat/v2\" \"github.com/silenceper/wechat/v2/cache\" offConfig \"github.com/silenceper/wechat/v2/officialaccount/config\" \"github.com/silenceper/wechat/v2/officialaccount/message\" ) func serveWechat(rw http.ResponseWriter, req *http.Request) { wc := wechat.NewWechat() //è¿™é‡Œæœ¬åœ°å†…å­˜ä¿å­˜access_tokenï¼Œä¹Ÿå¯é€‰æ‹©redisï¼Œ\bmemcacheæˆ–è€…è‡ªå®šcache memory := cache.NewMemory() cfg := \u0026offConfig.Config{ AppID: \"xxx\", AppSecret: \"xxx\", Token: \"xxx\", //EncodingAESKey: \"xxxx\", Cache: memory, } officialAccount := wc.GetOfficialAccount(cfg) // ä¼ å…¥requestå’ŒresponseWriter server := officialAccount.GetServer(req, rw) //è®¾ç½®æ¥æ”¶æ¶ˆæ¯çš„å¤„ç†æ–¹æ³• server.SetMessageHandler(func(msg *message.MixMessage) *message.Reply { //TODO //å›å¤æ¶ˆæ¯ï¼šæ¼”ç¤ºå›å¤ç”¨æˆ·å‘é€çš„æ¶ˆæ¯ text := message.NewText(msg.Content) return \u0026message.Reply{MsgType: message.MsgTypeText, MsgData: text} }) //å¤„ç†æ¶ˆæ¯æ¥æ”¶ä»¥åŠå›å¤ err := server.Serve() if err != nil { fmt.Println(err) return } //å‘é€å›å¤çš„æ¶ˆæ¯ server.Send() } func main() { http.HandleFunc(\"/\", serveWechat) fmt.Println(\"wechat server listener at\", \":8001\") err := http.ListenAndServe(\":8001\", nil) if err != nil { fmt.Printf(\"start server error , err=%v\", err) } } è¿è¡Œ\n# go run main.go wechat server listen at :8001 "},"title":"å¿«é€Ÿå…¥é—¨"},"/wechat/officialaccount/template_message.html":{"data":{"":"","å‘é€æ¨¡æ¿æ¶ˆæ¯#å‘é€æ¨¡æ¿æ¶ˆæ¯":" Send(msg *TemplateMessage) (msgID int64, err error) å…¶ä¸­ TemplateMessageç»“æ„ä¸ºï¼š\ntype TemplateMessage struct { ToUser string `json:\"touser\"` // å¿…é¡», æ¥å—è€…OpenID TemplateID string `json:\"template_id\"` // å¿…é¡», æ¨¡ç‰ˆID URL string `json:\"url,omitempty\"` // å¯é€‰, ç”¨æˆ·ç‚¹å‡»åè·³è½¬çš„URL, è¯¥URLå¿…é¡»å¤„äºå¼€å‘è€…åœ¨å…¬ä¼—å¹³å°ç½‘ç«™ä¸­è®¾ç½®çš„åŸŸä¸­ Color string `json:\"color,omitempty\"` // å¯é€‰, æ•´ä¸ªæ¶ˆæ¯çš„é¢œè‰², å¯ä»¥ä¸è®¾ç½® Data map[string]*TemplateDataItem `json:\"data\"` // å¿…é¡», æ¨¡æ¿æ•°æ® MiniProgram struct { AppID string `json:\"appid\"` //æ‰€éœ€è·³è½¬åˆ°çš„å°ç¨‹åºappidï¼ˆè¯¥å°ç¨‹åºappidå¿…é¡»ä¸å‘æ¨¡æ¿æ¶ˆæ¯çš„å…¬ä¼—å·æ˜¯ç»‘å®šå…³è”å…³ç³»ï¼‰ PagePath string `json:\"pagepath\"` //æ‰€éœ€è·³è½¬åˆ°å°ç¨‹åºçš„å…·ä½“é¡µé¢è·¯å¾„ï¼Œæ”¯æŒå¸¦å‚æ•°,ï¼ˆç¤ºä¾‹index?foo=barï¼‰ } `json:\"miniprogram\"` //å¯é€‰,è·³è½¬è‡³å°ç¨‹åºåœ°å€ } ","è·å–æ¨¡æ¿æ¶ˆæ¯å®ä¾‹#è·å–æ¨¡æ¿æ¶ˆæ¯å®ä¾‹":" oa := wc.GetOfficialAccount(cfg) m:=oa.GetTemplate() "},"title":"æ¨¡æ¿æ¶ˆæ¯"},"/wechat/officialaccount/user.html":{"data":{"":"","è·å–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯#è·å–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯":" GetUserInfo(openID string) (userInfo *Info, err error) ","è·å–ç”¨æˆ·ç®¡ç†æ“ä½œå®ä¾‹#è·å–ç”¨æˆ·ç®¡ç†æ“ä½œå®ä¾‹":" oa := wc.GetOfficialAccount(cfg) u:=oa.GetUser() ","è®¾ç½®ç”¨æˆ·å¤‡æ³¨å#è®¾ç½®ç”¨æˆ·å¤‡æ³¨å":" UpdateRemark(openID, remark string) (err error) ","è¿”å›ç”¨æˆ·åˆ—è¡¨#è¿”å›ç”¨æˆ·åˆ—è¡¨":" ListUserOpenIDs(nextOpenid ...string) (*OpenidList, error) å…¶ä¸­è¿”å›ç»“æœä¸ºï¼š\n/ OpenidList ç”¨æˆ·åˆ—è¡¨ type OpenidList struct { Total int `json:\"total\"` Count int `json:\"count\"` Data struct { OpenIDs []string `json:\"openid\"` } `json:\"data\"` NextOpenID string `json:\"next_openid\"` } "},"title":"ç”¨æˆ·ç®¡ç†"},"/wechat/openplatform/":{"data":{"":"çŠ¶æ€ï¼šbeta\nå®˜æ–¹æ–‡æ¡£","ä»£ç¬¬ä¸‰æ–¹å…¬ä¼—å·---å‘èµ·ç½‘é¡µæˆæƒ#ä»£ç¬¬ä¸‰æ–¹å…¬ä¼—å· - å‘èµ·ç½‘é¡µæˆæƒ":" //ç¬¬ä¸‰æ–¹å…¬ä¼—å·appid appid := \"\" officialAccount := openPlatform.GetOfficialAccount(appid) oauth := officialAccount.PlatformOauth() //é‡å®šå‘åˆ°å¾®ä¿¡oauthæˆæƒç™»å½• oauth.Redirect(rw, req, callback, \"snsapi_userinfo\", \"\", appid) ","ä»£ç¬¬ä¸‰æ–¹å…¬ä¼—å·---è·å–jsconfigä¿¡æ¯#ä»£ç¬¬ä¸‰æ–¹å…¬ä¼—å· - è·å–jsconfigä¿¡æ¯":" CheckAuthrToken(appid, refreshToken) jsConfig, err := openPlatform.GetOfficialAccount(appid).PlatformJs().GetConfig(uri, appid) if err != nil { fmt.Println(err) } fmt.Println(jsConfig) ","ä»£ç¬¬ä¸‰æ–¹å…¬ä¼—å·---è°ƒç”¨å¾®ä¿¡æ¥å£ä»¥å‘é€å¾®ä¿¡æ¨¡æ¿æ¶ˆæ¯ä¸ºä¾‹#ä»£ç¬¬ä¸‰æ–¹å…¬ä¼—å· - è°ƒç”¨å¾®ä¿¡æ¥å£ï¼ˆä»¥å‘é€å¾®ä¿¡æ¨¡æ¿æ¶ˆæ¯ä¸ºä¾‹ï¼‰":"å¹³å°ä»£ç¬¬ä¸‰æ–¹å…¬ä¼—å·è°ƒç”¨å¾®ä¿¡æ¥å£ï¼Œéœ€è¦åœ¨è°ƒç”¨å‰ç¡®ä¿AuthrTokenæœ‰æ•ˆï¼Œå…¶ä½™æ“ä½œä¸å…¬ä¼—å·ä¸€è‡´ã€‚\nimport \"github.com/silenceper/wechat/v2/officialaccount/message\" // åœ¨ä»£ç¬¬ä¸‰æ–¹å…¬ä¼—å·è°ƒç”¨å¾®ä¿¡æ¥å£çš„æ—¶å€™ï¼Œéœ€è¦ç¡®ä¿AuthrTokenæœ‰æ•ˆ // è¿™é‡Œçš„appidæ˜¯ç¬¬ä¸‰æ–¹å…¬ä¼—å·çš„appid CheckAuthrToken(appid, refreshToken) msg := \u0026message.TemplateMessage{ ToUser: openid, TemplateID: templateID, URL: url, Data: data, } officialAccount := openPlatform.GetOfficialAccount(appid) template := message.NewTemplate(officialAccount.GetContext()) msgID, err := template.Send(msg) if err != nil { fmt.Println(err) } fmt.Println(msgID) å¾®ä¿¡çš„éƒ¨åˆ†æ¥å£ï¼ˆå¦‚ï¼šè·å–jsconfigä¿¡æ¯ï¼‰åŒºåˆ†äº†ç¬¬ä¸‰æ–¹å¹³å°è°ƒç”¨å’Œå…¬ä¼—å·ç›´æ¥è°ƒç”¨çš„åœ°å€ï¼Œåœ¨æ–‡æ¡£ä¸‹æ–¹å•ç‹¬è¿›è¡Œè¯´æ˜ã€‚","ä»£ç¬¬ä¸‰æ–¹å…¬ä¼—å·---é€šè¿‡ç½‘é¡µæˆæƒçš„code-æ¢å–access_token#ä»£ç¬¬ä¸‰æ–¹å…¬ä¼—å· - é€šè¿‡ç½‘é¡µæˆæƒçš„code æ¢å–access_token":" officialAccount := openPlatform.GetOfficialAccount(appid) componentAccessToken, err := openPlatform.GetComponentAccessToken() if err != nil { fmt.Println(err) } accessToken, err := officialAccount.PlatformOauth().GetUserAccessToken(code, appid, componentAccessToken) if err != nil { fmt.Println(err) } fmt.Println(accessToken) // é€šè¿‡accessTokenè·å–ç”¨æˆ·ä¿¡æ¯è¯·å‚è€ƒå¾®ä¿¡å…¬ä¼—å·çš„ä¸šåŠ¡ ","å¿«é€Ÿå…¥é—¨#å¿«é€Ÿå…¥é—¨":" wc := wechat.NewWechat() memory := cache.NewMemory() cfg := \u0026openplatform.Config{ AppID: \"xxx\", AppSecret: \"xxx\", Token: \"xxx\", EncodingAESKey: \"xxx\", Cache: memory, } //æˆæƒçš„ç¬¬ä¸‰æ–¹å…¬ä¼—å·çš„appID appID := \"xxx\" // ä¸‹é¢æ–‡æ¡£ä¸­æåˆ°çš„openPlatforméƒ½æ˜¯è¿™ä¸ªå˜é‡ openPlatform := wc.GetOpenPlatform(cfg) officialAccount := openPlatform.GetOfficialAccount(appID) // ä¼ å…¥requestå’ŒresponseWriter server := officialAccount.GetServer(req, rw) //è®¾ç½®æ¥æ”¶æ¶ˆæ¯çš„å¤„ç†æ–¹æ³• server.SetMessageHandler(func(msg message.MixMessage) *message.Reply { if msg.InfoType == message.InfoTypeVerifyTicket { componentVerifyTicket, err := openPlatform.SetComponentAccessToken(msg.ComponentVerifyTicket) if err != nil { log.Println(err) return nil } //debug fmt.Println(componentVerifyTicket) rw.Write([]byte(\"success\")) return nil } //handle other message // return nil }) //å¤„ç†æ¶ˆæ¯æ¥æ”¶ä»¥åŠå›å¤ err := server.Serve() if err != nil { fmt.Println(err) return } //å‘é€å›å¤çš„æ¶ˆæ¯ server.Send() ","ç»´æŠ¤authrtoken#ç»´æŠ¤AuthrToken":"AuthrTokenæ˜¯å¹³å°ä»£ç¬¬ä¸‰æ–¹å…¬ä¼—å·è°ƒç”¨å¾®ä¿¡æ¥å£çš„å‡­æ®ï¼Œé€šè¿‡ç¬¬ä¸‰æ–¹å…¬ä¼—å·æˆæƒç»™å¹³å°æ—¶å¾—åˆ°çš„refreshTokenæ¥è·å–\nfunc CheckAuthrToken(appid, refreshToken string) { // è·å–authrToken token, err := openPlatform.GetAuthrAccessToken(appid) if err != nil { fmt.Println(err) } if token == \"\" { openPlatform.RefreshAuthrToken(appid, refreshToken) } } "},"title":"å¾®ä¿¡å¼€æ”¾å¹³å°"},"/wechat/openplatform/account_verify.html":{"data":{"":"å°ç¨‹åºæˆ–è€…å…¬ä¼—å·æˆæƒç»™ç¬¬ä¸‰æ–¹å¹³å°çš„æµç¨‹ å®˜æ–¹æ–‡æ¡£","æ‰«ç æˆæƒ#æ‰«ç æˆæƒ":" // è·å–å…¬ä¼—å·æ‰«ç æˆæƒé¡µé¢é“¾æ¥ loginPageURL, err := openPlatform.GetComponentLoginPage(redirectURI, authType, \"\") // ...å¼•å¯¼ç”¨æˆ·æ‰«ç æˆæƒ // æ³¨æ„: è¿™é‡Œå¾®ä¿¡ä¼šæ ¡éªŒè·³è½¬åˆ°æˆæƒé¡µçš„referer,å¿…é¡»ä¸ç¬¬ä¸‰æ–¹å¹³å°åå°è®¾ç½®çš„`ç™»å½•æˆæƒçš„å‘èµ·é¡µåŸŸå`ä¸€è‡´ // --------- // é€šè¿‡æˆæƒå›è°ƒè·å–åˆ°çš„authCodeæ¢å–å…¬ä¼—å·æˆ–å°ç¨‹åºçš„æ¥å£è°ƒç”¨å‡­æ®å’Œæˆæƒä¿¡æ¯ authInfo, err := openPlatform.QueryAuthCode(authCode) // ...å¤„ç†å…¬ä¼—å·æˆæƒåçš„é€»è¾‘, å­˜å‚¨refreshToken "},"title":"å…¬ä¼—å·æˆæƒæµç¨‹"},"/wechat/openplatform/publish_verify.html":{"data":{"":"å¾®ä¿¡ç¬¬ä¸‰æ–¹å¹³å°è¿›è¡Œå…¨ç½‘å‘å¸ƒçš„æ—¶å€™ï¼Œä¼šæœ‰ä¸€ä¸ªå…¨ç½‘å‘å¸ƒæ¥å…¥æ£€æµ‹çš„è¿‡ç¨‹ã€‚\nå®˜æ–¹æ–‡æ¡£\nwc := wechat.NewWechat() memory := cache.NewMemory() cfg := \u0026openplatform.Config{ AppID: \"xxx\", AppSecret: \"xxx\", Token: \"xxx\", EncodingAESKey: \"xxx\", Cache: memory, } //æˆæƒçš„ç¬¬ä¸‰æ–¹å…¬ä¼—å·çš„appID appID := \"xxx\" // ä¸‹é¢æ–‡æ¡£ä¸­æåˆ°çš„openPlatforméƒ½æ˜¯è¿™ä¸ªå˜é‡ openPlatform := wc.GetOpenPlatform(cfg) officialAccount := openPlatform.GetOfficialAccount(appID) // ä¼ å…¥requestå’ŒresponseWriter server := officialAccount.GetServer(req, rw) //è®¾ç½®æ¥æ”¶æ¶ˆæ¯çš„å¤„ç†æ–¹æ³• server.SetMessageHandler(func(msg message.MixMessage) *message.Reply { switch msg.InfoType { case message.InfoTypeVerifyTicket: // åœ¨è¿™é‡Œå¤„ç†æ¨é€çš„VerifyTicket // æµ‹è¯•éªŒè¯ç¥¨æ®æ¨é€æµç¨‹ rw.Write([]byte(\"success\")) case message.InfoTypeAuthorized: // å¾®ä¿¡ä¼šæ¨é€æµ‹è¯•å·çš„query_auth_codeè¿‡æ¥ï¼Œéœ€è¦åœ¨è¿™é‡Œè·å–åˆ°æµ‹è¯•å·çš„AuthrToken // å‚ç…§å¼€æ”¾å¹³å°çš„`ç»´æŠ¤AuthrToken`å°èŠ‚ } switch msg.MsgType { case message.MsgTypeText: if msg.Content == \"TESTCOMPONENT_MSG_TYPE_TEXT\" { // æµ‹è¯•å…¬ä¼—å·å¤„ç†ç”¨æˆ·æ¶ˆæ¯ return \u0026message.Reply{ MsgType: message.MsgTypeText, MsgData: message.NewText(\"TESTCOMPONENT_MSG_TYPE_TEXT_callback\"), } } // æµ‹è¯•å…¬ä¼—å·ä½¿ç”¨å®¢æœæ¶ˆæ¯æ¥å£å¤„ç†ç”¨æˆ·æ¶ˆæ¯ if strings.HasPrefix(msg.Content, \"QUERY_AUTH_CODE\") { // ç«‹å³å›å¤ç©ºä¸² rw.Write([]byte(\"\")) var data = strings.Split(msg.Content, \":\") if len(data) == 2 { // è°ƒç”¨å®¢æœæ¥å£å›å¤æ¶ˆæ¯ customerMsg := message.NewCustomerTextMessage(string(msg.FromUserName), fmt.Sprintf(\"%s_from_api\", data[1])) CheckAuthrToken(appid, refreshToken) officialAccount := openPlatform.GetOfficialAccount(appid) msgManager := message.NewMessageManager(officialAccount.GetContext()) msgManager.Send(msg) } } } return nil }) //å¤„ç†æ¶ˆæ¯æ¥æ”¶ä»¥åŠå›å¤ err := server.Serve() if err != nil { fmt.Println(err) return } //å‘é€å›å¤çš„æ¶ˆæ¯ server.Send() "},"title":"å…¨ç½‘å‘å¸ƒæ ¡éªŒ"}}